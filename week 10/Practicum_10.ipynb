{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neural Network\n",
    "Het doel van deze opdracht is om een basisbegrip van neurale netwerken te ontwikkelen door een eenvoudig neuraal netwerk te implementeren, zonder gebruik te maken van backpropagation en gradient descent. Er dient voor het trainen van het model een simpel algoritme gebruikt te worden. Je moet de code zelf goed kan uitleggen."
   ],
   "id": "f7af80e4bced83ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:16.907969Z",
     "start_time": "2024-04-17T09:44:16.903012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "13950eb31e5402c0",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Database connectie"
   ],
   "id": "39805e3616abe1bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.115938Z",
     "start_time": "2024-04-17T09:44:17.111807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# database name\n",
    "DB = {\n",
    "    'servername': '(local)\\\\SQLEXPRESS',\n",
    "    'database': 'DEDS_DataWarehouse'}"
   ],
   "id": "f419b54cf7fd5258",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.306771Z",
     "start_time": "2024-04-17T09:44:17.156683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + ';DATABASE=' + DB['database'] + ';Trusted_Connection=yes')\n",
    "\n",
    "\n",
    "# Create a cursor from the connection\n",
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "# check if connection is successful, else throw an error\n",
    "if export_conn:\n",
    "    print(\"Connection with database is established\")\n",
    "else:\n",
    "    print(\"Connection with database is not established\")\n",
    "    raise Exception(\"Connection with database is not established\")"
   ],
   "id": "e8a191448f3a9f87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection with database is established\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tabellen inlezen\n",
    "We hebben de volgende tabellen nodig:\n",
    "- Order_details\n",
    "- Product\n",
    "- Order"
   ],
   "id": "6d17fd6e5144d2df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.342693Z",
     "start_time": "2024-04-17T09:44:17.308778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "product_query = \"SELECT * FROM Product\"\n",
    "\n",
    "product_result = export_cursor.execute(product_query)\n",
    "product_fetch = product_result.fetchall()\n",
    "product_columns = [column[0] for column in product_result.description]\n",
    "product = pd.DataFrame.from_records(product_fetch, columns=product_columns)\n",
    "\n",
    "# Dropping current_value and last_updated columns\n",
    "product = product.drop(columns=['CURRENT_VALUE', 'LAST_UPDATED'])\n",
    "\n",
    "product"
   ],
   "id": "ffe84d00831ae9a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     PRODUCT_SK  PRODUCT_number      PRODUCT_name_product  \\\n",
       "0             1               1       TrailChef Water Bag   \n",
       "1             2              10        TrailChef Utensils   \n",
       "2             3             100        Insect Bite Relief   \n",
       "3             4             101     Hailstorm Steel Irons   \n",
       "4             5             102  Hailstorm Titanium Irons   \n",
       "..          ...             ...                       ...   \n",
       "110         111              95                Sun Shield   \n",
       "111         112              96        Compact Relief Kit   \n",
       "112         113              97  Deluxe Family Relief Kit   \n",
       "113         114              98           Calamine Relief   \n",
       "114         115              99               Aloe Relief   \n",
       "\n",
       "                       PRODUCT_description_description PRODUCT_image_image  \\\n",
       "0    Lightweight, collapsible bag to carry liquids ...       P01CE1CG1.jpg   \n",
       "1    Spoon, fork and knife set made of a light yet ...       P10CE1CG1.jpg   \n",
       "2    The Insect Bite Relief helps the itching and s...     P100OP4FA17.jpg   \n",
       "3    Iron is 17-4 stainless steel.  Shafts are grap...     P101GE5IR18.jpg   \n",
       "4    Made entirely of pure titanium. The ultimate i...     P102GE5IR18.jpg   \n",
       "..                                                 ...                 ...   \n",
       "110  PABA free sunscreen, SPF 30, poison oak and iv...      P91OP4SS16.jpg   \n",
       "111  A personal first aid kit is recommended for ev...      P96OP4FA17.jpg   \n",
       "112  A complete medical kit suitable for families w...      P96OP4FA17.jpg   \n",
       "113  Use the Calamine Relief for allergic skin reac...      P98OP4FA17.jpg   \n",
       "114  Perfect for minor burns and sunburn, the aloe ...      P99OP4FA17.jpg   \n",
       "\n",
       "    PRODUCT_INTRODUCTION_DATE_introduced PRODUCT_PRODUCTION_COST_cost  \\\n",
       "0                             2011-02-15                       4.0000   \n",
       "1                             2011-02-15                      10.0000   \n",
       "2                             2011-02-15                       3.0000   \n",
       "3                             2019-12-15                     305.5400   \n",
       "4                             2019-10-12                     380.9500   \n",
       "..                                   ...                          ...   \n",
       "110                           2011-02-15                       3.0000   \n",
       "111                           2011-02-15                      16.4300   \n",
       "112                           2013-05-03                      25.0000   \n",
       "113                           2011-02-15                       3.0000   \n",
       "114                           2011-02-15                       2.0000   \n",
       "\n",
       "    PRODUCT_MARGIN_margin PRODUCT_LANGUAGE_language  \\\n",
       "0                  0.3300                        EN   \n",
       "1                  0.4000                        EN   \n",
       "2                  0.5000                        EN   \n",
       "3                  0.4300                        EN   \n",
       "4                  0.5100                        EN   \n",
       "..                    ...                       ...   \n",
       "110                0.5000                        EN   \n",
       "111                0.2800                        EN   \n",
       "112                0.2800                        EN   \n",
       "113                0.5000                        EN   \n",
       "114                0.6000                        EN   \n",
       "\n",
       "    PRODUCT_MINIMUM_SALE_PRICE_minPrice PRODUCT_PRODUCT_LINE_code  \\\n",
       "0                                4.3300                         1   \n",
       "1                               10.4000                         1   \n",
       "2                                3.5000                         4   \n",
       "3                              305.9700                         5   \n",
       "4                              381.4600                         5   \n",
       "..                                  ...                       ...   \n",
       "110                              3.5000                         4   \n",
       "111                             16.7100                         4   \n",
       "112                             25.2800                         4   \n",
       "113                              3.5000                         4   \n",
       "114                              2.6000                         4   \n",
       "\n",
       "    PRODUCT_PRODUCT_LINE_code_en PRODUCT_PRODUCT_TYPE_code  \\\n",
       "0              Camping Equipment                         1   \n",
       "1              Camping Equipment                         1   \n",
       "2             Outdoor Protection                        17   \n",
       "3                 Golf Equipment                        18   \n",
       "4                 Golf Equipment                        18   \n",
       "..                           ...                       ...   \n",
       "110           Outdoor Protection                        16   \n",
       "111           Outdoor Protection                        17   \n",
       "112           Outdoor Protection                        17   \n",
       "113           Outdoor Protection                        17   \n",
       "114           Outdoor Protection                        17   \n",
       "\n",
       "    PRODUCT_PRODUCT_TYPE_code_en  \n",
       "0                   Cooking Gear  \n",
       "1                   Cooking Gear  \n",
       "2                      First Aid  \n",
       "3                          Irons  \n",
       "4                          Irons  \n",
       "..                           ...  \n",
       "110                    Sunscreen  \n",
       "111                    First Aid  \n",
       "112                    First Aid  \n",
       "113                    First Aid  \n",
       "114                    First Aid  \n",
       "\n",
       "[115 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_SK</th>\n",
       "      <th>PRODUCT_number</th>\n",
       "      <th>PRODUCT_name_product</th>\n",
       "      <th>PRODUCT_description_description</th>\n",
       "      <th>PRODUCT_image_image</th>\n",
       "      <th>PRODUCT_INTRODUCTION_DATE_introduced</th>\n",
       "      <th>PRODUCT_PRODUCTION_COST_cost</th>\n",
       "      <th>PRODUCT_MARGIN_margin</th>\n",
       "      <th>PRODUCT_LANGUAGE_language</th>\n",
       "      <th>PRODUCT_MINIMUM_SALE_PRICE_minPrice</th>\n",
       "      <th>PRODUCT_PRODUCT_LINE_code</th>\n",
       "      <th>PRODUCT_PRODUCT_LINE_code_en</th>\n",
       "      <th>PRODUCT_PRODUCT_TYPE_code</th>\n",
       "      <th>PRODUCT_PRODUCT_TYPE_code_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TrailChef Water Bag</td>\n",
       "      <td>Lightweight, collapsible bag to carry liquids ...</td>\n",
       "      <td>P01CE1CG1.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>EN</td>\n",
       "      <td>4.3300</td>\n",
       "      <td>1</td>\n",
       "      <td>Camping Equipment</td>\n",
       "      <td>1</td>\n",
       "      <td>Cooking Gear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>TrailChef Utensils</td>\n",
       "      <td>Spoon, fork and knife set made of a light yet ...</td>\n",
       "      <td>P10CE1CG1.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>EN</td>\n",
       "      <td>10.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>Camping Equipment</td>\n",
       "      <td>1</td>\n",
       "      <td>Cooking Gear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>Insect Bite Relief</td>\n",
       "      <td>The Insect Bite Relief helps the itching and s...</td>\n",
       "      <td>P100OP4FA17.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>Hailstorm Steel Irons</td>\n",
       "      <td>Iron is 17-4 stainless steel.  Shafts are grap...</td>\n",
       "      <td>P101GE5IR18.jpg</td>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>305.5400</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>EN</td>\n",
       "      <td>305.9700</td>\n",
       "      <td>5</td>\n",
       "      <td>Golf Equipment</td>\n",
       "      <td>18</td>\n",
       "      <td>Irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>Hailstorm Titanium Irons</td>\n",
       "      <td>Made entirely of pure titanium. The ultimate i...</td>\n",
       "      <td>P102GE5IR18.jpg</td>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>380.9500</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>EN</td>\n",
       "      <td>381.4600</td>\n",
       "      <td>5</td>\n",
       "      <td>Golf Equipment</td>\n",
       "      <td>18</td>\n",
       "      <td>Irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>Sun Shield</td>\n",
       "      <td>PABA free sunscreen, SPF 30, poison oak and iv...</td>\n",
       "      <td>P91OP4SS16.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunscreen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>A personal first aid kit is recommended for ev...</td>\n",
       "      <td>P96OP4FA17.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>16.4300</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>97</td>\n",
       "      <td>Deluxe Family Relief Kit</td>\n",
       "      <td>A complete medical kit suitable for families w...</td>\n",
       "      <td>P96OP4FA17.jpg</td>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>EN</td>\n",
       "      <td>25.2800</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>98</td>\n",
       "      <td>Calamine Relief</td>\n",
       "      <td>Use the Calamine Relief for allergic skin reac...</td>\n",
       "      <td>P98OP4FA17.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>99</td>\n",
       "      <td>Aloe Relief</td>\n",
       "      <td>Perfect for minor burns and sunburn, the aloe ...</td>\n",
       "      <td>P99OP4FA17.jpg</td>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>EN</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.742736Z",
     "start_time": "2024-04-17T09:44:17.344038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "order_details_query = \"SELECT * FROM Order_details\"\n",
    "\n",
    "order_details_result = export_cursor.execute(order_details_query)\n",
    "order_details_fetch = order_details_result.fetchall()\n",
    "order_details_columns = [column[0] for column in order_details_result.description]\n",
    "order_details = pd.DataFrame.from_records(order_details_fetch, columns=order_details_columns)\n",
    "\n",
    "# Dropping current_value and last_updated columns\n",
    "order_details = order_details.drop(columns=['CURRENT_VALUE', 'LAST_UPDATED'])\n",
    "\n",
    "order_details"
   ],
   "id": "befb700cc9170cb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       ORDER_DETAILS_SK  ORDER_DETAILS_code  ORDER_DETAILS_QUANTITY_quantity  \\\n",
       "0                     1              100000                               16   \n",
       "1                     2              100001                               20   \n",
       "2                     3              100002                               24   \n",
       "3                     4              100003                               18   \n",
       "4                     5              100004                               20   \n",
       "...                 ...                 ...                              ...   \n",
       "43058             43059               99995                              146   \n",
       "43059             43060               99996                              172   \n",
       "43060             43061               99997                              192   \n",
       "43061             43062               99998                              192   \n",
       "43062             43063               99999                               22   \n",
       "\n",
       "      ORDER_DETAILS_TOTAL_COST_total ORDER_DETAILS_TOTAL_MARGIN_margin  \\\n",
       "0                           257.6000                          360.6400   \n",
       "1                           322.0000                          450.8000   \n",
       "2                           386.4000                          540.9600   \n",
       "3                           289.8000                          405.7200   \n",
       "4                           322.0000                          450.8000   \n",
       "...                              ...                               ...   \n",
       "43058                       402.9600                          810.3000   \n",
       "43059                       474.7200                          954.6000   \n",
       "43060                       529.9200                         1065.6000   \n",
       "43061                       529.9200                         1065.6000   \n",
       "43062                       354.2000                          495.8800   \n",
       "\n",
       "       ORDER_DETAILS_ORDER_NUMBER_order  ORDER_DETAILS_PRODUCT_NUMBER_product  \\\n",
       "0                                  4405                                   112   \n",
       "1                                  5008                                   112   \n",
       "2                                  4394                                   112   \n",
       "3                                  4396                                   112   \n",
       "4                                  4382                                   112   \n",
       "...                                 ...                                   ...   \n",
       "43058                              4402                                   111   \n",
       "43059                              4400                                   111   \n",
       "43060                              5148                                   111   \n",
       "43061                              4384                                   111   \n",
       "43062                              4383                                   112   \n",
       "\n",
       "       ORDER_DETAILS_UNIT_ID_unit  \n",
       "0                               1  \n",
       "1                               2  \n",
       "2                               3  \n",
       "3                               4  \n",
       "4                               5  \n",
       "...                           ...  \n",
       "43058                       43059  \n",
       "43059                       43060  \n",
       "43060                       43061  \n",
       "43061                       43062  \n",
       "43062                       43063  \n",
       "\n",
       "[43063 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_DETAILS_SK</th>\n",
       "      <th>ORDER_DETAILS_code</th>\n",
       "      <th>ORDER_DETAILS_QUANTITY_quantity</th>\n",
       "      <th>ORDER_DETAILS_TOTAL_COST_total</th>\n",
       "      <th>ORDER_DETAILS_TOTAL_MARGIN_margin</th>\n",
       "      <th>ORDER_DETAILS_ORDER_NUMBER_order</th>\n",
       "      <th>ORDER_DETAILS_PRODUCT_NUMBER_product</th>\n",
       "      <th>ORDER_DETAILS_UNIT_ID_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>16</td>\n",
       "      <td>257.6000</td>\n",
       "      <td>360.6400</td>\n",
       "      <td>4405</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>20</td>\n",
       "      <td>322.0000</td>\n",
       "      <td>450.8000</td>\n",
       "      <td>5008</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100002</td>\n",
       "      <td>24</td>\n",
       "      <td>386.4000</td>\n",
       "      <td>540.9600</td>\n",
       "      <td>4394</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100003</td>\n",
       "      <td>18</td>\n",
       "      <td>289.8000</td>\n",
       "      <td>405.7200</td>\n",
       "      <td>4396</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100004</td>\n",
       "      <td>20</td>\n",
       "      <td>322.0000</td>\n",
       "      <td>450.8000</td>\n",
       "      <td>4382</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43058</th>\n",
       "      <td>43059</td>\n",
       "      <td>99995</td>\n",
       "      <td>146</td>\n",
       "      <td>402.9600</td>\n",
       "      <td>810.3000</td>\n",
       "      <td>4402</td>\n",
       "      <td>111</td>\n",
       "      <td>43059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43059</th>\n",
       "      <td>43060</td>\n",
       "      <td>99996</td>\n",
       "      <td>172</td>\n",
       "      <td>474.7200</td>\n",
       "      <td>954.6000</td>\n",
       "      <td>4400</td>\n",
       "      <td>111</td>\n",
       "      <td>43060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43060</th>\n",
       "      <td>43061</td>\n",
       "      <td>99997</td>\n",
       "      <td>192</td>\n",
       "      <td>529.9200</td>\n",
       "      <td>1065.6000</td>\n",
       "      <td>5148</td>\n",
       "      <td>111</td>\n",
       "      <td>43061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43061</th>\n",
       "      <td>43062</td>\n",
       "      <td>99998</td>\n",
       "      <td>192</td>\n",
       "      <td>529.9200</td>\n",
       "      <td>1065.6000</td>\n",
       "      <td>4384</td>\n",
       "      <td>111</td>\n",
       "      <td>43062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43062</th>\n",
       "      <td>43063</td>\n",
       "      <td>99999</td>\n",
       "      <td>22</td>\n",
       "      <td>354.2000</td>\n",
       "      <td>495.8800</td>\n",
       "      <td>4383</td>\n",
       "      <td>112</td>\n",
       "      <td>43063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43063 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.789112Z",
     "start_time": "2024-04-17T09:44:17.744743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "order_query = \"SELECT * FROM [Order]\"\n",
    "\n",
    "order_result = export_cursor.execute(order_query)\n",
    "order_fetch = order_result.fetchall()\n",
    "order_columns = [column[0] for column in order_result.description]\n",
    "order = pd.DataFrame.from_records(order_fetch, columns=order_columns)\n",
    "\n",
    "# Dropping current_value and last_updated columns\n",
    "order = order.drop(columns=['CURRENT_VALUE', 'LAST_UPDATED'])\n",
    "\n",
    "order"
   ],
   "id": "4bdbb90a5f947cde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      ORDER_SK  ORDER_order_number  ORDER_ORDER_METHOD_CODE_method_code  \\\n",
       "0            1                1153                                    7   \n",
       "1            2                1154                                    4   \n",
       "2            3                1155                                    7   \n",
       "3            4                1156                                    5   \n",
       "4            5                1157                                    2   \n",
       "...        ...                 ...                                  ...   \n",
       "5355      5356                9475                                    4   \n",
       "5356      5357                9476                                    5   \n",
       "5357      5358                9477                                    2   \n",
       "5358      5359                9478                                    7   \n",
       "5359      5360                9479                                    5   \n",
       "\n",
       "     ORDER_ORDER_METHOD_EN_method  \n",
       "0                     Sales visit  \n",
       "1                          E-mail  \n",
       "2                     Sales visit  \n",
       "3                             Web  \n",
       "4                       Telephone  \n",
       "...                           ...  \n",
       "5355                       E-mail  \n",
       "5356                          Web  \n",
       "5357                    Telephone  \n",
       "5358                  Sales visit  \n",
       "5359                          Web  \n",
       "\n",
       "[5360 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_SK</th>\n",
       "      <th>ORDER_order_number</th>\n",
       "      <th>ORDER_ORDER_METHOD_CODE_method_code</th>\n",
       "      <th>ORDER_ORDER_METHOD_EN_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1153</td>\n",
       "      <td>7</td>\n",
       "      <td>Sales visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1154</td>\n",
       "      <td>4</td>\n",
       "      <td>E-mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1155</td>\n",
       "      <td>7</td>\n",
       "      <td>Sales visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1156</td>\n",
       "      <td>5</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1157</td>\n",
       "      <td>2</td>\n",
       "      <td>Telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>5356</td>\n",
       "      <td>9475</td>\n",
       "      <td>4</td>\n",
       "      <td>E-mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356</th>\n",
       "      <td>5357</td>\n",
       "      <td>9476</td>\n",
       "      <td>5</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>5358</td>\n",
       "      <td>9477</td>\n",
       "      <td>2</td>\n",
       "      <td>Telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>5359</td>\n",
       "      <td>9478</td>\n",
       "      <td>7</td>\n",
       "      <td>Sales visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>5360</td>\n",
       "      <td>9479</td>\n",
       "      <td>5</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5360 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Database connectie sluiten"
   ],
   "id": "67a655400f101812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.795531Z",
     "start_time": "2024-04-17T09:44:17.790122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_cursor.close()\n",
    "export_conn.close()"
   ],
   "id": "799f9d307625f621",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tabellen samenvoegen"
   ],
   "id": "bd000112a286c2ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.878774Z",
     "start_time": "2024-04-17T09:44:17.796539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combined_data = pd.merge(order_details, product, left_on='ORDER_DETAILS_PRODUCT_NUMBER_product', right_on='PRODUCT_SK')\n",
    "combined_data = pd.merge(combined_data, order, left_on='ORDER_DETAILS_ORDER_NUMBER_order', right_on='ORDER_SK')\n",
    "\n",
    "combined_data"
   ],
   "id": "e19695aa4fe64308",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       ORDER_DETAILS_SK  ORDER_DETAILS_code  ORDER_DETAILS_QUANTITY_quantity  \\\n",
       "0                     1              100000                               16   \n",
       "1                     2              100001                               20   \n",
       "2                     3              100002                               24   \n",
       "3                     4              100003                               18   \n",
       "4                     5              100004                               20   \n",
       "...                 ...                 ...                              ...   \n",
       "43058             43059               99995                              146   \n",
       "43059             43060               99996                              172   \n",
       "43060             43061               99997                              192   \n",
       "43061             43062               99998                              192   \n",
       "43062             43063               99999                               22   \n",
       "\n",
       "      ORDER_DETAILS_TOTAL_COST_total ORDER_DETAILS_TOTAL_MARGIN_margin  \\\n",
       "0                           257.6000                          360.6400   \n",
       "1                           322.0000                          450.8000   \n",
       "2                           386.4000                          540.9600   \n",
       "3                           289.8000                          405.7200   \n",
       "4                           322.0000                          450.8000   \n",
       "...                              ...                               ...   \n",
       "43058                       402.9600                          810.3000   \n",
       "43059                       474.7200                          954.6000   \n",
       "43060                       529.9200                         1065.6000   \n",
       "43061                       529.9200                         1065.6000   \n",
       "43062                       354.2000                          495.8800   \n",
       "\n",
       "       ORDER_DETAILS_ORDER_NUMBER_order  ORDER_DETAILS_PRODUCT_NUMBER_product  \\\n",
       "0                                  4405                                   112   \n",
       "1                                  5008                                   112   \n",
       "2                                  4394                                   112   \n",
       "3                                  4396                                   112   \n",
       "4                                  4382                                   112   \n",
       "...                                 ...                                   ...   \n",
       "43058                              4402                                   111   \n",
       "43059                              4400                                   111   \n",
       "43060                              5148                                   111   \n",
       "43061                              4384                                   111   \n",
       "43062                              4383                                   112   \n",
       "\n",
       "       ORDER_DETAILS_UNIT_ID_unit  PRODUCT_SK  PRODUCT_number  ...  \\\n",
       "0                               1         112              96  ...   \n",
       "1                               2         112              96  ...   \n",
       "2                               3         112              96  ...   \n",
       "3                               4         112              96  ...   \n",
       "4                               5         112              96  ...   \n",
       "...                           ...         ...             ...  ...   \n",
       "43058                       43059         111              95  ...   \n",
       "43059                       43060         111              95  ...   \n",
       "43060                       43061         111              95  ...   \n",
       "43061                       43062         111              95  ...   \n",
       "43062                       43063         112              96  ...   \n",
       "\n",
       "      PRODUCT_LANGUAGE_language PRODUCT_MINIMUM_SALE_PRICE_minPrice  \\\n",
       "0                            EN                             16.7100   \n",
       "1                            EN                             16.7100   \n",
       "2                            EN                             16.7100   \n",
       "3                            EN                             16.7100   \n",
       "4                            EN                             16.7100   \n",
       "...                         ...                                 ...   \n",
       "43058                        EN                              3.5000   \n",
       "43059                        EN                              3.5000   \n",
       "43060                        EN                              3.5000   \n",
       "43061                        EN                              3.5000   \n",
       "43062                        EN                             16.7100   \n",
       "\n",
       "      PRODUCT_PRODUCT_LINE_code PRODUCT_PRODUCT_LINE_code_en  \\\n",
       "0                             4           Outdoor Protection   \n",
       "1                             4           Outdoor Protection   \n",
       "2                             4           Outdoor Protection   \n",
       "3                             4           Outdoor Protection   \n",
       "4                             4           Outdoor Protection   \n",
       "...                         ...                          ...   \n",
       "43058                         4           Outdoor Protection   \n",
       "43059                         4           Outdoor Protection   \n",
       "43060                         4           Outdoor Protection   \n",
       "43061                         4           Outdoor Protection   \n",
       "43062                         4           Outdoor Protection   \n",
       "\n",
       "      PRODUCT_PRODUCT_TYPE_code PRODUCT_PRODUCT_TYPE_code_en ORDER_SK  \\\n",
       "0                            17                    First Aid     4405   \n",
       "1                            17                    First Aid     5008   \n",
       "2                            17                    First Aid     4394   \n",
       "3                            17                    First Aid     4396   \n",
       "4                            17                    First Aid     4382   \n",
       "...                         ...                          ...      ...   \n",
       "43058                        16                    Sunscreen     4402   \n",
       "43059                        16                    Sunscreen     4400   \n",
       "43060                        16                    Sunscreen     5148   \n",
       "43061                        16                    Sunscreen     4384   \n",
       "43062                        17                    First Aid     4383   \n",
       "\n",
       "      ORDER_order_number ORDER_ORDER_METHOD_CODE_method_code  \\\n",
       "0                   8462                                   5   \n",
       "1                   9111                                   2   \n",
       "2                   8451                                   2   \n",
       "3                   8453                                   7   \n",
       "4                   8439                                   7   \n",
       "...                  ...                                 ...   \n",
       "43058               8459                                   4   \n",
       "43059               8457                                   4   \n",
       "43060               9267                                   5   \n",
       "43061               8441                                   4   \n",
       "43062               8440                                   7   \n",
       "\n",
       "      ORDER_ORDER_METHOD_EN_method  \n",
       "0                              Web  \n",
       "1                        Telephone  \n",
       "2                        Telephone  \n",
       "3                      Sales visit  \n",
       "4                      Sales visit  \n",
       "...                            ...  \n",
       "43058                       E-mail  \n",
       "43059                       E-mail  \n",
       "43060                          Web  \n",
       "43061                       E-mail  \n",
       "43062                  Sales visit  \n",
       "\n",
       "[43063 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_DETAILS_SK</th>\n",
       "      <th>ORDER_DETAILS_code</th>\n",
       "      <th>ORDER_DETAILS_QUANTITY_quantity</th>\n",
       "      <th>ORDER_DETAILS_TOTAL_COST_total</th>\n",
       "      <th>ORDER_DETAILS_TOTAL_MARGIN_margin</th>\n",
       "      <th>ORDER_DETAILS_ORDER_NUMBER_order</th>\n",
       "      <th>ORDER_DETAILS_PRODUCT_NUMBER_product</th>\n",
       "      <th>ORDER_DETAILS_UNIT_ID_unit</th>\n",
       "      <th>PRODUCT_SK</th>\n",
       "      <th>PRODUCT_number</th>\n",
       "      <th>...</th>\n",
       "      <th>PRODUCT_LANGUAGE_language</th>\n",
       "      <th>PRODUCT_MINIMUM_SALE_PRICE_minPrice</th>\n",
       "      <th>PRODUCT_PRODUCT_LINE_code</th>\n",
       "      <th>PRODUCT_PRODUCT_LINE_code_en</th>\n",
       "      <th>PRODUCT_PRODUCT_TYPE_code</th>\n",
       "      <th>PRODUCT_PRODUCT_TYPE_code_en</th>\n",
       "      <th>ORDER_SK</th>\n",
       "      <th>ORDER_order_number</th>\n",
       "      <th>ORDER_ORDER_METHOD_CODE_method_code</th>\n",
       "      <th>ORDER_ORDER_METHOD_EN_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>16</td>\n",
       "      <td>257.6000</td>\n",
       "      <td>360.6400</td>\n",
       "      <td>4405</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "      <td>4405</td>\n",
       "      <td>8462</td>\n",
       "      <td>5</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>20</td>\n",
       "      <td>322.0000</td>\n",
       "      <td>450.8000</td>\n",
       "      <td>5008</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "      <td>5008</td>\n",
       "      <td>9111</td>\n",
       "      <td>2</td>\n",
       "      <td>Telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100002</td>\n",
       "      <td>24</td>\n",
       "      <td>386.4000</td>\n",
       "      <td>540.9600</td>\n",
       "      <td>4394</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "      <td>4394</td>\n",
       "      <td>8451</td>\n",
       "      <td>2</td>\n",
       "      <td>Telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100003</td>\n",
       "      <td>18</td>\n",
       "      <td>289.8000</td>\n",
       "      <td>405.7200</td>\n",
       "      <td>4396</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "      <td>4396</td>\n",
       "      <td>8453</td>\n",
       "      <td>7</td>\n",
       "      <td>Sales visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100004</td>\n",
       "      <td>20</td>\n",
       "      <td>322.0000</td>\n",
       "      <td>450.8000</td>\n",
       "      <td>4382</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "      <td>4382</td>\n",
       "      <td>8439</td>\n",
       "      <td>7</td>\n",
       "      <td>Sales visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43058</th>\n",
       "      <td>43059</td>\n",
       "      <td>99995</td>\n",
       "      <td>146</td>\n",
       "      <td>402.9600</td>\n",
       "      <td>810.3000</td>\n",
       "      <td>4402</td>\n",
       "      <td>111</td>\n",
       "      <td>43059</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunscreen</td>\n",
       "      <td>4402</td>\n",
       "      <td>8459</td>\n",
       "      <td>4</td>\n",
       "      <td>E-mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43059</th>\n",
       "      <td>43060</td>\n",
       "      <td>99996</td>\n",
       "      <td>172</td>\n",
       "      <td>474.7200</td>\n",
       "      <td>954.6000</td>\n",
       "      <td>4400</td>\n",
       "      <td>111</td>\n",
       "      <td>43060</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunscreen</td>\n",
       "      <td>4400</td>\n",
       "      <td>8457</td>\n",
       "      <td>4</td>\n",
       "      <td>E-mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43060</th>\n",
       "      <td>43061</td>\n",
       "      <td>99997</td>\n",
       "      <td>192</td>\n",
       "      <td>529.9200</td>\n",
       "      <td>1065.6000</td>\n",
       "      <td>5148</td>\n",
       "      <td>111</td>\n",
       "      <td>43061</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunscreen</td>\n",
       "      <td>5148</td>\n",
       "      <td>9267</td>\n",
       "      <td>5</td>\n",
       "      <td>Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43061</th>\n",
       "      <td>43062</td>\n",
       "      <td>99998</td>\n",
       "      <td>192</td>\n",
       "      <td>529.9200</td>\n",
       "      <td>1065.6000</td>\n",
       "      <td>4384</td>\n",
       "      <td>111</td>\n",
       "      <td>43062</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>16</td>\n",
       "      <td>Sunscreen</td>\n",
       "      <td>4384</td>\n",
       "      <td>8441</td>\n",
       "      <td>4</td>\n",
       "      <td>E-mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43062</th>\n",
       "      <td>43063</td>\n",
       "      <td>99999</td>\n",
       "      <td>22</td>\n",
       "      <td>354.2000</td>\n",
       "      <td>495.8800</td>\n",
       "      <td>4383</td>\n",
       "      <td>112</td>\n",
       "      <td>43063</td>\n",
       "      <td>112</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>EN</td>\n",
       "      <td>16.7100</td>\n",
       "      <td>4</td>\n",
       "      <td>Outdoor Protection</td>\n",
       "      <td>17</td>\n",
       "      <td>First Aid</td>\n",
       "      <td>4383</td>\n",
       "      <td>8440</td>\n",
       "      <td>7</td>\n",
       "      <td>Sales visit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43063 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tabel opschonen"
   ],
   "id": "20b096cc0e0a9885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.893265Z",
     "start_time": "2024-04-17T09:44:17.879786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dropping columns\n",
    "keep_columns = ['ORDER_DETAILS_QUANTITY_quantity','PRODUCT_name_product','PRODUCT_PRODUCT_LINE_code', 'PRODUCT_PRODUCT_TYPE_code', 'ORDER_ORDER_METHOD_CODE_method_code']\n",
    "combined_data = combined_data.loc[:, keep_columns]\n",
    "\n",
    "combined_data"
   ],
   "id": "5758bc6db772ae44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       ORDER_DETAILS_QUANTITY_quantity PRODUCT_name_product  \\\n",
       "0                                   16   Compact Relief Kit   \n",
       "1                                   20   Compact Relief Kit   \n",
       "2                                   24   Compact Relief Kit   \n",
       "3                                   18   Compact Relief Kit   \n",
       "4                                   20   Compact Relief Kit   \n",
       "...                                ...                  ...   \n",
       "43058                              146           Sun Shield   \n",
       "43059                              172           Sun Shield   \n",
       "43060                              192           Sun Shield   \n",
       "43061                              192           Sun Shield   \n",
       "43062                               22   Compact Relief Kit   \n",
       "\n",
       "      PRODUCT_PRODUCT_LINE_code PRODUCT_PRODUCT_TYPE_code  \\\n",
       "0                             4                        17   \n",
       "1                             4                        17   \n",
       "2                             4                        17   \n",
       "3                             4                        17   \n",
       "4                             4                        17   \n",
       "...                         ...                       ...   \n",
       "43058                         4                        16   \n",
       "43059                         4                        16   \n",
       "43060                         4                        16   \n",
       "43061                         4                        16   \n",
       "43062                         4                        17   \n",
       "\n",
       "       ORDER_ORDER_METHOD_CODE_method_code  \n",
       "0                                        5  \n",
       "1                                        2  \n",
       "2                                        2  \n",
       "3                                        7  \n",
       "4                                        7  \n",
       "...                                    ...  \n",
       "43058                                    4  \n",
       "43059                                    4  \n",
       "43060                                    5  \n",
       "43061                                    4  \n",
       "43062                                    7  \n",
       "\n",
       "[43063 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_DETAILS_QUANTITY_quantity</th>\n",
       "      <th>PRODUCT_name_product</th>\n",
       "      <th>PRODUCT_PRODUCT_LINE_code</th>\n",
       "      <th>PRODUCT_PRODUCT_TYPE_code</th>\n",
       "      <th>ORDER_ORDER_METHOD_CODE_method_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43058</th>\n",
       "      <td>146</td>\n",
       "      <td>Sun Shield</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43059</th>\n",
       "      <td>172</td>\n",
       "      <td>Sun Shield</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43060</th>\n",
       "      <td>192</td>\n",
       "      <td>Sun Shield</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43061</th>\n",
       "      <td>192</td>\n",
       "      <td>Sun Shield</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43062</th>\n",
       "      <td>22</td>\n",
       "      <td>Compact Relief Kit</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43063 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data voorbereiden\n",
    "data omzetten naar bruikbare data voor het neurale netwerk"
   ],
   "id": "53bed562bf32451e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.919267Z",
     "start_time": "2024-04-17T09:44:17.894461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoding PRODUCT_name_product. Cannot use dummy encoding since there are too many unique values and only one value per row\n",
    "combined_data['PRODUCT_name_product'] = combined_data['PRODUCT_name_product'].astype('category').cat.codes.astype('int32')\n",
    "\n",
    "# turning everything into int32\n",
    "combined_data['PRODUCT_PRODUCT_LINE_code'] = combined_data['PRODUCT_PRODUCT_LINE_code'].astype('int32')\n",
    "combined_data['ORDER_DETAILS_QUANTITY_quantity'] = combined_data['ORDER_DETAILS_QUANTITY_quantity'].astype('int32')\n",
    "combined_data['PRODUCT_PRODUCT_TYPE_code'] = combined_data['PRODUCT_PRODUCT_TYPE_code'].astype('int32')\n",
    "combined_data['ORDER_ORDER_METHOD_CODE_method_code'] = combined_data['ORDER_ORDER_METHOD_CODE_method_code'].astype('int32')\n",
    "\n",
    "combined_data.dtypes"
   ],
   "id": "793f995955e19cc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORDER_DETAILS_QUANTITY_quantity        int32\n",
       "PRODUCT_name_product                   int32\n",
       "PRODUCT_PRODUCT_LINE_code              int32\n",
       "PRODUCT_PRODUCT_TYPE_code              int32\n",
       "ORDER_ORDER_METHOD_CODE_method_code    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data splitsen"
   ],
   "id": "bbbad953f317df3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.934454Z",
     "start_time": "2024-04-17T09:44:17.921651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# splitting the data in x and y\n",
    "X = combined_data.drop(columns=['ORDER_DETAILS_QUANTITY_quantity'])\n",
    "y = combined_data['ORDER_DETAILS_QUANTITY_quantity']\n",
    "\n",
    "# splitting the data in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# printing the sizes\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}')"
   ],
   "id": "fa509d1f95121d7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (34450, 4), X_test: (8613, 4), y_train: (34450,), y_test: (8613,)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.940875Z",
     "start_time": "2024-04-17T09:44:17.936463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# defining the amount of epochs and batch size\n",
    "epochs = 200\n",
    "batch_size = 46"
   ],
   "id": "df076df46f518602",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tensorflow + keras\n",
    "neural network using keras"
   ],
   "id": "972a75e03a4e5f56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model maken"
   ],
   "id": "8f196004ce8d7cd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:44:17.973895Z",
     "start_time": "2024-04-17T09:44:17.941892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting the amount of columns in order_details\n",
    "amount_of_columns = len(combined_data.columns)-1 # needs -1 since one of the columns is the target column. Should be 4\n",
    "\n",
    "# the model\n",
    "model = Sequential()\n",
    "\n",
    "# input layer, 4 nodes\n",
    "model.add(Input(shape=(amount_of_columns,)))\n",
    "\n",
    "# 1 hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(24, activation='relu'))\n",
    "\n",
    "# output layer, 1 node\n",
    "model.add(Dense(1, activation='linear')) # linear since we are predicting a number\n",
    "\n",
    "# compile the model, so we can get metrics\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_logarithmic_error']) # adam uses gradient descent, doesnt seem to be able to use non-gradient descent based optimizer"
   ],
   "id": "c67dc4f2efa7edfb",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model trainen"
   ],
   "id": "cc24e810f4e5c433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:49:23.332773Z",
     "start_time": "2024-04-17T09:44:17.974990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size) # batch size: after how many samples the weights are updated"
   ],
   "id": "7b59494ded1eefb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - loss: 4295.7412 - mean_absolute_error: 38.3872 - mean_squared_logarithmic_error: 1.3689\n",
      "Epoch 2/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 3957.5063 - mean_absolute_error: 35.6878 - mean_squared_logarithmic_error: 0.9829\n",
      "Epoch 3/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 3724.0254 - mean_absolute_error: 35.4784 - mean_squared_logarithmic_error: 0.9300\n",
      "Epoch 4/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 3442.3547 - mean_absolute_error: 34.5030 - mean_squared_logarithmic_error: 0.9007\n",
      "Epoch 5/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3624.9873 - mean_absolute_error: 34.4142 - mean_squared_logarithmic_error: 0.8863\n",
      "Epoch 6/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 3247.6638 - mean_absolute_error: 33.3221 - mean_squared_logarithmic_error: 0.8450\n",
      "Epoch 7/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3453.4009 - mean_absolute_error: 32.9668 - mean_squared_logarithmic_error: 0.8108\n",
      "Epoch 8/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3369.8574 - mean_absolute_error: 32.7266 - mean_squared_logarithmic_error: 0.7857\n",
      "Epoch 9/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3217.3210 - mean_absolute_error: 32.2526 - mean_squared_logarithmic_error: 0.7832\n",
      "Epoch 10/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3037.9424 - mean_absolute_error: 31.6832 - mean_squared_logarithmic_error: 0.7491\n",
      "Epoch 11/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3192.4575 - mean_absolute_error: 32.1004 - mean_squared_logarithmic_error: 0.7320\n",
      "Epoch 12/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2917.3643 - mean_absolute_error: 30.9508 - mean_squared_logarithmic_error: 0.7171\n",
      "Epoch 13/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2964.9314 - mean_absolute_error: 31.0765 - mean_squared_logarithmic_error: 0.7000\n",
      "Epoch 14/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2971.3948 - mean_absolute_error: 30.6985 - mean_squared_logarithmic_error: 0.6861\n",
      "Epoch 15/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2885.3931 - mean_absolute_error: 31.0656 - mean_squared_logarithmic_error: 0.6969\n",
      "Epoch 16/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2910.0220 - mean_absolute_error: 30.8775 - mean_squared_logarithmic_error: 0.6846\n",
      "Epoch 17/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2914.7686 - mean_absolute_error: 30.4640 - mean_squared_logarithmic_error: 0.6693\n",
      "Epoch 18/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2937.0535 - mean_absolute_error: 30.5715 - mean_squared_logarithmic_error: 0.6680\n",
      "Epoch 19/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2994.3525 - mean_absolute_error: 30.5511 - mean_squared_logarithmic_error: 0.6629\n",
      "Epoch 20/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 3069.9568 - mean_absolute_error: 30.7871 - mean_squared_logarithmic_error: 0.6536\n",
      "Epoch 21/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3150.2014 - mean_absolute_error: 31.1959 - mean_squared_logarithmic_error: 0.6639\n",
      "Epoch 22/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3041.6396 - mean_absolute_error: 30.4765 - mean_squared_logarithmic_error: 0.6492\n",
      "Epoch 23/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3002.4536 - mean_absolute_error: 30.4664 - mean_squared_logarithmic_error: 0.6499\n",
      "Epoch 24/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3462.6602 - mean_absolute_error: 31.4116 - mean_squared_logarithmic_error: 0.6597\n",
      "Epoch 25/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2915.0276 - mean_absolute_error: 30.1866 - mean_squared_logarithmic_error: 0.6394\n",
      "Epoch 26/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2702.5349 - mean_absolute_error: 29.7244 - mean_squared_logarithmic_error: 0.6319\n",
      "Epoch 27/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2980.0645 - mean_absolute_error: 30.5315 - mean_squared_logarithmic_error: 0.6526\n",
      "Epoch 28/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3215.2012 - mean_absolute_error: 30.9992 - mean_squared_logarithmic_error: 0.6567\n",
      "Epoch 29/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2825.8953 - mean_absolute_error: 30.5257 - mean_squared_logarithmic_error: 0.6415\n",
      "Epoch 30/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3017.3694 - mean_absolute_error: 30.0979 - mean_squared_logarithmic_error: 0.6270\n",
      "Epoch 31/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2992.5156 - mean_absolute_error: 30.6687 - mean_squared_logarithmic_error: 0.6490\n",
      "Epoch 32/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2978.3599 - mean_absolute_error: 30.1556 - mean_squared_logarithmic_error: 0.6330\n",
      "Epoch 33/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2946.5710 - mean_absolute_error: 30.4021 - mean_squared_logarithmic_error: 0.6305\n",
      "Epoch 34/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2901.9600 - mean_absolute_error: 30.3758 - mean_squared_logarithmic_error: 0.6427\n",
      "Epoch 35/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2996.8794 - mean_absolute_error: 30.4472 - mean_squared_logarithmic_error: 0.6361\n",
      "Epoch 36/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2866.7278 - mean_absolute_error: 30.2692 - mean_squared_logarithmic_error: 0.6197\n",
      "Epoch 37/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2615.4275 - mean_absolute_error: 29.5497 - mean_squared_logarithmic_error: 0.6218\n",
      "Epoch 38/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3134.3796 - mean_absolute_error: 30.5021 - mean_squared_logarithmic_error: 0.6336\n",
      "Epoch 39/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2896.2334 - mean_absolute_error: 30.3323 - mean_squared_logarithmic_error: 0.6274\n",
      "Epoch 40/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3073.0786 - mean_absolute_error: 30.5566 - mean_squared_logarithmic_error: 0.6264\n",
      "Epoch 41/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2711.5867 - mean_absolute_error: 29.6246 - mean_squared_logarithmic_error: 0.6215\n",
      "Epoch 42/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3158.1238 - mean_absolute_error: 30.3553 - mean_squared_logarithmic_error: 0.6309\n",
      "Epoch 43/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2786.9629 - mean_absolute_error: 29.7574 - mean_squared_logarithmic_error: 0.6143\n",
      "Epoch 44/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2786.5891 - mean_absolute_error: 29.3891 - mean_squared_logarithmic_error: 0.6090\n",
      "Epoch 45/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2726.7056 - mean_absolute_error: 29.9000 - mean_squared_logarithmic_error: 0.6166\n",
      "Epoch 46/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2988.7529 - mean_absolute_error: 30.0236 - mean_squared_logarithmic_error: 0.6185\n",
      "Epoch 47/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2736.7454 - mean_absolute_error: 29.4728 - mean_squared_logarithmic_error: 0.6103\n",
      "Epoch 48/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2827.9731 - mean_absolute_error: 29.6666 - mean_squared_logarithmic_error: 0.6171\n",
      "Epoch 49/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - loss: 2640.6265 - mean_absolute_error: 29.4381 - mean_squared_logarithmic_error: 0.6114\n",
      "Epoch 50/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2699.4380 - mean_absolute_error: 29.4307 - mean_squared_logarithmic_error: 0.6078\n",
      "Epoch 51/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2978.8088 - mean_absolute_error: 29.9912 - mean_squared_logarithmic_error: 0.6202\n",
      "Epoch 52/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2637.9146 - mean_absolute_error: 29.1771 - mean_squared_logarithmic_error: 0.5979\n",
      "Epoch 53/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2831.0801 - mean_absolute_error: 29.2838 - mean_squared_logarithmic_error: 0.6059\n",
      "Epoch 54/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3032.1643 - mean_absolute_error: 30.2290 - mean_squared_logarithmic_error: 0.6224\n",
      "Epoch 55/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2861.1023 - mean_absolute_error: 29.9125 - mean_squared_logarithmic_error: 0.6159\n",
      "Epoch 56/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 2918.7051 - mean_absolute_error: 29.5047 - mean_squared_logarithmic_error: 0.6067\n",
      "Epoch 57/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2668.5391 - mean_absolute_error: 29.3228 - mean_squared_logarithmic_error: 0.6106\n",
      "Epoch 58/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2849.3845 - mean_absolute_error: 29.1796 - mean_squared_logarithmic_error: 0.5976\n",
      "Epoch 59/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2769.1313 - mean_absolute_error: 29.4572 - mean_squared_logarithmic_error: 0.6010\n",
      "Epoch 60/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2692.3716 - mean_absolute_error: 29.3147 - mean_squared_logarithmic_error: 0.5987\n",
      "Epoch 61/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2934.9900 - mean_absolute_error: 29.6927 - mean_squared_logarithmic_error: 0.6149\n",
      "Epoch 62/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2813.3953 - mean_absolute_error: 29.3493 - mean_squared_logarithmic_error: 0.6029\n",
      "Epoch 63/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2808.6123 - mean_absolute_error: 28.9212 - mean_squared_logarithmic_error: 0.6004\n",
      "Epoch 64/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2944.1833 - mean_absolute_error: 29.4429 - mean_squared_logarithmic_error: 0.5959\n",
      "Epoch 65/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2854.9277 - mean_absolute_error: 29.3764 - mean_squared_logarithmic_error: 0.5978\n",
      "Epoch 66/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2845.6309 - mean_absolute_error: 29.4052 - mean_squared_logarithmic_error: 0.5965\n",
      "Epoch 67/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2742.7480 - mean_absolute_error: 29.3138 - mean_squared_logarithmic_error: 0.5999\n",
      "Epoch 68/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2887.9858 - mean_absolute_error: 29.2843 - mean_squared_logarithmic_error: 0.6062\n",
      "Epoch 69/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2843.7410 - mean_absolute_error: 29.4193 - mean_squared_logarithmic_error: 0.6036\n",
      "Epoch 70/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3033.4790 - mean_absolute_error: 29.8429 - mean_squared_logarithmic_error: 0.6113\n",
      "Epoch 71/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2710.2922 - mean_absolute_error: 29.0654 - mean_squared_logarithmic_error: 0.5755\n",
      "Epoch 72/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2792.8633 - mean_absolute_error: 29.0464 - mean_squared_logarithmic_error: 0.5866\n",
      "Epoch 73/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2895.0364 - mean_absolute_error: 29.2339 - mean_squared_logarithmic_error: 0.5856\n",
      "Epoch 74/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2998.0837 - mean_absolute_error: 29.8392 - mean_squared_logarithmic_error: 0.5908\n",
      "Epoch 75/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2875.8364 - mean_absolute_error: 29.9749 - mean_squared_logarithmic_error: 0.6116\n",
      "Epoch 76/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2834.7549 - mean_absolute_error: 29.3352 - mean_squared_logarithmic_error: 0.5932\n",
      "Epoch 77/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2921.1077 - mean_absolute_error: 29.5239 - mean_squared_logarithmic_error: 0.5939\n",
      "Epoch 78/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2843.5315 - mean_absolute_error: 29.6112 - mean_squared_logarithmic_error: 0.5914\n",
      "Epoch 79/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2980.1113 - mean_absolute_error: 29.1028 - mean_squared_logarithmic_error: 0.5816\n",
      "Epoch 80/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2846.1013 - mean_absolute_error: 29.5666 - mean_squared_logarithmic_error: 0.5894\n",
      "Epoch 81/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - loss: 2811.7964 - mean_absolute_error: 28.7736 - mean_squared_logarithmic_error: 0.5669\n",
      "Epoch 82/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2948.6272 - mean_absolute_error: 29.3121 - mean_squared_logarithmic_error: 0.5893\n",
      "Epoch 83/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2830.0413 - mean_absolute_error: 29.0399 - mean_squared_logarithmic_error: 0.5812\n",
      "Epoch 84/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2922.0513 - mean_absolute_error: 29.2992 - mean_squared_logarithmic_error: 0.5858\n",
      "Epoch 85/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2651.8330 - mean_absolute_error: 28.7639 - mean_squared_logarithmic_error: 0.5713\n",
      "Epoch 86/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2813.4429 - mean_absolute_error: 28.9949 - mean_squared_logarithmic_error: 0.5658\n",
      "Epoch 87/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2968.1489 - mean_absolute_error: 29.4608 - mean_squared_logarithmic_error: 0.5757\n",
      "Epoch 88/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2960.6902 - mean_absolute_error: 29.4590 - mean_squared_logarithmic_error: 0.5792\n",
      "Epoch 89/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2727.2017 - mean_absolute_error: 28.3801 - mean_squared_logarithmic_error: 0.5694\n",
      "Epoch 90/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2770.7083 - mean_absolute_error: 28.7892 - mean_squared_logarithmic_error: 0.5728\n",
      "Epoch 91/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2826.0623 - mean_absolute_error: 29.3192 - mean_squared_logarithmic_error: 0.5777\n",
      "Epoch 92/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2718.4753 - mean_absolute_error: 29.0476 - mean_squared_logarithmic_error: 0.5765\n",
      "Epoch 93/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2860.7383 - mean_absolute_error: 29.4860 - mean_squared_logarithmic_error: 0.5838\n",
      "Epoch 94/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2892.9224 - mean_absolute_error: 29.4157 - mean_squared_logarithmic_error: 0.5879\n",
      "Epoch 95/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2982.0486 - mean_absolute_error: 29.2113 - mean_squared_logarithmic_error: 0.5688\n",
      "Epoch 96/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2779.4148 - mean_absolute_error: 28.8791 - mean_squared_logarithmic_error: 0.5722\n",
      "Epoch 97/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 953us/step - loss: 2809.9431 - mean_absolute_error: 29.0415 - mean_squared_logarithmic_error: 0.5676\n",
      "Epoch 98/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 944us/step - loss: 2764.5317 - mean_absolute_error: 28.7803 - mean_squared_logarithmic_error: 0.5735\n",
      "Epoch 99/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 909us/step - loss: 2790.7690 - mean_absolute_error: 29.2049 - mean_squared_logarithmic_error: 0.5898\n",
      "Epoch 100/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 918us/step - loss: 3129.9526 - mean_absolute_error: 29.3930 - mean_squared_logarithmic_error: 0.5839\n",
      "Epoch 101/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 892us/step - loss: 2692.8374 - mean_absolute_error: 28.9213 - mean_squared_logarithmic_error: 0.5690\n",
      "Epoch 102/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 884us/step - loss: 2657.3303 - mean_absolute_error: 28.7779 - mean_squared_logarithmic_error: 0.5835\n",
      "Epoch 103/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 926us/step - loss: 2813.2637 - mean_absolute_error: 28.6578 - mean_squared_logarithmic_error: 0.5601\n",
      "Epoch 104/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2777.4771 - mean_absolute_error: 28.9979 - mean_squared_logarithmic_error: 0.5600\n",
      "Epoch 105/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2611.5847 - mean_absolute_error: 28.2475 - mean_squared_logarithmic_error: 0.5589\n",
      "Epoch 106/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2626.5652 - mean_absolute_error: 28.5744 - mean_squared_logarithmic_error: 0.5694\n",
      "Epoch 107/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2873.3152 - mean_absolute_error: 29.4787 - mean_squared_logarithmic_error: 0.5779\n",
      "Epoch 108/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 982us/step - loss: 2787.2834 - mean_absolute_error: 28.9113 - mean_squared_logarithmic_error: 0.5709\n",
      "Epoch 109/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 958us/step - loss: 2695.7236 - mean_absolute_error: 28.8291 - mean_squared_logarithmic_error: 0.5655\n",
      "Epoch 110/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2786.1958 - mean_absolute_error: 29.0406 - mean_squared_logarithmic_error: 0.5773\n",
      "Epoch 111/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2993.9272 - mean_absolute_error: 29.1445 - mean_squared_logarithmic_error: 0.5642\n",
      "Epoch 112/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2905.0808 - mean_absolute_error: 29.4250 - mean_squared_logarithmic_error: 0.5785\n",
      "Epoch 113/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2849.5886 - mean_absolute_error: 28.9643 - mean_squared_logarithmic_error: 0.5656\n",
      "Epoch 114/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2694.3035 - mean_absolute_error: 28.8483 - mean_squared_logarithmic_error: 0.5684\n",
      "Epoch 115/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2737.9255 - mean_absolute_error: 28.9096 - mean_squared_logarithmic_error: 0.5721\n",
      "Epoch 116/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 2653.0200 - mean_absolute_error: 28.3211 - mean_squared_logarithmic_error: 0.5564\n",
      "Epoch 117/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2979.8533 - mean_absolute_error: 29.3278 - mean_squared_logarithmic_error: 0.5722\n",
      "Epoch 118/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2653.9670 - mean_absolute_error: 28.6347 - mean_squared_logarithmic_error: 0.5582\n",
      "Epoch 119/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2817.5381 - mean_absolute_error: 29.0519 - mean_squared_logarithmic_error: 0.5680\n",
      "Epoch 120/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2732.0847 - mean_absolute_error: 28.7289 - mean_squared_logarithmic_error: 0.5570\n",
      "Epoch 121/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 2547.6589 - mean_absolute_error: 28.1862 - mean_squared_logarithmic_error: 0.5542\n",
      "Epoch 122/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2898.9307 - mean_absolute_error: 29.0312 - mean_squared_logarithmic_error: 0.5655\n",
      "Epoch 123/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 2747.6799 - mean_absolute_error: 28.3517 - mean_squared_logarithmic_error: 0.5590\n",
      "Epoch 124/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2747.8787 - mean_absolute_error: 28.7633 - mean_squared_logarithmic_error: 0.5629\n",
      "Epoch 125/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2884.2188 - mean_absolute_error: 28.9050 - mean_squared_logarithmic_error: 0.5623\n",
      "Epoch 126/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2923.6538 - mean_absolute_error: 28.7232 - mean_squared_logarithmic_error: 0.5596\n",
      "Epoch 127/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2779.9189 - mean_absolute_error: 29.0119 - mean_squared_logarithmic_error: 0.5632\n",
      "Epoch 128/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2941.5308 - mean_absolute_error: 29.1162 - mean_squared_logarithmic_error: 0.5685\n",
      "Epoch 129/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2764.6143 - mean_absolute_error: 28.7650 - mean_squared_logarithmic_error: 0.5639\n",
      "Epoch 130/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2727.1609 - mean_absolute_error: 28.5300 - mean_squared_logarithmic_error: 0.5510\n",
      "Epoch 131/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2802.1255 - mean_absolute_error: 28.6833 - mean_squared_logarithmic_error: 0.5581\n",
      "Epoch 132/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 3145.6897 - mean_absolute_error: 29.4440 - mean_squared_logarithmic_error: 0.5666\n",
      "Epoch 133/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - loss: 2805.1897 - mean_absolute_error: 29.2779 - mean_squared_logarithmic_error: 0.5596\n",
      "Epoch 134/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2896.2424 - mean_absolute_error: 29.1467 - mean_squared_logarithmic_error: 0.5575\n",
      "Epoch 135/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2572.0569 - mean_absolute_error: 28.3341 - mean_squared_logarithmic_error: 0.5569\n",
      "Epoch 136/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2794.1084 - mean_absolute_error: 28.9225 - mean_squared_logarithmic_error: 0.5702\n",
      "Epoch 137/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 2678.0378 - mean_absolute_error: 28.4503 - mean_squared_logarithmic_error: 0.5441\n",
      "Epoch 138/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - loss: 2813.6038 - mean_absolute_error: 28.7260 - mean_squared_logarithmic_error: 0.5571\n",
      "Epoch 139/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2666.4602 - mean_absolute_error: 28.6326 - mean_squared_logarithmic_error: 0.5484\n",
      "Epoch 140/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2707.5303 - mean_absolute_error: 28.4485 - mean_squared_logarithmic_error: 0.5427\n",
      "Epoch 141/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2828.1021 - mean_absolute_error: 29.2578 - mean_squared_logarithmic_error: 0.5626\n",
      "Epoch 142/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2852.5542 - mean_absolute_error: 29.1079 - mean_squared_logarithmic_error: 0.5633\n",
      "Epoch 143/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2857.2598 - mean_absolute_error: 28.7967 - mean_squared_logarithmic_error: 0.5687\n",
      "Epoch 144/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2599.5505 - mean_absolute_error: 28.4169 - mean_squared_logarithmic_error: 0.5493\n",
      "Epoch 145/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2854.3521 - mean_absolute_error: 28.8296 - mean_squared_logarithmic_error: 0.5487\n",
      "Epoch 146/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2923.6843 - mean_absolute_error: 29.2830 - mean_squared_logarithmic_error: 0.5608\n",
      "Epoch 147/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2834.4390 - mean_absolute_error: 28.7677 - mean_squared_logarithmic_error: 0.5597\n",
      "Epoch 148/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2602.9163 - mean_absolute_error: 28.2932 - mean_squared_logarithmic_error: 0.5443\n",
      "Epoch 149/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2856.8054 - mean_absolute_error: 28.8768 - mean_squared_logarithmic_error: 0.5606\n",
      "Epoch 150/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2646.7844 - mean_absolute_error: 28.5155 - mean_squared_logarithmic_error: 0.5392\n",
      "Epoch 151/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2926.6382 - mean_absolute_error: 28.7709 - mean_squared_logarithmic_error: 0.5488\n",
      "Epoch 152/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 933us/step - loss: 2607.5002 - mean_absolute_error: 28.3034 - mean_squared_logarithmic_error: 0.5446\n",
      "Epoch 153/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 957us/step - loss: 2755.0051 - mean_absolute_error: 28.7662 - mean_squared_logarithmic_error: 0.5554\n",
      "Epoch 154/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 986us/step - loss: 2699.2551 - mean_absolute_error: 28.6218 - mean_squared_logarithmic_error: 0.5395\n",
      "Epoch 155/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 939us/step - loss: 2729.8618 - mean_absolute_error: 28.4104 - mean_squared_logarithmic_error: 0.5444\n",
      "Epoch 156/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 892us/step - loss: 2825.0078 - mean_absolute_error: 28.7808 - mean_squared_logarithmic_error: 0.5498\n",
      "Epoch 157/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 925us/step - loss: 2824.1316 - mean_absolute_error: 28.2921 - mean_squared_logarithmic_error: 0.5362\n",
      "Epoch 158/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 958us/step - loss: 2823.5610 - mean_absolute_error: 28.4328 - mean_squared_logarithmic_error: 0.5490\n",
      "Epoch 159/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 927us/step - loss: 2573.3484 - mean_absolute_error: 28.0078 - mean_squared_logarithmic_error: 0.5546\n",
      "Epoch 160/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2693.2480 - mean_absolute_error: 28.2776 - mean_squared_logarithmic_error: 0.5444  \n",
      "Epoch 161/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2767.3027 - mean_absolute_error: 28.9531 - mean_squared_logarithmic_error: 0.5471\n",
      "Epoch 162/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 912us/step - loss: 2639.9648 - mean_absolute_error: 28.0941 - mean_squared_logarithmic_error: 0.5463\n",
      "Epoch 163/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 920us/step - loss: 2777.5405 - mean_absolute_error: 28.4649 - mean_squared_logarithmic_error: 0.5463\n",
      "Epoch 164/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 945us/step - loss: 2455.2639 - mean_absolute_error: 27.8511 - mean_squared_logarithmic_error: 0.5365\n",
      "Epoch 165/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2639.5691 - mean_absolute_error: 28.7657 - mean_squared_logarithmic_error: 0.5560\n",
      "Epoch 166/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 983us/step - loss: 2626.1140 - mean_absolute_error: 28.4643 - mean_squared_logarithmic_error: 0.5528\n",
      "Epoch 167/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 923us/step - loss: 2934.0881 - mean_absolute_error: 28.8591 - mean_squared_logarithmic_error: 0.5540\n",
      "Epoch 168/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 906us/step - loss: 2783.3748 - mean_absolute_error: 28.5469 - mean_squared_logarithmic_error: 0.5466\n",
      "Epoch 169/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 928us/step - loss: 2778.0310 - mean_absolute_error: 28.9078 - mean_squared_logarithmic_error: 0.5563\n",
      "Epoch 170/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 969us/step - loss: 2727.9917 - mean_absolute_error: 28.1180 - mean_squared_logarithmic_error: 0.5391\n",
      "Epoch 171/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 934us/step - loss: 2948.7192 - mean_absolute_error: 28.7785 - mean_squared_logarithmic_error: 0.5572\n",
      "Epoch 172/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 902us/step - loss: 2838.1824 - mean_absolute_error: 28.8025 - mean_squared_logarithmic_error: 0.5629\n",
      "Epoch 173/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 914us/step - loss: 2845.0400 - mean_absolute_error: 28.6373 - mean_squared_logarithmic_error: 0.5589\n",
      "Epoch 174/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 931us/step - loss: 2825.4099 - mean_absolute_error: 28.8583 - mean_squared_logarithmic_error: 0.5523\n",
      "Epoch 175/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2823.6860 - mean_absolute_error: 28.3442 - mean_squared_logarithmic_error: 0.5347\n",
      "Epoch 176/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 988us/step - loss: 2720.1052 - mean_absolute_error: 28.5668 - mean_squared_logarithmic_error: 0.5482\n",
      "Epoch 177/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 996us/step - loss: 2826.4819 - mean_absolute_error: 28.6240 - mean_squared_logarithmic_error: 0.5395\n",
      "Epoch 178/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 923us/step - loss: 2655.0305 - mean_absolute_error: 28.3323 - mean_squared_logarithmic_error: 0.5430\n",
      "Epoch 179/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 892us/step - loss: 2822.0586 - mean_absolute_error: 28.3144 - mean_squared_logarithmic_error: 0.5517\n",
      "Epoch 180/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - loss: 2648.6567 - mean_absolute_error: 28.3143 - mean_squared_logarithmic_error: 0.5521\n",
      "Epoch 181/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2560.4619 - mean_absolute_error: 28.2447 - mean_squared_logarithmic_error: 0.5377\n",
      "Epoch 182/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2797.4756 - mean_absolute_error: 28.5648 - mean_squared_logarithmic_error: 0.5412\n",
      "Epoch 183/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2802.0830 - mean_absolute_error: 28.9729 - mean_squared_logarithmic_error: 0.5396\n",
      "Epoch 184/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2896.5842 - mean_absolute_error: 28.7489 - mean_squared_logarithmic_error: 0.5506\n",
      "Epoch 185/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2709.6523 - mean_absolute_error: 28.4085 - mean_squared_logarithmic_error: 0.5404\n",
      "Epoch 186/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2495.7534 - mean_absolute_error: 27.8559 - mean_squared_logarithmic_error: 0.5401\n",
      "Epoch 187/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2857.3074 - mean_absolute_error: 28.6715 - mean_squared_logarithmic_error: 0.5557\n",
      "Epoch 188/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2817.3074 - mean_absolute_error: 28.6693 - mean_squared_logarithmic_error: 0.5468\n",
      "Epoch 189/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2645.1628 - mean_absolute_error: 28.3587 - mean_squared_logarithmic_error: 0.5481\n",
      "Epoch 190/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2775.9006 - mean_absolute_error: 28.4371 - mean_squared_logarithmic_error: 0.5425\n",
      "Epoch 191/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2923.9641 - mean_absolute_error: 29.1017 - mean_squared_logarithmic_error: 0.5552\n",
      "Epoch 192/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2639.2153 - mean_absolute_error: 28.0842 - mean_squared_logarithmic_error: 0.5442\n",
      "Epoch 193/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2665.1157 - mean_absolute_error: 28.1569 - mean_squared_logarithmic_error: 0.5411\n",
      "Epoch 194/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2784.3696 - mean_absolute_error: 28.3495 - mean_squared_logarithmic_error: 0.5431\n",
      "Epoch 195/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2756.2671 - mean_absolute_error: 28.4778 - mean_squared_logarithmic_error: 0.5436\n",
      "Epoch 196/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2845.2957 - mean_absolute_error: 28.6271 - mean_squared_logarithmic_error: 0.5338\n",
      "Epoch 197/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2710.6941 - mean_absolute_error: 28.3859 - mean_squared_logarithmic_error: 0.5471\n",
      "Epoch 198/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2849.9880 - mean_absolute_error: 28.3616 - mean_squared_logarithmic_error: 0.5385\n",
      "Epoch 199/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2799.8284 - mean_absolute_error: 28.3269 - mean_squared_logarithmic_error: 0.5439\n",
      "Epoch 200/200\n",
      "\u001B[1m749/749\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - loss: 2492.2520 - mean_absolute_error: 27.7917 - mean_squared_logarithmic_error: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22ab8168cb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model evalueren"
   ],
   "id": "d538bb54a80b5e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:49:24.347873Z",
     "start_time": "2024-04-17T09:49:23.336938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# predicting the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted'], index=X_test.index)\n",
    "\n",
    "# Add the actual values to the DataFrame\n",
    "predictions_df['Actual'] = y_test\n",
    "\n",
    "predictions_df['Difference'] = predictions_df['Predicted'] - predictions_df['Actual']\n",
    "predictions_df['Absolute Difference'] = abs(predictions_df['Difference'])\n",
    "\n",
    "predictions_df"
   ],
   "id": "157c160913af3b20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m270/270\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       Predicted  Actual  Difference  Absolute Difference\n",
       "9130   42.696201      56  -13.303799            13.303799\n",
       "27718  63.972660      36   27.972660            27.972660\n",
       "41898  38.113224      26   12.113224            12.113224\n",
       "15673  63.517067      24   39.517067            39.517067\n",
       "2314   73.576828      46   27.576828            27.576828\n",
       "...          ...     ...         ...                  ...\n",
       "38076  41.828354      46   -4.171646             4.171646\n",
       "18731  52.423325      94  -41.576675            41.576675\n",
       "2460   43.929462      56  -12.070538            12.070538\n",
       "15719  57.863617      90  -32.136383            32.136383\n",
       "39153   1.881117       6   -4.118883             4.118883\n",
       "\n",
       "[8613 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Absolute Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>42.696201</td>\n",
       "      <td>56</td>\n",
       "      <td>-13.303799</td>\n",
       "      <td>13.303799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27718</th>\n",
       "      <td>63.972660</td>\n",
       "      <td>36</td>\n",
       "      <td>27.972660</td>\n",
       "      <td>27.972660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41898</th>\n",
       "      <td>38.113224</td>\n",
       "      <td>26</td>\n",
       "      <td>12.113224</td>\n",
       "      <td>12.113224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15673</th>\n",
       "      <td>63.517067</td>\n",
       "      <td>24</td>\n",
       "      <td>39.517067</td>\n",
       "      <td>39.517067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>73.576828</td>\n",
       "      <td>46</td>\n",
       "      <td>27.576828</td>\n",
       "      <td>27.576828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38076</th>\n",
       "      <td>41.828354</td>\n",
       "      <td>46</td>\n",
       "      <td>-4.171646</td>\n",
       "      <td>4.171646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>52.423325</td>\n",
       "      <td>94</td>\n",
       "      <td>-41.576675</td>\n",
       "      <td>41.576675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>43.929462</td>\n",
       "      <td>56</td>\n",
       "      <td>-12.070538</td>\n",
       "      <td>12.070538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15719</th>\n",
       "      <td>57.863617</td>\n",
       "      <td>90</td>\n",
       "      <td>-32.136383</td>\n",
       "      <td>32.136383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>1.881117</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.118883</td>\n",
       "      <td>4.118883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8613 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:49:25.464349Z",
     "start_time": "2024-04-17T09:49:24.350989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluating the model\n",
    "loss, mae, mslr = model.evaluate(X_test, y_test)\n",
    "average_difference = predictions_df['Absolute Difference'].mean()\n",
    "print(f'Average Loss (Mean Squared Error): {loss}, Mean Absolute Error: {mae}, Mean Squared Logarithmic Error: {mslr}, Average Difference: {average_difference}')"
   ],
   "id": "a5c0f5dbc60aa3f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m270/270\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - loss: 2159.1655 - mean_absolute_error: 27.7522 - mean_squared_logarithmic_error: 0.5498\n",
      "Loss (Mean Squared Error): 2535.1162109375, Mean Absolute Error: 27.88893699645996, Mean Squared Logarithmic Error: 0.5381360650062561, Average Difference: 27.88893642147894\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pytorch\n",
    "neural network using pytorch"
   ],
   "id": "dae4114b45daf1f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model maken"
   ],
   "id": "2c2c87a21f46b8d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:49:25.479244Z",
     "start_time": "2024-04-17T09:49:25.467461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check if cuda is available\n",
    "# to use gpu, torch needs to be installed with the correct cuda version\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the architecture of the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 16), # input layer with 16 output nodes\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8), # 16 input nodes to 16 output nodes\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1) # 16 input nodes to 1 output node\n",
    ")\n",
    "\n",
    "# Send the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "print(f'The model is using {device}')"
   ],
   "id": "c863ac4bc5ea9bf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is using cpu\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model trainen"
   ],
   "id": "d9c80286b1f48d19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:49:25.494056Z",
     "start_time": "2024-04-17T09:49:25.482406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom optimizer class which doesn't use gradient descent or backpropagation\n",
    "class SimpleErrorOptimizerPyTorch(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(SimpleErrorOptimizerPyTorch, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                # Here we directly subtract the error from the parameters\n",
    "                p.data -= group['lr'] * p.grad.data"
   ],
   "id": "68b69ed9151a7d64",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:52:32.189408Z",
     "start_time": "2024-04-17T09:49:25.500208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Converting the dataframes to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the loss function and the custom optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = SimpleErrorOptimizerPyTorch(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):  # 100 epochs\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ],
   "id": "16f7e294580da2d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 8574.9013671875\n",
      "Epoch 2/200, Loss: 1815.59375\n",
      "Epoch 3/200, Loss: 1096.69873046875\n",
      "Epoch 4/200, Loss: 5409.26025390625\n",
      "Epoch 5/200, Loss: 961.6363525390625\n",
      "Epoch 6/200, Loss: 2608.597412109375\n",
      "Epoch 7/200, Loss: 1094.4290771484375\n",
      "Epoch 8/200, Loss: 1217.9888916015625\n",
      "Epoch 9/200, Loss: 5686.91943359375\n",
      "Epoch 10/200, Loss: 4218.189453125\n",
      "Epoch 11/200, Loss: 4134.861328125\n",
      "Epoch 12/200, Loss: 5379.04443359375\n",
      "Epoch 13/200, Loss: 1678.9793701171875\n",
      "Epoch 14/200, Loss: 3976.979248046875\n",
      "Epoch 15/200, Loss: 2218.52685546875\n",
      "Epoch 16/200, Loss: 7532.5126953125\n",
      "Epoch 17/200, Loss: 755.6180419921875\n",
      "Epoch 18/200, Loss: 1131.1256103515625\n",
      "Epoch 19/200, Loss: 2069.857177734375\n",
      "Epoch 20/200, Loss: 8470.888671875\n",
      "Epoch 21/200, Loss: 4223.63037109375\n",
      "Epoch 22/200, Loss: 1146.35107421875\n",
      "Epoch 23/200, Loss: 7424.44482421875\n",
      "Epoch 24/200, Loss: 6359.84765625\n",
      "Epoch 25/200, Loss: 1114.824462890625\n",
      "Epoch 26/200, Loss: 5124.67626953125\n",
      "Epoch 27/200, Loss: 3848.385498046875\n",
      "Epoch 28/200, Loss: 8930.9580078125\n",
      "Epoch 29/200, Loss: 1913.7431640625\n",
      "Epoch 30/200, Loss: 1887.2879638671875\n",
      "Epoch 31/200, Loss: 1769.099853515625\n",
      "Epoch 32/200, Loss: 540.6007080078125\n",
      "Epoch 33/200, Loss: 20856.21875\n",
      "Epoch 34/200, Loss: 5377.3369140625\n",
      "Epoch 35/200, Loss: 4524.24560546875\n",
      "Epoch 36/200, Loss: 2566.626708984375\n",
      "Epoch 37/200, Loss: 4418.31689453125\n",
      "Epoch 38/200, Loss: 2581.3935546875\n",
      "Epoch 39/200, Loss: 4838.0302734375\n",
      "Epoch 40/200, Loss: 21687.89453125\n",
      "Epoch 41/200, Loss: 2843.7138671875\n",
      "Epoch 42/200, Loss: 1552.245361328125\n",
      "Epoch 43/200, Loss: 11698.0244140625\n",
      "Epoch 44/200, Loss: 4032.854248046875\n",
      "Epoch 45/200, Loss: 1337.9935302734375\n",
      "Epoch 46/200, Loss: 5705.46435546875\n",
      "Epoch 47/200, Loss: 1983.27099609375\n",
      "Epoch 48/200, Loss: 1521.4306640625\n",
      "Epoch 49/200, Loss: 1637.0677490234375\n",
      "Epoch 50/200, Loss: 2559.050537109375\n",
      "Epoch 51/200, Loss: 1244.5474853515625\n",
      "Epoch 52/200, Loss: 2708.19580078125\n",
      "Epoch 53/200, Loss: 4898.34375\n",
      "Epoch 54/200, Loss: 1370.2960205078125\n",
      "Epoch 55/200, Loss: 7444.64501953125\n",
      "Epoch 56/200, Loss: 4252.46142578125\n",
      "Epoch 57/200, Loss: 2194.0625\n",
      "Epoch 58/200, Loss: 11451.9560546875\n",
      "Epoch 59/200, Loss: 1720.312744140625\n",
      "Epoch 60/200, Loss: 943.8531494140625\n",
      "Epoch 61/200, Loss: 644.005859375\n",
      "Epoch 62/200, Loss: 4290.66162109375\n",
      "Epoch 63/200, Loss: 1968.4857177734375\n",
      "Epoch 64/200, Loss: 1520.4210205078125\n",
      "Epoch 65/200, Loss: 1791.2120361328125\n",
      "Epoch 66/200, Loss: 1921.1019287109375\n",
      "Epoch 67/200, Loss: 1338.974365234375\n",
      "Epoch 68/200, Loss: 4472.10107421875\n",
      "Epoch 69/200, Loss: 1382.103271484375\n",
      "Epoch 70/200, Loss: 937.5457763671875\n",
      "Epoch 71/200, Loss: 1117.1114501953125\n",
      "Epoch 72/200, Loss: 7298.07666015625\n",
      "Epoch 73/200, Loss: 1102.3380126953125\n",
      "Epoch 74/200, Loss: 2929.1962890625\n",
      "Epoch 75/200, Loss: 3687.253662109375\n",
      "Epoch 76/200, Loss: 4264.23583984375\n",
      "Epoch 77/200, Loss: 2357.686279296875\n",
      "Epoch 78/200, Loss: 1309.943115234375\n",
      "Epoch 79/200, Loss: 3129.535400390625\n",
      "Epoch 80/200, Loss: 1222.9466552734375\n",
      "Epoch 81/200, Loss: 1191.6961669921875\n",
      "Epoch 82/200, Loss: 4011.299560546875\n",
      "Epoch 83/200, Loss: 971.6134033203125\n",
      "Epoch 84/200, Loss: 2686.37548828125\n",
      "Epoch 85/200, Loss: 1104.58251953125\n",
      "Epoch 86/200, Loss: 950.0825805664062\n",
      "Epoch 87/200, Loss: 2721.4287109375\n",
      "Epoch 88/200, Loss: 2605.54638671875\n",
      "Epoch 89/200, Loss: 3262.4951171875\n",
      "Epoch 90/200, Loss: 1602.2222900390625\n",
      "Epoch 91/200, Loss: 16816.529296875\n",
      "Epoch 92/200, Loss: 14085.6728515625\n",
      "Epoch 93/200, Loss: 2729.0615234375\n",
      "Epoch 94/200, Loss: 4074.325927734375\n",
      "Epoch 95/200, Loss: 1260.803955078125\n",
      "Epoch 96/200, Loss: 2480.322998046875\n",
      "Epoch 97/200, Loss: 4515.74267578125\n",
      "Epoch 98/200, Loss: 927.8684692382812\n",
      "Epoch 99/200, Loss: 2453.45263671875\n",
      "Epoch 100/200, Loss: 890.055908203125\n",
      "Epoch 101/200, Loss: 3119.2001953125\n",
      "Epoch 102/200, Loss: 2229.719482421875\n",
      "Epoch 103/200, Loss: 4612.54248046875\n",
      "Epoch 104/200, Loss: 1968.742919921875\n",
      "Epoch 105/200, Loss: 4379.46923828125\n",
      "Epoch 106/200, Loss: 3617.4482421875\n",
      "Epoch 107/200, Loss: 1257.768310546875\n",
      "Epoch 108/200, Loss: 2728.78564453125\n",
      "Epoch 109/200, Loss: 1474.2626953125\n",
      "Epoch 110/200, Loss: 1249.6927490234375\n",
      "Epoch 111/200, Loss: 3302.283203125\n",
      "Epoch 112/200, Loss: 4923.0966796875\n",
      "Epoch 113/200, Loss: 2732.12890625\n",
      "Epoch 114/200, Loss: 4341.7587890625\n",
      "Epoch 115/200, Loss: 12241.310546875\n",
      "Epoch 116/200, Loss: 2727.837158203125\n",
      "Epoch 117/200, Loss: 4821.0908203125\n",
      "Epoch 118/200, Loss: 2422.481201171875\n",
      "Epoch 119/200, Loss: 1665.007080078125\n",
      "Epoch 120/200, Loss: 3684.975341796875\n",
      "Epoch 121/200, Loss: 18392.384765625\n",
      "Epoch 122/200, Loss: 4379.8779296875\n",
      "Epoch 123/200, Loss: 1729.0408935546875\n",
      "Epoch 124/200, Loss: 2761.7099609375\n",
      "Epoch 125/200, Loss: 3179.240966796875\n",
      "Epoch 126/200, Loss: 1200.5162353515625\n",
      "Epoch 127/200, Loss: 3108.5693359375\n",
      "Epoch 128/200, Loss: 1586.708740234375\n",
      "Epoch 129/200, Loss: 2099.440185546875\n",
      "Epoch 130/200, Loss: 1088.3052978515625\n",
      "Epoch 131/200, Loss: 3566.720703125\n",
      "Epoch 132/200, Loss: 3867.819091796875\n",
      "Epoch 133/200, Loss: 1202.237060546875\n",
      "Epoch 134/200, Loss: 1134.33642578125\n",
      "Epoch 135/200, Loss: 3033.094970703125\n",
      "Epoch 136/200, Loss: 2538.9462890625\n",
      "Epoch 137/200, Loss: 1009.4286499023438\n",
      "Epoch 138/200, Loss: 1926.680419921875\n",
      "Epoch 139/200, Loss: 1379.953857421875\n",
      "Epoch 140/200, Loss: 1845.31787109375\n",
      "Epoch 141/200, Loss: 788.1768188476562\n",
      "Epoch 142/200, Loss: 5642.45556640625\n",
      "Epoch 143/200, Loss: 4283.0791015625\n",
      "Epoch 144/200, Loss: 2436.7900390625\n",
      "Epoch 145/200, Loss: 4160.5888671875\n",
      "Epoch 146/200, Loss: 3409.21533203125\n",
      "Epoch 147/200, Loss: 15688.6650390625\n",
      "Epoch 148/200, Loss: 5230.11376953125\n",
      "Epoch 149/200, Loss: 3634.5341796875\n",
      "Epoch 150/200, Loss: 1422.2755126953125\n",
      "Epoch 151/200, Loss: 1837.0498046875\n",
      "Epoch 152/200, Loss: 1772.1317138671875\n",
      "Epoch 153/200, Loss: 4130.548828125\n",
      "Epoch 154/200, Loss: 3115.000244140625\n",
      "Epoch 155/200, Loss: 8678.5888671875\n",
      "Epoch 156/200, Loss: 2526.28857421875\n",
      "Epoch 157/200, Loss: 4900.08447265625\n",
      "Epoch 158/200, Loss: 2242.873779296875\n",
      "Epoch 159/200, Loss: 1362.6336669921875\n",
      "Epoch 160/200, Loss: 872.5303344726562\n",
      "Epoch 161/200, Loss: 2555.42578125\n",
      "Epoch 162/200, Loss: 2409.26904296875\n",
      "Epoch 163/200, Loss: 2215.097900390625\n",
      "Epoch 164/200, Loss: 4294.19287109375\n",
      "Epoch 165/200, Loss: 3784.136962890625\n",
      "Epoch 166/200, Loss: 1787.9072265625\n",
      "Epoch 167/200, Loss: 4842.33984375\n",
      "Epoch 168/200, Loss: 5286.4775390625\n",
      "Epoch 169/200, Loss: 2359.7685546875\n",
      "Epoch 170/200, Loss: 3180.921142578125\n",
      "Epoch 171/200, Loss: 1349.07763671875\n",
      "Epoch 172/200, Loss: 5279.79150390625\n",
      "Epoch 173/200, Loss: 5417.77294921875\n",
      "Epoch 174/200, Loss: 3219.69677734375\n",
      "Epoch 175/200, Loss: 5188.8486328125\n",
      "Epoch 176/200, Loss: 2434.78369140625\n",
      "Epoch 177/200, Loss: 2128.571533203125\n",
      "Epoch 178/200, Loss: 2030.868896484375\n",
      "Epoch 179/200, Loss: 2128.225341796875\n",
      "Epoch 180/200, Loss: 1650.2020263671875\n",
      "Epoch 181/200, Loss: 4216.44921875\n",
      "Epoch 182/200, Loss: 6501.79931640625\n",
      "Epoch 183/200, Loss: 1479.005126953125\n",
      "Epoch 184/200, Loss: 1197.1953125\n",
      "Epoch 185/200, Loss: 2607.1796875\n",
      "Epoch 186/200, Loss: 5575.0322265625\n",
      "Epoch 187/200, Loss: 2551.60986328125\n",
      "Epoch 188/200, Loss: 4305.7099609375\n",
      "Epoch 189/200, Loss: 1590.414306640625\n",
      "Epoch 190/200, Loss: 3433.134033203125\n",
      "Epoch 191/200, Loss: 3228.585205078125\n",
      "Epoch 192/200, Loss: 1651.0634765625\n",
      "Epoch 193/200, Loss: 2497.78466796875\n",
      "Epoch 194/200, Loss: 8323.791015625\n",
      "Epoch 195/200, Loss: 4862.19140625\n",
      "Epoch 196/200, Loss: 1665.622802734375\n",
      "Epoch 197/200, Loss: 2056.967041015625\n",
      "Epoch 198/200, Loss: 1184.2755126953125\n",
      "Epoch 199/200, Loss: 5373.71923828125\n",
      "Epoch 200/200, Loss: 16143.7919921875\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model evalueren"
   ],
   "id": "4264b461dc76c362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:52:32.207184Z",
     "start_time": "2024-04-17T09:52:32.192553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).squeeze()\n",
    "    loss = criterion(predictions, y_test_tensor)\n",
    "print(f'Test Loss: {loss.item()}')"
   ],
   "id": "e5f80e9088cf4e94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3318.3125\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "# copy the predictions to the cpu\n",
    "predictions_cpu_tensor = predictions.detach().cpu()\n",
    "y_test_cpu_tensor = y_test_tensor.cpu()\n",
    "\n",
    "# Convert the predictions to a numpy array\n",
    "predictions_np = predictions_cpu_tensor.numpy()\n",
    "y_test_np = y_test_cpu_tensor.numpy()\n",
    "\n",
    "# Convert the numpy array to a pandas DataFrame\n",
    "predictions_df = pd.DataFrame(predictions_np, columns=['Predicted'], index=X_test.index)\n",
    "\n",
    "# Convert the actual values to a pandas DataFrame\n",
    "actual_df = pd.DataFrame(y_test_np, columns=['Actual'], index=X_test.index)\n",
    "\n",
    "# Concatenate the two dataframes along the column axis\n",
    "result_df = pd.concat([predictions_df, actual_df], axis=1)\n",
    "\n",
    "# adding difference and absolute difference\n",
    "result_df['Difference'] = result_df['Predicted'] - result_df['Actual']\n",
    "result_df['Absolute Difference'] = abs(result_df['Difference'])\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T09:52:32.248409Z",
     "start_time": "2024-04-17T09:52:32.211724Z"
    }
   },
   "id": "dd1d4f1680fdf576",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Predicted  Actual  Difference  Absolute Difference\n",
       "9130     51.6255    56.0     -4.3745               4.3745\n",
       "27718    51.6255    36.0     15.6255              15.6255\n",
       "41898    51.6255    26.0     25.6255              25.6255\n",
       "15673    51.6255    24.0     27.6255              27.6255\n",
       "2314     51.6255    46.0      5.6255               5.6255\n",
       "...          ...     ...         ...                  ...\n",
       "38076    51.6255    46.0      5.6255               5.6255\n",
       "18731    51.6255    94.0    -42.3745              42.3745\n",
       "2460     51.6255    56.0     -4.3745               4.3745\n",
       "15719    51.6255    90.0    -38.3745              38.3745\n",
       "39153    51.6255     6.0     45.6255              45.6255\n",
       "\n",
       "[8613 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Absolute Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-4.3745</td>\n",
       "      <td>4.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27718</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.6255</td>\n",
       "      <td>15.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41898</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.6255</td>\n",
       "      <td>25.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15673</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.6255</td>\n",
       "      <td>27.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.6255</td>\n",
       "      <td>5.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38076</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.6255</td>\n",
       "      <td>5.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-42.3745</td>\n",
       "      <td>42.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-4.3745</td>\n",
       "      <td>4.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15719</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-38.3745</td>\n",
       "      <td>38.3745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>51.6255</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.6255</td>\n",
       "      <td>45.6255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8613 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the average difference\n",
    "average_difference = result_df['Absolute Difference'].mean()\n",
    "print(f'Average Difference: {average_difference}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T09:52:32.266041Z",
     "start_time": "2024-04-17T09:52:32.251467Z"
    }
   },
   "id": "dd5798588577f44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Difference: 34.41593551635742\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scratch\n",
    "Een neural network maken zonder gebruik te maken van een library"
   ],
   "id": "a92666033051abe6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model maken"
   ],
   "id": "fad4368ab5282f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:52:32.295159Z",
     "start_time": "2024-04-17T09:52:32.270059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomNeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5,\n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5,\n",
    "                                       (self.hidden_nodes, 1))\n",
    "        self.bias_hidden = np.zeros(self.hidden_nodes)\n",
    "        self.bias_output = np.zeros(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        hidden_layer_input = np.dot(X, self.weights_input_to_hidden) + self.bias_hidden\n",
    "        hidden_layer_output = self.linear(hidden_layer_input)\n",
    "\n",
    "        output_layer_input = np.dot(hidden_layer_output, self.weights_hidden_to_output) + self.bias_output\n",
    "        output_layer_output = self.linear(output_layer_input)\n",
    "\n",
    "        return hidden_layer_output, output_layer_output\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_error(y, final_outputs):\n",
    "        return y - final_outputs\n",
    "\n",
    "    def update_weights(self, X, hidden_outputs, error, lr):\n",
    "        epsilon = 1e-8\n",
    "        # Simple rule for updating weights\n",
    "        for i in range(self.weights_input_to_hidden.shape[0]):\n",
    "            for j in range(self.weights_input_to_hidden.shape[1]):\n",
    "                for k in range(X.shape[0]):\n",
    "                    self.weights_input_to_hidden[i, j] += lr * error[k][0] * X[k, i] / (np.abs(hidden_outputs[k, j]) + epsilon)\n",
    "                    \n",
    "    @staticmethod\n",
    "    def calculate_loss(y, final_outputs):\n",
    "        # Calculate the Mean Squared Error loss\n",
    "        return np.mean((y - final_outputs) ** 2)\n",
    "\n",
    "        \n",
    "    def train(self, X, y, lr, batch_size=50):\n",
    "        # normalize the input data\n",
    "        X = X / np.max(X, axis=0)\n",
    "        \n",
    "        # Initialize the loss\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Batch training\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            X_batch = X[i:i+batch_size]\n",
    "            y_batch = y[i:i+batch_size]\n",
    "            \n",
    "            hidden_outputs, final_outputs = self.forward_pass(X_batch)\n",
    "            error = self.calculate_error(y_batch, final_outputs)\n",
    "            self.update_weights(X_batch, hidden_outputs, error, lr)\n",
    "            total_loss += self.calculate_loss(y_batch, final_outputs)\n",
    "            num_batches += 1\n",
    "            \n",
    "        return total_loss / num_batches\n",
    "\n",
    "    def predict(self, X):\n",
    "        _, final_outputs = self.forward_pass(X)\n",
    "        return final_outputs"
   ],
   "id": "4b1362a323153efd",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T09:52:32.309456Z",
     "start_time": "2024-04-17T09:52:32.298179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the neural network\n",
    "nn = CustomNeuralNetwork(input_nodes=4, hidden_nodes=8)"
   ],
   "id": "95839ed30be18c2b",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model trainen"
   ],
   "id": "3cfdc9c2363e3485"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T10:04:04.144641Z",
     "start_time": "2024-04-17T09:52:32.312473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert pandas DataFrame to numpy array\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):  # number of epochs\n",
    "    loss = nn.train(X_train_np, y_train_np, lr=0.001, batch_size=batch_size)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss(MSE): {loss}')"
   ],
   "id": "eef1bdfb6780a4a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss(MSE): 4739.764161933753\n",
      "Epoch 2/200, Loss(MSE): 4254.2551428089\n",
      "Epoch 3/200, Loss(MSE): 4169.653921709434\n",
      "Epoch 4/200, Loss(MSE): 16419.589032407202\n",
      "Epoch 5/200, Loss(MSE): 37924.971701406466\n",
      "Epoch 6/200, Loss(MSE): 52265.012940623565\n",
      "Epoch 7/200, Loss(MSE): 48952.09104670113\n",
      "Epoch 8/200, Loss(MSE): 44068.86872462205\n",
      "Epoch 9/200, Loss(MSE): 38906.51946018407\n",
      "Epoch 10/200, Loss(MSE): 33838.51768611665\n",
      "Epoch 11/200, Loss(MSE): 29026.61022480682\n",
      "Epoch 12/200, Loss(MSE): 24553.511946284525\n",
      "Epoch 13/200, Loss(MSE): 20462.512635663803\n",
      "Epoch 14/200, Loss(MSE): 16729.006438732726\n",
      "Epoch 15/200, Loss(MSE): 13050.167286071668\n",
      "Epoch 16/200, Loss(MSE): 9511.885503391883\n",
      "Epoch 17/200, Loss(MSE): 5220.9892308106155\n",
      "Epoch 18/200, Loss(MSE): 4262.565670132442\n",
      "Epoch 19/200, Loss(MSE): 4192.07116370706\n",
      "Epoch 20/200, Loss(MSE): 4183.875046135191\n",
      "Epoch 21/200, Loss(MSE): 4223.431048834125\n",
      "Epoch 22/200, Loss(MSE): 4133.772573796678\n",
      "Epoch 23/200, Loss(MSE): 4375.6038150404265\n",
      "Epoch 24/200, Loss(MSE): 4204.71055933355\n",
      "Epoch 25/200, Loss(MSE): 4147.141354771796\n",
      "Epoch 26/200, Loss(MSE): 4093.3875073749705\n",
      "Epoch 27/200, Loss(MSE): 4003.200475923749\n",
      "Epoch 28/200, Loss(MSE): 3991.177873895157\n",
      "Epoch 29/200, Loss(MSE): 4129.662518702374\n",
      "Epoch 30/200, Loss(MSE): 4043.482841205212\n",
      "Epoch 31/200, Loss(MSE): 3963.612560025243\n",
      "Epoch 32/200, Loss(MSE): 3925.580881891769\n",
      "Epoch 33/200, Loss(MSE): 3958.2884069383736\n",
      "Epoch 34/200, Loss(MSE): 3990.491521597125\n",
      "Epoch 35/200, Loss(MSE): 3911.272088450664\n",
      "Epoch 36/200, Loss(MSE): 3889.0976580208862\n",
      "Epoch 37/200, Loss(MSE): 3891.260399770009\n",
      "Epoch 38/200, Loss(MSE): 3886.2241011086408\n",
      "Epoch 39/200, Loss(MSE): 3891.1997317180612\n",
      "Epoch 40/200, Loss(MSE): 3894.228808209171\n",
      "Epoch 41/200, Loss(MSE): 3888.197626697292\n",
      "Epoch 42/200, Loss(MSE): 3882.9533133571204\n",
      "Epoch 43/200, Loss(MSE): 4101.0427739128545\n",
      "Epoch 44/200, Loss(MSE): 4003.8613436671217\n",
      "Epoch 45/200, Loss(MSE): 3958.561604716669\n",
      "Epoch 46/200, Loss(MSE): 3905.532074801139\n",
      "Epoch 47/200, Loss(MSE): 3898.742936826348\n",
      "Epoch 48/200, Loss(MSE): 4057.990108197067\n",
      "Epoch 49/200, Loss(MSE): 3900.0116260596824\n",
      "Epoch 50/200, Loss(MSE): 30792.516853159\n",
      "Epoch 51/200, Loss(MSE): 5101.907208341035\n",
      "Epoch 52/200, Loss(MSE): 5059.517887868399\n",
      "Epoch 53/200, Loss(MSE): 5019.786028318158\n",
      "Epoch 54/200, Loss(MSE): 4982.532227131135\n",
      "Epoch 55/200, Loss(MSE): 4947.587891149444\n",
      "Epoch 56/200, Loss(MSE): 4914.794810352346\n",
      "Epoch 57/200, Loss(MSE): 4884.004709932282\n",
      "Epoch 58/200, Loss(MSE): 4855.078789834158\n",
      "Epoch 59/200, Loss(MSE): 4827.887259083551\n",
      "Epoch 60/200, Loss(MSE): 4802.308870757302\n",
      "Epoch 61/200, Loss(MSE): 4778.230462231491\n",
      "Epoch 62/200, Loss(MSE): 4755.54650433386\n",
      "Epoch 63/200, Loss(MSE): 4734.158662201645\n",
      "Epoch 64/200, Loss(MSE): 4713.9753699585535\n",
      "Epoch 65/200, Loss(MSE): 4694.911420761715\n",
      "Epoch 66/200, Loss(MSE): 4676.887573306394\n",
      "Epoch 67/200, Loss(MSE): 4659.830175493305\n",
      "Epoch 68/200, Loss(MSE): 4643.670805656313\n",
      "Epoch 69/200, Loss(MSE): 4628.345931494073\n",
      "Epoch 70/200, Loss(MSE): 4613.796586646613\n",
      "Epoch 71/200, Loss(MSE): 4599.968064694571\n",
      "Epoch 72/200, Loss(MSE): 4586.809630232062\n",
      "Epoch 73/200, Loss(MSE): 4574.274246562636\n",
      "Epoch 74/200, Loss(MSE): 4562.318319493487\n",
      "Epoch 75/200, Loss(MSE): 4550.901456646017\n",
      "Epoch 76/200, Loss(MSE): 4539.986241660279\n",
      "Epoch 77/200, Loss(MSE): 4529.53802264856\n",
      "Epoch 78/200, Loss(MSE): 4519.524714233515\n",
      "Epoch 79/200, Loss(MSE): 4509.916612505138\n",
      "Epoch 80/200, Loss(MSE): 4500.6862222308455\n",
      "Epoch 81/200, Loss(MSE): 4491.808095660696\n",
      "Epoch 82/200, Loss(MSE): 4483.258682283939\n",
      "Epoch 83/200, Loss(MSE): 4475.016188908145\n",
      "Epoch 84/200, Loss(MSE): 4467.060449453134\n",
      "Epoch 85/200, Loss(MSE): 4459.372803872408\n",
      "Epoch 86/200, Loss(MSE): 4451.935985638318\n",
      "Epoch 87/200, Loss(MSE): 4444.734017251627\n",
      "Epoch 88/200, Loss(MSE): 4437.752113261025\n",
      "Epoch 89/200, Loss(MSE): 4430.9765903018915\n",
      "Epoch 90/200, Loss(MSE): 4424.3947836911675\n",
      "Epoch 91/200, Loss(MSE): 4417.994970137163\n",
      "Epoch 92/200, Loss(MSE): 4411.766296149388\n",
      "Epoch 93/200, Loss(MSE): 4405.698711756618\n",
      "Epoch 94/200, Loss(MSE): 4399.782909163782\n",
      "Epoch 95/200, Loss(MSE): 4394.010266001638\n",
      "Epoch 96/200, Loss(MSE): 4388.372792843766\n",
      "Epoch 97/200, Loss(MSE): 4382.8630846855085\n",
      "Epoch 98/200, Loss(MSE): 4377.474276100612\n",
      "Epoch 99/200, Loss(MSE): 4372.199999807563\n",
      "Epoch 100/200, Loss(MSE): 4367.034348397452\n",
      "Epoch 101/200, Loss(MSE): 4361.971838990644\n",
      "Epoch 102/200, Loss(MSE): 4357.007380605278\n",
      "Epoch 103/200, Loss(MSE): 4352.13624403651\n",
      "Epoch 104/200, Loss(MSE): 4347.354034058442\n",
      "Epoch 105/200, Loss(MSE): 4342.65666377416\n",
      "Epoch 106/200, Loss(MSE): 4338.040330951762\n",
      "Epoch 107/200, Loss(MSE): 4333.50149619591\n",
      "Epoch 108/200, Loss(MSE): 4329.036862815524\n",
      "Epoch 109/200, Loss(MSE): 4324.643358257109\n",
      "Epoch 110/200, Loss(MSE): 4320.3181169848\n",
      "Epoch 111/200, Loss(MSE): 4316.058464695066\n",
      "Epoch 112/200, Loss(MSE): 4311.861903763435\n",
      "Epoch 113/200, Loss(MSE): 4307.726099827947\n",
      "Epoch 114/200, Loss(MSE): 4303.648869421049\n",
      "Epoch 115/200, Loss(MSE): 4299.628168568654\n",
      "Epoch 116/200, Loss(MSE): 4295.662082280389\n",
      "Epoch 117/200, Loss(MSE): 4291.748814862321\n",
      "Epoch 118/200, Loss(MSE): 4287.886680987179\n",
      "Epoch 119/200, Loss(MSE): 4284.07409746277\n",
      "Epoch 120/200, Loss(MSE): 4280.309575644259\n",
      "Epoch 121/200, Loss(MSE): 4276.591714438908\n",
      "Epoch 122/200, Loss(MSE): 4272.919193857511\n",
      "Epoch 123/200, Loss(MSE): 4269.290769068623\n",
      "Epoch 124/200, Loss(MSE): 4265.70526491677\n",
      "Epoch 125/200, Loss(MSE): 4262.161570867137\n",
      "Epoch 126/200, Loss(MSE): 4258.658636343762\n",
      "Epoch 127/200, Loss(MSE): 4255.195466429743\n",
      "Epoch 128/200, Loss(MSE): 4251.771117900988\n",
      "Epoch 129/200, Loss(MSE): 4248.384695566897\n",
      "Epoch 130/200, Loss(MSE): 4245.03534889405\n",
      "Epoch 131/200, Loss(MSE): 4241.722268890137\n",
      "Epoch 132/200, Loss(MSE): 4238.444685227773\n",
      "Epoch 133/200, Loss(MSE): 4235.201863589134\n",
      "Epoch 134/200, Loss(MSE): 4231.99310321404\n",
      "Epoch 135/200, Loss(MSE): 4228.8177346347875\n",
      "Epoch 136/200, Loss(MSE): 4225.675117584387\n",
      "Epoch 137/200, Loss(MSE): 4222.56463906275\n",
      "Epoch 138/200, Loss(MSE): 4219.485711549575\n",
      "Epoch 139/200, Loss(MSE): 4216.4377713520125\n",
      "Epoch 140/200, Loss(MSE): 4213.420277076293\n",
      "Epoch 141/200, Loss(MSE): 4210.4327082137615\n",
      "Epoch 142/200, Loss(MSE): 4207.474563832465\n",
      "Epoch 143/200, Loss(MSE): 4204.54536136546\n",
      "Epoch 144/200, Loss(MSE): 4201.644635489012\n",
      "Epoch 145/200, Loss(MSE): 4198.771937083005\n",
      "Epoch 146/200, Loss(MSE): 4195.926832267328\n",
      "Epoch 147/200, Loss(MSE): 4193.108901508463\n",
      "Epoch 148/200, Loss(MSE): 4190.317738790772\n",
      "Epoch 149/200, Loss(MSE): 4187.552950847232\n",
      "Epoch 150/200, Loss(MSE): 4184.814156445206\n",
      "Epoch 151/200, Loss(MSE): 4182.100985722978\n",
      "Epoch 152/200, Loss(MSE): 4179.413079573054\n",
      "Epoch 153/200, Loss(MSE): 4176.750089068764\n",
      "Epoch 154/200, Loss(MSE): 4174.111674930508\n",
      "Epoch 155/200, Loss(MSE): 4171.497507029239\n",
      "Epoch 156/200, Loss(MSE): 4168.907263923586\n",
      "Epoch 157/200, Loss(MSE): 4166.340632428636\n",
      "Epoch 158/200, Loss(MSE): 4163.797307213762\n",
      "Epoch 159/200, Loss(MSE): 4161.276990427175\n",
      "Epoch 160/200, Loss(MSE): 4158.779391345473\n",
      "Epoch 161/200, Loss(MSE): 4156.304226046173\n",
      "Epoch 162/200, Loss(MSE): 4153.85121710129\n",
      "Epoch 163/200, Loss(MSE): 4151.42009329089\n",
      "Epoch 164/200, Loss(MSE): 4149.010589334693\n",
      "Epoch 165/200, Loss(MSE): 4146.622445640585\n",
      "Epoch 166/200, Loss(MSE): 4144.255408068829\n",
      "Epoch 167/200, Loss(MSE): 4141.909227710831\n",
      "Epoch 168/200, Loss(MSE): 4139.583660681103\n",
      "Epoch 169/200, Loss(MSE): 4137.278467922138\n",
      "Epoch 170/200, Loss(MSE): 4134.993415020478\n",
      "Epoch 171/200, Loss(MSE): 4132.7282720337735\n",
      "Epoch 172/200, Loss(MSE): 4130.482813327826\n",
      "Epoch 173/200, Loss(MSE): 4128.2568174227\n",
      "Epoch 174/200, Loss(MSE): 4126.050066847905\n",
      "Epoch 175/200, Loss(MSE): 4123.862348005356\n",
      "Epoch 176/200, Loss(MSE): 4121.69345103974\n",
      "Epoch 177/200, Loss(MSE): 4119.543169716096\n",
      "Epoch 178/200, Loss(MSE): 4117.411301303834\n",
      "Epoch 179/200, Loss(MSE): 4115.2976464666845\n",
      "Epoch 180/200, Loss(MSE): 4113.202009158538\n",
      "Epoch 181/200, Loss(MSE): 4111.124196524317\n",
      "Epoch 182/200, Loss(MSE): 4109.064018806088\n",
      "Epoch 183/200, Loss(MSE): 4107.0212892535355\n",
      "Epoch 184/200, Loss(MSE): 4104.995824038855\n",
      "Epoch 185/200, Loss(MSE): 4102.987442175706\n",
      "Epoch 186/200, Loss(MSE): 4100.9959654419445\n",
      "Epoch 187/200, Loss(MSE): 4099.021218305981\n",
      "Epoch 188/200, Loss(MSE): 4097.063027856238\n",
      "Epoch 189/200, Loss(MSE): 4095.121223733986\n",
      "Epoch 190/200, Loss(MSE): 4093.1956380691086\n",
      "Epoch 191/200, Loss(MSE): 4091.286105418321\n",
      "Epoch 192/200, Loss(MSE): 4089.3924627063598\n",
      "Epoch 193/200, Loss(MSE): 4087.514549169513\n",
      "Epoch 194/200, Loss(MSE): 4085.6522063011917\n",
      "Epoch 195/200, Loss(MSE): 4083.8052778001247\n",
      "Epoch 196/200, Loss(MSE): 4081.9736095201415\n",
      "Epoch 197/200, Loss(MSE): 4080.1570494222865\n",
      "Epoch 198/200, Loss(MSE): 4078.3554475284586\n",
      "Epoch 199/200, Loss(MSE): 4076.5686558769157\n",
      "Epoch 200/200, Loss(MSE): 4074.796528479401\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model evalueren"
   ],
   "id": "75869ad696a70683"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T10:04:04.762011Z",
     "start_time": "2024-04-17T10:04:04.146650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate predictions for the test data\n",
    "predictions = nn.predict(X_test.values)\n",
    "\n",
    "# Calculate the error\n",
    "error = y_test.values - predictions\n",
    "\n",
    "# Square the error\n",
    "squared_error = np.square(error)\n",
    "\n",
    "# Calculate the mean of the squared errors\n",
    "mse = np.mean(squared_error)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Convert the predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted'], index=X_test.index)\n",
    "# adding the actual values to the dataframe\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Difference'] = predictions_df['Predicted'] - predictions_df['Actual']\n",
    "predictions_df['Absolute Difference'] = abs(predictions_df['Difference'])\n",
    "\n",
    "predictions_df"
   ],
   "id": "e577e213bc894e78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 12563524.22393069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         Predicted  Actual   Difference  Absolute Difference\n",
       "9130   4294.038788      56  4238.038788          4238.038788\n",
       "27718  1672.318659      36  1636.318659          1636.318659\n",
       "41898  3380.605861      26  3354.605861          3354.605861\n",
       "15673  2241.238898      24  2217.238898          2217.238898\n",
       "2314   2615.205747      46  2569.205747          2569.205747\n",
       "...            ...     ...          ...                  ...\n",
       "38076  4793.681601      46  4747.681601          4747.681601\n",
       "18731  5520.136214      94  5426.136214          5426.136214\n",
       "2460   4507.971699      56  4451.971699          4451.971699\n",
       "15719  2602.577355      90  2512.577355          2512.577355\n",
       "39153  4487.855844       6  4481.855844          4481.855844\n",
       "\n",
       "[8613 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Absolute Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>4294.038788</td>\n",
       "      <td>56</td>\n",
       "      <td>4238.038788</td>\n",
       "      <td>4238.038788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27718</th>\n",
       "      <td>1672.318659</td>\n",
       "      <td>36</td>\n",
       "      <td>1636.318659</td>\n",
       "      <td>1636.318659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41898</th>\n",
       "      <td>3380.605861</td>\n",
       "      <td>26</td>\n",
       "      <td>3354.605861</td>\n",
       "      <td>3354.605861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15673</th>\n",
       "      <td>2241.238898</td>\n",
       "      <td>24</td>\n",
       "      <td>2217.238898</td>\n",
       "      <td>2217.238898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>2615.205747</td>\n",
       "      <td>46</td>\n",
       "      <td>2569.205747</td>\n",
       "      <td>2569.205747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38076</th>\n",
       "      <td>4793.681601</td>\n",
       "      <td>46</td>\n",
       "      <td>4747.681601</td>\n",
       "      <td>4747.681601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>5520.136214</td>\n",
       "      <td>94</td>\n",
       "      <td>5426.136214</td>\n",
       "      <td>5426.136214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>4507.971699</td>\n",
       "      <td>56</td>\n",
       "      <td>4451.971699</td>\n",
       "      <td>4451.971699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15719</th>\n",
       "      <td>2602.577355</td>\n",
       "      <td>90</td>\n",
       "      <td>2512.577355</td>\n",
       "      <td>2512.577355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>4487.855844</td>\n",
       "      <td>6</td>\n",
       "      <td>4481.855844</td>\n",
       "      <td>4481.855844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8613 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the average difference\n",
    "average_difference = predictions_df['Absolute Difference'].mean()\n",
    "print(f'Average Difference: {average_difference}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T10:04:06.156508Z",
     "start_time": "2024-04-17T10:04:04.764019Z"
    }
   },
   "id": "a2175abd978cea4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Difference: 3146.1718878027255\n"
     ]
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
