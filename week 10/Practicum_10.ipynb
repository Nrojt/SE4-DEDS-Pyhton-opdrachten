{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neural Network\n",
    "Het doel van deze opdracht is om een basisbegrip van neurale netwerken te ontwikkelen door een eenvoudig neuraal netwerk te implementeren, zonder gebruik te maken van backpropagation en gradient descent. Er dient voor het trainen van het model een simpel algoritme gebruikt te worden. Je moet de code zelf goed kan uitleggen."
   ],
   "id": "f7af80e4bced83ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.400637Z",
     "start_time": "2024-04-16T08:35:49.047319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "13950eb31e5402c0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Database connectie"
   ],
   "id": "39805e3616abe1bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.404045Z",
     "start_time": "2024-04-16T08:35:54.401643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# database name\n",
    "DB = {\n",
    "    'servername': '(local)\\\\SQLEXPRESS',\n",
    "    'database': 'DEDS_DataWarehouse'}"
   ],
   "id": "f419b54cf7fd5258",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.470190Z",
     "start_time": "2024-04-16T08:35:54.405056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + ';DATABASE=' + DB['database'] + ';Trusted_Connection=yes')\n",
    "\n",
    "\n",
    "# Create a cursor from the connection\n",
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "# check if connection is successful, else throw an error\n",
    "if export_conn:\n",
    "    print(\"Connection with database is established\")\n",
    "else:\n",
    "    print(\"Connection with database is not established\")\n",
    "    raise Exception(\"Connection with database is not established\")"
   ],
   "id": "e8a191448f3a9f87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection with database is established\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tabellen inlezen\n",
    "We hebben de volgende tabellen nodig:\n",
    "- Order_details\n",
    "- Product\n",
    "- Order"
   ],
   "id": "6d17fd6e5144d2df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.496979Z",
     "start_time": "2024-04-16T08:35:54.471696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "product_query = \"SELECT * FROM Product\"\n",
    "\n",
    "product_result = export_cursor.execute(product_query)\n",
    "product_fetch = product_result.fetchall()\n",
    "product_columns = [column[0] for column in product_result.description]\n",
    "product = pd.DataFrame.from_records(product_fetch, columns=product_columns)\n",
    "\n",
    "# Dropping current_value and last_updated columns\n",
    "product = product.drop(columns=['CURRENT_VALUE', 'LAST_UPDATED'])\n",
    "\n",
    "product"
   ],
   "id": "ffe84d00831ae9a3",
   "outputs": [
    {
     "data": {
      "text/plain": "     PRODUCT_SK  PRODUCT_number      PRODUCT_name_product  \\\n0             1               1       TrailChef Water Bag   \n1             2              10        TrailChef Utensils   \n2             3             100        Insect Bite Relief   \n3             4             101     Hailstorm Steel Irons   \n4             5             102  Hailstorm Titanium Irons   \n..          ...             ...                       ...   \n110         111              95                Sun Shield   \n111         112              96        Compact Relief Kit   \n112         113              97  Deluxe Family Relief Kit   \n113         114              98           Calamine Relief   \n114         115              99               Aloe Relief   \n\n                       PRODUCT_description_description PRODUCT_image_image  \\\n0    Lightweight, collapsible bag to carry liquids ...       P01CE1CG1.jpg   \n1    Spoon, fork and knife set made of a light yet ...       P10CE1CG1.jpg   \n2    The Insect Bite Relief helps the itching and s...     P100OP4FA17.jpg   \n3    Iron is 17-4 stainless steel.  Shafts are grap...     P101GE5IR18.jpg   \n4    Made entirely of pure titanium. The ultimate i...     P102GE5IR18.jpg   \n..                                                 ...                 ...   \n110  PABA free sunscreen, SPF 30, poison oak and iv...      P91OP4SS16.jpg   \n111  A personal first aid kit is recommended for ev...      P96OP4FA17.jpg   \n112  A complete medical kit suitable for families w...      P96OP4FA17.jpg   \n113  Use the Calamine Relief for allergic skin reac...      P98OP4FA17.jpg   \n114  Perfect for minor burns and sunburn, the aloe ...      P99OP4FA17.jpg   \n\n    PRODUCT_INTRODUCTION_DATE_introduced PRODUCT_PRODUCTION_COST_cost  \\\n0                             2011-02-15                       4.0000   \n1                             2011-02-15                      10.0000   \n2                             2011-02-15                       3.0000   \n3                             2019-12-15                     305.5400   \n4                             2019-10-12                     380.9500   \n..                                   ...                          ...   \n110                           2011-02-15                       3.0000   \n111                           2011-02-15                      16.4300   \n112                           2013-05-03                      25.0000   \n113                           2011-02-15                       3.0000   \n114                           2011-02-15                       2.0000   \n\n    PRODUCT_MARGIN_margin PRODUCT_LANGUAGE_language  \\\n0                  0.3300                        EN   \n1                  0.4000                        EN   \n2                  0.5000                        EN   \n3                  0.4300                        EN   \n4                  0.5100                        EN   \n..                    ...                       ...   \n110                0.5000                        EN   \n111                0.2800                        EN   \n112                0.2800                        EN   \n113                0.5000                        EN   \n114                0.6000                        EN   \n\n    PRODUCT_MINIMUM_SALE_PRICE_minPrice PRODUCT_PRODUCT_LINE_code  \\\n0                                4.3300                         1   \n1                               10.4000                         1   \n2                                3.5000                         4   \n3                              305.9700                         5   \n4                              381.4600                         5   \n..                                  ...                       ...   \n110                              3.5000                         4   \n111                             16.7100                         4   \n112                             25.2800                         4   \n113                              3.5000                         4   \n114                              2.6000                         4   \n\n    PRODUCT_PRODUCT_LINE_code_en PRODUCT_PRODUCT_TYPE_code  \\\n0              Camping Equipment                         1   \n1              Camping Equipment                         1   \n2             Outdoor Protection                        17   \n3                 Golf Equipment                        18   \n4                 Golf Equipment                        18   \n..                           ...                       ...   \n110           Outdoor Protection                        16   \n111           Outdoor Protection                        17   \n112           Outdoor Protection                        17   \n113           Outdoor Protection                        17   \n114           Outdoor Protection                        17   \n\n    PRODUCT_PRODUCT_TYPE_code_en  \n0                   Cooking Gear  \n1                   Cooking Gear  \n2                      First Aid  \n3                          Irons  \n4                          Irons  \n..                           ...  \n110                    Sunscreen  \n111                    First Aid  \n112                    First Aid  \n113                    First Aid  \n114                    First Aid  \n\n[115 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_SK</th>\n      <th>PRODUCT_number</th>\n      <th>PRODUCT_name_product</th>\n      <th>PRODUCT_description_description</th>\n      <th>PRODUCT_image_image</th>\n      <th>PRODUCT_INTRODUCTION_DATE_introduced</th>\n      <th>PRODUCT_PRODUCTION_COST_cost</th>\n      <th>PRODUCT_MARGIN_margin</th>\n      <th>PRODUCT_LANGUAGE_language</th>\n      <th>PRODUCT_MINIMUM_SALE_PRICE_minPrice</th>\n      <th>PRODUCT_PRODUCT_LINE_code</th>\n      <th>PRODUCT_PRODUCT_LINE_code_en</th>\n      <th>PRODUCT_PRODUCT_TYPE_code</th>\n      <th>PRODUCT_PRODUCT_TYPE_code_en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>TrailChef Water Bag</td>\n      <td>Lightweight, collapsible bag to carry liquids ...</td>\n      <td>P01CE1CG1.jpg</td>\n      <td>2011-02-15</td>\n      <td>4.0000</td>\n      <td>0.3300</td>\n      <td>EN</td>\n      <td>4.3300</td>\n      <td>1</td>\n      <td>Camping Equipment</td>\n      <td>1</td>\n      <td>Cooking Gear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10</td>\n      <td>TrailChef Utensils</td>\n      <td>Spoon, fork and knife set made of a light yet ...</td>\n      <td>P10CE1CG1.jpg</td>\n      <td>2011-02-15</td>\n      <td>10.0000</td>\n      <td>0.4000</td>\n      <td>EN</td>\n      <td>10.4000</td>\n      <td>1</td>\n      <td>Camping Equipment</td>\n      <td>1</td>\n      <td>Cooking Gear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100</td>\n      <td>Insect Bite Relief</td>\n      <td>The Insect Bite Relief helps the itching and s...</td>\n      <td>P100OP4FA17.jpg</td>\n      <td>2011-02-15</td>\n      <td>3.0000</td>\n      <td>0.5000</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>101</td>\n      <td>Hailstorm Steel Irons</td>\n      <td>Iron is 17-4 stainless steel.  Shafts are grap...</td>\n      <td>P101GE5IR18.jpg</td>\n      <td>2019-12-15</td>\n      <td>305.5400</td>\n      <td>0.4300</td>\n      <td>EN</td>\n      <td>305.9700</td>\n      <td>5</td>\n      <td>Golf Equipment</td>\n      <td>18</td>\n      <td>Irons</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>102</td>\n      <td>Hailstorm Titanium Irons</td>\n      <td>Made entirely of pure titanium. The ultimate i...</td>\n      <td>P102GE5IR18.jpg</td>\n      <td>2019-10-12</td>\n      <td>380.9500</td>\n      <td>0.5100</td>\n      <td>EN</td>\n      <td>381.4600</td>\n      <td>5</td>\n      <td>Golf Equipment</td>\n      <td>18</td>\n      <td>Irons</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>111</td>\n      <td>95</td>\n      <td>Sun Shield</td>\n      <td>PABA free sunscreen, SPF 30, poison oak and iv...</td>\n      <td>P91OP4SS16.jpg</td>\n      <td>2011-02-15</td>\n      <td>3.0000</td>\n      <td>0.5000</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>16</td>\n      <td>Sunscreen</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>112</td>\n      <td>96</td>\n      <td>Compact Relief Kit</td>\n      <td>A personal first aid kit is recommended for ev...</td>\n      <td>P96OP4FA17.jpg</td>\n      <td>2011-02-15</td>\n      <td>16.4300</td>\n      <td>0.2800</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>113</td>\n      <td>97</td>\n      <td>Deluxe Family Relief Kit</td>\n      <td>A complete medical kit suitable for families w...</td>\n      <td>P96OP4FA17.jpg</td>\n      <td>2013-05-03</td>\n      <td>25.0000</td>\n      <td>0.2800</td>\n      <td>EN</td>\n      <td>25.2800</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>114</td>\n      <td>98</td>\n      <td>Calamine Relief</td>\n      <td>Use the Calamine Relief for allergic skin reac...</td>\n      <td>P98OP4FA17.jpg</td>\n      <td>2011-02-15</td>\n      <td>3.0000</td>\n      <td>0.5000</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>115</td>\n      <td>99</td>\n      <td>Aloe Relief</td>\n      <td>Perfect for minor burns and sunburn, the aloe ...</td>\n      <td>P99OP4FA17.jpg</td>\n      <td>2011-02-15</td>\n      <td>2.0000</td>\n      <td>0.6000</td>\n      <td>EN</td>\n      <td>2.6000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n    </tr>\n  </tbody>\n</table>\n<p>115 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.864779Z",
     "start_time": "2024-04-16T08:35:54.497984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "order_details_query = \"SELECT * FROM Order_details\"\n",
    "\n",
    "order_details_result = export_cursor.execute(order_details_query)\n",
    "order_details_fetch = order_details_result.fetchall()\n",
    "order_details_columns = [column[0] for column in order_details_result.description]\n",
    "order_details = pd.DataFrame.from_records(order_details_fetch, columns=order_details_columns)\n",
    "\n",
    "# Dropping current_value and last_updated columns\n",
    "order_details = order_details.drop(columns=['CURRENT_VALUE', 'LAST_UPDATED'])\n",
    "\n",
    "order_details"
   ],
   "id": "befb700cc9170cb5",
   "outputs": [
    {
     "data": {
      "text/plain": "       ORDER_DETAILS_SK  ORDER_DETAILS_code  ORDER_DETAILS_QUANTITY_quantity  \\\n0                     1              100000                               16   \n1                     2              100001                               20   \n2                     3              100002                               24   \n3                     4              100003                               18   \n4                     5              100004                               20   \n...                 ...                 ...                              ...   \n43058             43059               99995                              146   \n43059             43060               99996                              172   \n43060             43061               99997                              192   \n43061             43062               99998                              192   \n43062             43063               99999                               22   \n\n      ORDER_DETAILS_TOTAL_COST_total ORDER_DETAILS_TOTAL_MARGIN_margin  \\\n0                           257.6000                          360.6400   \n1                           322.0000                          450.8000   \n2                           386.4000                          540.9600   \n3                           289.8000                          405.7200   \n4                           322.0000                          450.8000   \n...                              ...                               ...   \n43058                       402.9600                          810.3000   \n43059                       474.7200                          954.6000   \n43060                       529.9200                         1065.6000   \n43061                       529.9200                         1065.6000   \n43062                       354.2000                          495.8800   \n\n       ORDER_DETAILS_ORDER_NUMBER_order  ORDER_DETAILS_PRODUCT_NUMBER_product  \\\n0                                  4405                                   112   \n1                                  5008                                   112   \n2                                  4394                                   112   \n3                                  4396                                   112   \n4                                  4382                                   112   \n...                                 ...                                   ...   \n43058                              4402                                   111   \n43059                              4400                                   111   \n43060                              5148                                   111   \n43061                              4384                                   111   \n43062                              4383                                   112   \n\n       ORDER_DETAILS_UNIT_ID_unit  \n0                               1  \n1                               2  \n2                               3  \n3                               4  \n4                               5  \n...                           ...  \n43058                       43059  \n43059                       43060  \n43060                       43061  \n43061                       43062  \n43062                       43063  \n\n[43063 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ORDER_DETAILS_SK</th>\n      <th>ORDER_DETAILS_code</th>\n      <th>ORDER_DETAILS_QUANTITY_quantity</th>\n      <th>ORDER_DETAILS_TOTAL_COST_total</th>\n      <th>ORDER_DETAILS_TOTAL_MARGIN_margin</th>\n      <th>ORDER_DETAILS_ORDER_NUMBER_order</th>\n      <th>ORDER_DETAILS_PRODUCT_NUMBER_product</th>\n      <th>ORDER_DETAILS_UNIT_ID_unit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>100000</td>\n      <td>16</td>\n      <td>257.6000</td>\n      <td>360.6400</td>\n      <td>4405</td>\n      <td>112</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>100001</td>\n      <td>20</td>\n      <td>322.0000</td>\n      <td>450.8000</td>\n      <td>5008</td>\n      <td>112</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100002</td>\n      <td>24</td>\n      <td>386.4000</td>\n      <td>540.9600</td>\n      <td>4394</td>\n      <td>112</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>100003</td>\n      <td>18</td>\n      <td>289.8000</td>\n      <td>405.7200</td>\n      <td>4396</td>\n      <td>112</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>100004</td>\n      <td>20</td>\n      <td>322.0000</td>\n      <td>450.8000</td>\n      <td>4382</td>\n      <td>112</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43058</th>\n      <td>43059</td>\n      <td>99995</td>\n      <td>146</td>\n      <td>402.9600</td>\n      <td>810.3000</td>\n      <td>4402</td>\n      <td>111</td>\n      <td>43059</td>\n    </tr>\n    <tr>\n      <th>43059</th>\n      <td>43060</td>\n      <td>99996</td>\n      <td>172</td>\n      <td>474.7200</td>\n      <td>954.6000</td>\n      <td>4400</td>\n      <td>111</td>\n      <td>43060</td>\n    </tr>\n    <tr>\n      <th>43060</th>\n      <td>43061</td>\n      <td>99997</td>\n      <td>192</td>\n      <td>529.9200</td>\n      <td>1065.6000</td>\n      <td>5148</td>\n      <td>111</td>\n      <td>43061</td>\n    </tr>\n    <tr>\n      <th>43061</th>\n      <td>43062</td>\n      <td>99998</td>\n      <td>192</td>\n      <td>529.9200</td>\n      <td>1065.6000</td>\n      <td>4384</td>\n      <td>111</td>\n      <td>43062</td>\n    </tr>\n    <tr>\n      <th>43062</th>\n      <td>43063</td>\n      <td>99999</td>\n      <td>22</td>\n      <td>354.2000</td>\n      <td>495.8800</td>\n      <td>4383</td>\n      <td>112</td>\n      <td>43063</td>\n    </tr>\n  </tbody>\n</table>\n<p>43063 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.888768Z",
     "start_time": "2024-04-16T08:35:54.865285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "order_query = \"SELECT * FROM [Order]\"\n",
    "\n",
    "order_result = export_cursor.execute(order_query)\n",
    "order_fetch = order_result.fetchall()\n",
    "order_columns = [column[0] for column in order_result.description]\n",
    "order = pd.DataFrame.from_records(order_fetch, columns=order_columns)\n",
    "\n",
    "# Dropping current_value and last_updated columns\n",
    "order = order.drop(columns=['CURRENT_VALUE', 'LAST_UPDATED'])\n",
    "\n",
    "order"
   ],
   "id": "4bdbb90a5f947cde",
   "outputs": [
    {
     "data": {
      "text/plain": "      ORDER_SK  ORDER_order_number  ORDER_ORDER_METHOD_CODE_method_code  \\\n0            1                1153                                    7   \n1            2                1154                                    4   \n2            3                1155                                    7   \n3            4                1156                                    5   \n4            5                1157                                    2   \n...        ...                 ...                                  ...   \n5355      5356                9475                                    4   \n5356      5357                9476                                    5   \n5357      5358                9477                                    2   \n5358      5359                9478                                    7   \n5359      5360                9479                                    5   \n\n     ORDER_ORDER_METHOD_EN_method  \n0                     Sales visit  \n1                          E-mail  \n2                     Sales visit  \n3                             Web  \n4                       Telephone  \n...                           ...  \n5355                       E-mail  \n5356                          Web  \n5357                    Telephone  \n5358                  Sales visit  \n5359                          Web  \n\n[5360 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ORDER_SK</th>\n      <th>ORDER_order_number</th>\n      <th>ORDER_ORDER_METHOD_CODE_method_code</th>\n      <th>ORDER_ORDER_METHOD_EN_method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1153</td>\n      <td>7</td>\n      <td>Sales visit</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1154</td>\n      <td>4</td>\n      <td>E-mail</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1155</td>\n      <td>7</td>\n      <td>Sales visit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1156</td>\n      <td>5</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1157</td>\n      <td>2</td>\n      <td>Telephone</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5355</th>\n      <td>5356</td>\n      <td>9475</td>\n      <td>4</td>\n      <td>E-mail</td>\n    </tr>\n    <tr>\n      <th>5356</th>\n      <td>5357</td>\n      <td>9476</td>\n      <td>5</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>5357</th>\n      <td>5358</td>\n      <td>9477</td>\n      <td>2</td>\n      <td>Telephone</td>\n    </tr>\n    <tr>\n      <th>5358</th>\n      <td>5359</td>\n      <td>9478</td>\n      <td>7</td>\n      <td>Sales visit</td>\n    </tr>\n    <tr>\n      <th>5359</th>\n      <td>5360</td>\n      <td>9479</td>\n      <td>5</td>\n      <td>Web</td>\n    </tr>\n  </tbody>\n</table>\n<p>5360 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Database connectie sluiten"
   ],
   "id": "67a655400f101812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.893147Z",
     "start_time": "2024-04-16T08:35:54.889774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_cursor.close()\n",
    "export_conn.close()"
   ],
   "id": "799f9d307625f621",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tabellen samenvoegen"
   ],
   "id": "bd000112a286c2ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.945793Z",
     "start_time": "2024-04-16T08:35:54.893654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combined_data = pd.merge(order_details, product, left_on='ORDER_DETAILS_PRODUCT_NUMBER_product', right_on='PRODUCT_SK')\n",
    "combined_data = pd.merge(combined_data, order, left_on='ORDER_DETAILS_ORDER_NUMBER_order', right_on='ORDER_SK')\n",
    "\n",
    "combined_data"
   ],
   "id": "e19695aa4fe64308",
   "outputs": [
    {
     "data": {
      "text/plain": "       ORDER_DETAILS_SK  ORDER_DETAILS_code  ORDER_DETAILS_QUANTITY_quantity  \\\n0                     1              100000                               16   \n1                     2              100001                               20   \n2                     3              100002                               24   \n3                     4              100003                               18   \n4                     5              100004                               20   \n...                 ...                 ...                              ...   \n43058             43059               99995                              146   \n43059             43060               99996                              172   \n43060             43061               99997                              192   \n43061             43062               99998                              192   \n43062             43063               99999                               22   \n\n      ORDER_DETAILS_TOTAL_COST_total ORDER_DETAILS_TOTAL_MARGIN_margin  \\\n0                           257.6000                          360.6400   \n1                           322.0000                          450.8000   \n2                           386.4000                          540.9600   \n3                           289.8000                          405.7200   \n4                           322.0000                          450.8000   \n...                              ...                               ...   \n43058                       402.9600                          810.3000   \n43059                       474.7200                          954.6000   \n43060                       529.9200                         1065.6000   \n43061                       529.9200                         1065.6000   \n43062                       354.2000                          495.8800   \n\n       ORDER_DETAILS_ORDER_NUMBER_order  ORDER_DETAILS_PRODUCT_NUMBER_product  \\\n0                                  4405                                   112   \n1                                  5008                                   112   \n2                                  4394                                   112   \n3                                  4396                                   112   \n4                                  4382                                   112   \n...                                 ...                                   ...   \n43058                              4402                                   111   \n43059                              4400                                   111   \n43060                              5148                                   111   \n43061                              4384                                   111   \n43062                              4383                                   112   \n\n       ORDER_DETAILS_UNIT_ID_unit  PRODUCT_SK  PRODUCT_number  ...  \\\n0                               1         112              96  ...   \n1                               2         112              96  ...   \n2                               3         112              96  ...   \n3                               4         112              96  ...   \n4                               5         112              96  ...   \n...                           ...         ...             ...  ...   \n43058                       43059         111              95  ...   \n43059                       43060         111              95  ...   \n43060                       43061         111              95  ...   \n43061                       43062         111              95  ...   \n43062                       43063         112              96  ...   \n\n      PRODUCT_LANGUAGE_language PRODUCT_MINIMUM_SALE_PRICE_minPrice  \\\n0                            EN                             16.7100   \n1                            EN                             16.7100   \n2                            EN                             16.7100   \n3                            EN                             16.7100   \n4                            EN                             16.7100   \n...                         ...                                 ...   \n43058                        EN                              3.5000   \n43059                        EN                              3.5000   \n43060                        EN                              3.5000   \n43061                        EN                              3.5000   \n43062                        EN                             16.7100   \n\n      PRODUCT_PRODUCT_LINE_code PRODUCT_PRODUCT_LINE_code_en  \\\n0                             4           Outdoor Protection   \n1                             4           Outdoor Protection   \n2                             4           Outdoor Protection   \n3                             4           Outdoor Protection   \n4                             4           Outdoor Protection   \n...                         ...                          ...   \n43058                         4           Outdoor Protection   \n43059                         4           Outdoor Protection   \n43060                         4           Outdoor Protection   \n43061                         4           Outdoor Protection   \n43062                         4           Outdoor Protection   \n\n      PRODUCT_PRODUCT_TYPE_code PRODUCT_PRODUCT_TYPE_code_en ORDER_SK  \\\n0                            17                    First Aid     4405   \n1                            17                    First Aid     5008   \n2                            17                    First Aid     4394   \n3                            17                    First Aid     4396   \n4                            17                    First Aid     4382   \n...                         ...                          ...      ...   \n43058                        16                    Sunscreen     4402   \n43059                        16                    Sunscreen     4400   \n43060                        16                    Sunscreen     5148   \n43061                        16                    Sunscreen     4384   \n43062                        17                    First Aid     4383   \n\n      ORDER_order_number ORDER_ORDER_METHOD_CODE_method_code  \\\n0                   8462                                   5   \n1                   9111                                   2   \n2                   8451                                   2   \n3                   8453                                   7   \n4                   8439                                   7   \n...                  ...                                 ...   \n43058               8459                                   4   \n43059               8457                                   4   \n43060               9267                                   5   \n43061               8441                                   4   \n43062               8440                                   7   \n\n      ORDER_ORDER_METHOD_EN_method  \n0                              Web  \n1                        Telephone  \n2                        Telephone  \n3                      Sales visit  \n4                      Sales visit  \n...                            ...  \n43058                       E-mail  \n43059                       E-mail  \n43060                          Web  \n43061                       E-mail  \n43062                  Sales visit  \n\n[43063 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ORDER_DETAILS_SK</th>\n      <th>ORDER_DETAILS_code</th>\n      <th>ORDER_DETAILS_QUANTITY_quantity</th>\n      <th>ORDER_DETAILS_TOTAL_COST_total</th>\n      <th>ORDER_DETAILS_TOTAL_MARGIN_margin</th>\n      <th>ORDER_DETAILS_ORDER_NUMBER_order</th>\n      <th>ORDER_DETAILS_PRODUCT_NUMBER_product</th>\n      <th>ORDER_DETAILS_UNIT_ID_unit</th>\n      <th>PRODUCT_SK</th>\n      <th>PRODUCT_number</th>\n      <th>...</th>\n      <th>PRODUCT_LANGUAGE_language</th>\n      <th>PRODUCT_MINIMUM_SALE_PRICE_minPrice</th>\n      <th>PRODUCT_PRODUCT_LINE_code</th>\n      <th>PRODUCT_PRODUCT_LINE_code_en</th>\n      <th>PRODUCT_PRODUCT_TYPE_code</th>\n      <th>PRODUCT_PRODUCT_TYPE_code_en</th>\n      <th>ORDER_SK</th>\n      <th>ORDER_order_number</th>\n      <th>ORDER_ORDER_METHOD_CODE_method_code</th>\n      <th>ORDER_ORDER_METHOD_EN_method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>100000</td>\n      <td>16</td>\n      <td>257.6000</td>\n      <td>360.6400</td>\n      <td>4405</td>\n      <td>112</td>\n      <td>1</td>\n      <td>112</td>\n      <td>96</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n      <td>4405</td>\n      <td>8462</td>\n      <td>5</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>100001</td>\n      <td>20</td>\n      <td>322.0000</td>\n      <td>450.8000</td>\n      <td>5008</td>\n      <td>112</td>\n      <td>2</td>\n      <td>112</td>\n      <td>96</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n      <td>5008</td>\n      <td>9111</td>\n      <td>2</td>\n      <td>Telephone</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>100002</td>\n      <td>24</td>\n      <td>386.4000</td>\n      <td>540.9600</td>\n      <td>4394</td>\n      <td>112</td>\n      <td>3</td>\n      <td>112</td>\n      <td>96</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n      <td>4394</td>\n      <td>8451</td>\n      <td>2</td>\n      <td>Telephone</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>100003</td>\n      <td>18</td>\n      <td>289.8000</td>\n      <td>405.7200</td>\n      <td>4396</td>\n      <td>112</td>\n      <td>4</td>\n      <td>112</td>\n      <td>96</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n      <td>4396</td>\n      <td>8453</td>\n      <td>7</td>\n      <td>Sales visit</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>100004</td>\n      <td>20</td>\n      <td>322.0000</td>\n      <td>450.8000</td>\n      <td>4382</td>\n      <td>112</td>\n      <td>5</td>\n      <td>112</td>\n      <td>96</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n      <td>4382</td>\n      <td>8439</td>\n      <td>7</td>\n      <td>Sales visit</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43058</th>\n      <td>43059</td>\n      <td>99995</td>\n      <td>146</td>\n      <td>402.9600</td>\n      <td>810.3000</td>\n      <td>4402</td>\n      <td>111</td>\n      <td>43059</td>\n      <td>111</td>\n      <td>95</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>16</td>\n      <td>Sunscreen</td>\n      <td>4402</td>\n      <td>8459</td>\n      <td>4</td>\n      <td>E-mail</td>\n    </tr>\n    <tr>\n      <th>43059</th>\n      <td>43060</td>\n      <td>99996</td>\n      <td>172</td>\n      <td>474.7200</td>\n      <td>954.6000</td>\n      <td>4400</td>\n      <td>111</td>\n      <td>43060</td>\n      <td>111</td>\n      <td>95</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>16</td>\n      <td>Sunscreen</td>\n      <td>4400</td>\n      <td>8457</td>\n      <td>4</td>\n      <td>E-mail</td>\n    </tr>\n    <tr>\n      <th>43060</th>\n      <td>43061</td>\n      <td>99997</td>\n      <td>192</td>\n      <td>529.9200</td>\n      <td>1065.6000</td>\n      <td>5148</td>\n      <td>111</td>\n      <td>43061</td>\n      <td>111</td>\n      <td>95</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>16</td>\n      <td>Sunscreen</td>\n      <td>5148</td>\n      <td>9267</td>\n      <td>5</td>\n      <td>Web</td>\n    </tr>\n    <tr>\n      <th>43061</th>\n      <td>43062</td>\n      <td>99998</td>\n      <td>192</td>\n      <td>529.9200</td>\n      <td>1065.6000</td>\n      <td>4384</td>\n      <td>111</td>\n      <td>43062</td>\n      <td>111</td>\n      <td>95</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>3.5000</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>16</td>\n      <td>Sunscreen</td>\n      <td>4384</td>\n      <td>8441</td>\n      <td>4</td>\n      <td>E-mail</td>\n    </tr>\n    <tr>\n      <th>43062</th>\n      <td>43063</td>\n      <td>99999</td>\n      <td>22</td>\n      <td>354.2000</td>\n      <td>495.8800</td>\n      <td>4383</td>\n      <td>112</td>\n      <td>43063</td>\n      <td>112</td>\n      <td>96</td>\n      <td>...</td>\n      <td>EN</td>\n      <td>16.7100</td>\n      <td>4</td>\n      <td>Outdoor Protection</td>\n      <td>17</td>\n      <td>First Aid</td>\n      <td>4383</td>\n      <td>8440</td>\n      <td>7</td>\n      <td>Sales visit</td>\n    </tr>\n  </tbody>\n</table>\n<p>43063 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tabel opschonen"
   ],
   "id": "20b096cc0e0a9885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.954225Z",
     "start_time": "2024-04-16T08:35:54.946799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dropping columns\n",
    "keep_columns = ['ORDER_DETAILS_QUANTITY_quantity','PRODUCT_name_product','PRODUCT_PRODUCT_LINE_code', 'PRODUCT_PRODUCT_TYPE_code', 'ORDER_ORDER_METHOD_CODE_method_code']\n",
    "combined_data = combined_data.loc[:, keep_columns]\n",
    "\n",
    "combined_data"
   ],
   "id": "5758bc6db772ae44",
   "outputs": [
    {
     "data": {
      "text/plain": "       ORDER_DETAILS_QUANTITY_quantity PRODUCT_name_product  \\\n0                                   16   Compact Relief Kit   \n1                                   20   Compact Relief Kit   \n2                                   24   Compact Relief Kit   \n3                                   18   Compact Relief Kit   \n4                                   20   Compact Relief Kit   \n...                                ...                  ...   \n43058                              146           Sun Shield   \n43059                              172           Sun Shield   \n43060                              192           Sun Shield   \n43061                              192           Sun Shield   \n43062                               22   Compact Relief Kit   \n\n      PRODUCT_PRODUCT_LINE_code PRODUCT_PRODUCT_TYPE_code  \\\n0                             4                        17   \n1                             4                        17   \n2                             4                        17   \n3                             4                        17   \n4                             4                        17   \n...                         ...                       ...   \n43058                         4                        16   \n43059                         4                        16   \n43060                         4                        16   \n43061                         4                        16   \n43062                         4                        17   \n\n       ORDER_ORDER_METHOD_CODE_method_code  \n0                                        5  \n1                                        2  \n2                                        2  \n3                                        7  \n4                                        7  \n...                                    ...  \n43058                                    4  \n43059                                    4  \n43060                                    5  \n43061                                    4  \n43062                                    7  \n\n[43063 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ORDER_DETAILS_QUANTITY_quantity</th>\n      <th>PRODUCT_name_product</th>\n      <th>PRODUCT_PRODUCT_LINE_code</th>\n      <th>PRODUCT_PRODUCT_TYPE_code</th>\n      <th>ORDER_ORDER_METHOD_CODE_method_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>Compact Relief Kit</td>\n      <td>4</td>\n      <td>17</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>Compact Relief Kit</td>\n      <td>4</td>\n      <td>17</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24</td>\n      <td>Compact Relief Kit</td>\n      <td>4</td>\n      <td>17</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>Compact Relief Kit</td>\n      <td>4</td>\n      <td>17</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20</td>\n      <td>Compact Relief Kit</td>\n      <td>4</td>\n      <td>17</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43058</th>\n      <td>146</td>\n      <td>Sun Shield</td>\n      <td>4</td>\n      <td>16</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>43059</th>\n      <td>172</td>\n      <td>Sun Shield</td>\n      <td>4</td>\n      <td>16</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>43060</th>\n      <td>192</td>\n      <td>Sun Shield</td>\n      <td>4</td>\n      <td>16</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>43061</th>\n      <td>192</td>\n      <td>Sun Shield</td>\n      <td>4</td>\n      <td>16</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>43062</th>\n      <td>22</td>\n      <td>Compact Relief Kit</td>\n      <td>4</td>\n      <td>17</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>43063 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data voorbereiden\n",
    "data omzetten naar bruikbare data voor het neurale netwerk"
   ],
   "id": "53bed562bf32451e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.967490Z",
     "start_time": "2024-04-16T08:35:54.955733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# encoding PRODUCT_name_product. Cannot use dummy encoding since there are too many unique values and only one value per row\n",
    "combined_data['PRODUCT_name_product'] = combined_data['PRODUCT_name_product'].astype('category').cat.codes.astype('int32')\n",
    "\n",
    "# turning everything into int32\n",
    "combined_data['PRODUCT_PRODUCT_LINE_code'] = combined_data['PRODUCT_PRODUCT_LINE_code'].astype('int32')\n",
    "combined_data['ORDER_DETAILS_QUANTITY_quantity'] = combined_data['ORDER_DETAILS_QUANTITY_quantity'].astype('int32')\n",
    "combined_data['PRODUCT_PRODUCT_TYPE_code'] = combined_data['PRODUCT_PRODUCT_TYPE_code'].astype('int32')\n",
    "combined_data['ORDER_ORDER_METHOD_CODE_method_code'] = combined_data['ORDER_ORDER_METHOD_CODE_method_code'].astype('int32')\n",
    "\n",
    "combined_data.dtypes"
   ],
   "id": "793f995955e19cc6",
   "outputs": [
    {
     "data": {
      "text/plain": "ORDER_DETAILS_QUANTITY_quantity        int32\nPRODUCT_name_product                   int32\nPRODUCT_PRODUCT_LINE_code              int32\nPRODUCT_PRODUCT_TYPE_code              int32\nORDER_ORDER_METHOD_CODE_method_code    int32\ndtype: object"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data splitsen"
   ],
   "id": "bbbad953f317df3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.974737Z",
     "start_time": "2024-04-16T08:35:54.968499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# splitting the data in x and y\n",
    "X = combined_data.drop(columns=['ORDER_DETAILS_QUANTITY_quantity'])\n",
    "y = combined_data['ORDER_DETAILS_QUANTITY_quantity']\n",
    "\n",
    "# splitting the data in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# printing the sizes\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}')"
   ],
   "id": "fa509d1f95121d7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (34450, 4), X_test: (8613, 4), y_train: (34450,), y_test: (8613,)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:54.977875Z",
     "start_time": "2024-04-16T08:35:54.975745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# defining the amount of epochs and batch size\n",
    "epochs = 500\n",
    "batch_size = 50"
   ],
   "id": "df076df46f518602",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tensorflow + keras\n",
    "neural network using keras"
   ],
   "id": "972a75e03a4e5f56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model maken"
   ],
   "id": "8f196004ce8d7cd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:35:55.070551Z",
     "start_time": "2024-04-16T08:35:54.978881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# getting the amount of columns in order_details\n",
    "amount_of_columns = len(combined_data.columns)-1 # needs -1 since one of the columns is the target column. Should be 4\n",
    "\n",
    "# the model\n",
    "model = Sequential()\n",
    "\n",
    "# input layer, 4 nodes\n",
    "model.add(Input(shape=(amount_of_columns,)))\n",
    "\n",
    "# 1 hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(24, activation='relu'))\n",
    "\n",
    "# output layer, 1 node\n",
    "model.add(Dense(1, activation='linear')) # linear since we are predicting a number\n",
    "\n",
    "# compile the model, so we can get metrics\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error', 'mean_squared_logarithmic_error']) # adam uses gradient descent, doesnt seem to be able to use non-gradient descent based optimizer"
   ],
   "id": "c67dc4f2efa7edfb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model trainen"
   ],
   "id": "cc24e810f4e5c433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:39:45.066470Z",
     "start_time": "2024-04-16T08:35:55.072570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size) # batch size: after how many samples the weights are updated"
   ],
   "id": "7b59494ded1eefb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 495us/step - loss: 4248.2124 - mean_absolute_error: 38.1960 - mean_squared_logarithmic_error: 1.6311\n",
      "Epoch 2/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 3850.6567 - mean_absolute_error: 35.6809 - mean_squared_logarithmic_error: 0.9404\n",
      "Epoch 3/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 3397.8127 - mean_absolute_error: 33.5779 - mean_squared_logarithmic_error: 0.8420\n",
      "Epoch 4/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - loss: 3079.1936 - mean_absolute_error: 32.6767 - mean_squared_logarithmic_error: 0.7941\n",
      "Epoch 5/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 3593.7061 - mean_absolute_error: 32.9340 - mean_squared_logarithmic_error: 0.7706\n",
      "Epoch 6/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 3124.9663 - mean_absolute_error: 32.5127 - mean_squared_logarithmic_error: 0.7968\n",
      "Epoch 7/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 3183.8845 - mean_absolute_error: 32.5058 - mean_squared_logarithmic_error: 0.7552\n",
      "Epoch 8/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 3371.0327 - mean_absolute_error: 32.3265 - mean_squared_logarithmic_error: 0.7609\n",
      "Epoch 9/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 3085.4094 - mean_absolute_error: 31.2272 - mean_squared_logarithmic_error: 0.7457\n",
      "Epoch 10/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 3052.7590 - mean_absolute_error: 31.4684 - mean_squared_logarithmic_error: 0.7420\n",
      "Epoch 11/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 3077.5842 - mean_absolute_error: 31.2830 - mean_squared_logarithmic_error: 0.7426\n",
      "Epoch 12/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 3213.7043 - mean_absolute_error: 31.9595 - mean_squared_logarithmic_error: 0.7800\n",
      "Epoch 13/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 501us/step - loss: 2915.8176 - mean_absolute_error: 31.2700 - mean_squared_logarithmic_error: 0.7546\n",
      "Epoch 14/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 3028.0781 - mean_absolute_error: 31.2538 - mean_squared_logarithmic_error: 0.7511\n",
      "Epoch 15/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 3104.0127 - mean_absolute_error: 31.1353 - mean_squared_logarithmic_error: 0.7417\n",
      "Epoch 16/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 3056.1394 - mean_absolute_error: 31.0886 - mean_squared_logarithmic_error: 0.7483\n",
      "Epoch 17/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 3123.3877 - mean_absolute_error: 31.3869 - mean_squared_logarithmic_error: 0.7513\n",
      "Epoch 18/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - loss: 2683.6267 - mean_absolute_error: 30.2397 - mean_squared_logarithmic_error: 0.7361\n",
      "Epoch 19/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 3118.3420 - mean_absolute_error: 31.1835 - mean_squared_logarithmic_error: 0.7452\n",
      "Epoch 20/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 3098.2546 - mean_absolute_error: 31.4298 - mean_squared_logarithmic_error: 0.7399\n",
      "Epoch 21/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2940.0439 - mean_absolute_error: 30.5370 - mean_squared_logarithmic_error: 0.7158\n",
      "Epoch 22/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2892.4978 - mean_absolute_error: 30.3797 - mean_squared_logarithmic_error: 0.7239\n",
      "Epoch 23/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2882.6938 - mean_absolute_error: 30.6402 - mean_squared_logarithmic_error: 0.7467\n",
      "Epoch 24/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 533us/step - loss: 2986.5649 - mean_absolute_error: 30.6751 - mean_squared_logarithmic_error: 0.7029\n",
      "Epoch 25/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 2806.6997 - mean_absolute_error: 30.2517 - mean_squared_logarithmic_error: 0.7110\n",
      "Epoch 26/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 3079.2441 - mean_absolute_error: 30.8669 - mean_squared_logarithmic_error: 0.7110\n",
      "Epoch 27/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 483us/step - loss: 2893.9080 - mean_absolute_error: 30.5419 - mean_squared_logarithmic_error: 0.6950\n",
      "Epoch 28/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 3071.8159 - mean_absolute_error: 30.7308 - mean_squared_logarithmic_error: 0.6981\n",
      "Epoch 29/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - loss: 3126.4116 - mean_absolute_error: 31.1733 - mean_squared_logarithmic_error: 0.7013\n",
      "Epoch 30/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 2839.0310 - mean_absolute_error: 30.0426 - mean_squared_logarithmic_error: 0.6707\n",
      "Epoch 31/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2903.8022 - mean_absolute_error: 30.3625 - mean_squared_logarithmic_error: 0.6730\n",
      "Epoch 32/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - loss: 3041.9976 - mean_absolute_error: 30.3565 - mean_squared_logarithmic_error: 0.6557\n",
      "Epoch 33/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 2717.8198 - mean_absolute_error: 29.5330 - mean_squared_logarithmic_error: 0.6369\n",
      "Epoch 34/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 518us/step - loss: 2769.2214 - mean_absolute_error: 29.8967 - mean_squared_logarithmic_error: 0.6387\n",
      "Epoch 35/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 3222.2947 - mean_absolute_error: 30.8126 - mean_squared_logarithmic_error: 0.6580\n",
      "Epoch 36/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 3120.7546 - mean_absolute_error: 30.6758 - mean_squared_logarithmic_error: 0.6357\n",
      "Epoch 37/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 2950.1135 - mean_absolute_error: 30.0228 - mean_squared_logarithmic_error: 0.6222\n",
      "Epoch 38/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - loss: 2796.1975 - mean_absolute_error: 29.3580 - mean_squared_logarithmic_error: 0.6075\n",
      "Epoch 39/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 2855.1404 - mean_absolute_error: 29.7157 - mean_squared_logarithmic_error: 0.6218\n",
      "Epoch 40/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2987.0928 - mean_absolute_error: 29.8700 - mean_squared_logarithmic_error: 0.6158\n",
      "Epoch 41/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - loss: 2921.0129 - mean_absolute_error: 29.7796 - mean_squared_logarithmic_error: 0.6135\n",
      "Epoch 42/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 2713.6599 - mean_absolute_error: 29.3150 - mean_squared_logarithmic_error: 0.6116\n",
      "Epoch 43/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2802.7888 - mean_absolute_error: 29.7702 - mean_squared_logarithmic_error: 0.6129\n",
      "Epoch 44/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2836.2861 - mean_absolute_error: 29.7756 - mean_squared_logarithmic_error: 0.6074\n",
      "Epoch 45/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2988.8740 - mean_absolute_error: 29.8560 - mean_squared_logarithmic_error: 0.6129\n",
      "Epoch 46/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2848.6765 - mean_absolute_error: 29.5653 - mean_squared_logarithmic_error: 0.5995\n",
      "Epoch 47/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 2667.6152 - mean_absolute_error: 29.0504 - mean_squared_logarithmic_error: 0.5893\n",
      "Epoch 48/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 501us/step - loss: 2758.8562 - mean_absolute_error: 29.3936 - mean_squared_logarithmic_error: 0.5919\n",
      "Epoch 49/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 3073.2402 - mean_absolute_error: 30.0280 - mean_squared_logarithmic_error: 0.5941\n",
      "Epoch 50/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 2946.4695 - mean_absolute_error: 29.6792 - mean_squared_logarithmic_error: 0.5935\n",
      "Epoch 51/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2912.8345 - mean_absolute_error: 29.9070 - mean_squared_logarithmic_error: 0.6044\n",
      "Epoch 52/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - loss: 2885.2454 - mean_absolute_error: 29.3004 - mean_squared_logarithmic_error: 0.5803\n",
      "Epoch 53/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 497us/step - loss: 2835.9539 - mean_absolute_error: 29.2644 - mean_squared_logarithmic_error: 0.5833\n",
      "Epoch 54/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 3229.0249 - mean_absolute_error: 29.9380 - mean_squared_logarithmic_error: 0.5950\n",
      "Epoch 55/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2930.6382 - mean_absolute_error: 29.8089 - mean_squared_logarithmic_error: 0.5801\n",
      "Epoch 56/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 2776.5156 - mean_absolute_error: 29.4285 - mean_squared_logarithmic_error: 0.5874\n",
      "Epoch 57/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 2707.7058 - mean_absolute_error: 29.3000 - mean_squared_logarithmic_error: 0.5875\n",
      "Epoch 58/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 2652.2937 - mean_absolute_error: 29.0445 - mean_squared_logarithmic_error: 0.5779\n",
      "Epoch 59/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2802.1978 - mean_absolute_error: 29.3356 - mean_squared_logarithmic_error: 0.5821\n",
      "Epoch 60/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2711.7122 - mean_absolute_error: 28.8482 - mean_squared_logarithmic_error: 0.5679\n",
      "Epoch 61/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 2850.2891 - mean_absolute_error: 29.7058 - mean_squared_logarithmic_error: 0.5924\n",
      "Epoch 62/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2826.3328 - mean_absolute_error: 29.4869 - mean_squared_logarithmic_error: 0.5795\n",
      "Epoch 63/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2702.9031 - mean_absolute_error: 28.9112 - mean_squared_logarithmic_error: 0.5618\n",
      "Epoch 64/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2703.3708 - mean_absolute_error: 29.0156 - mean_squared_logarithmic_error: 0.5754\n",
      "Epoch 65/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2965.4238 - mean_absolute_error: 29.3170 - mean_squared_logarithmic_error: 0.5723\n",
      "Epoch 66/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2679.7786 - mean_absolute_error: 28.8871 - mean_squared_logarithmic_error: 0.5735\n",
      "Epoch 67/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 501us/step - loss: 3057.1777 - mean_absolute_error: 29.5714 - mean_squared_logarithmic_error: 0.5876\n",
      "Epoch 68/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 515us/step - loss: 2902.4146 - mean_absolute_error: 29.6782 - mean_squared_logarithmic_error: 0.5872\n",
      "Epoch 69/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2743.4036 - mean_absolute_error: 29.1836 - mean_squared_logarithmic_error: 0.5863\n",
      "Epoch 70/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2718.8235 - mean_absolute_error: 28.8056 - mean_squared_logarithmic_error: 0.5651\n",
      "Epoch 71/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2771.9192 - mean_absolute_error: 29.3015 - mean_squared_logarithmic_error: 0.5804\n",
      "Epoch 72/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 511us/step - loss: 2866.3977 - mean_absolute_error: 29.4050 - mean_squared_logarithmic_error: 0.5782\n",
      "Epoch 73/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2926.8291 - mean_absolute_error: 29.2716 - mean_squared_logarithmic_error: 0.5683\n",
      "Epoch 74/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2708.6294 - mean_absolute_error: 28.7657 - mean_squared_logarithmic_error: 0.5592\n",
      "Epoch 75/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2985.3506 - mean_absolute_error: 29.1072 - mean_squared_logarithmic_error: 0.5721\n",
      "Epoch 76/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2832.0132 - mean_absolute_error: 29.0931 - mean_squared_logarithmic_error: 0.5708\n",
      "Epoch 77/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2736.9766 - mean_absolute_error: 28.8755 - mean_squared_logarithmic_error: 0.5590\n",
      "Epoch 78/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 506us/step - loss: 2521.5249 - mean_absolute_error: 28.4798 - mean_squared_logarithmic_error: 0.5614\n",
      "Epoch 79/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2676.5583 - mean_absolute_error: 28.8259 - mean_squared_logarithmic_error: 0.5697\n",
      "Epoch 80/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2899.5994 - mean_absolute_error: 29.1369 - mean_squared_logarithmic_error: 0.5796\n",
      "Epoch 81/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 505us/step - loss: 2669.4290 - mean_absolute_error: 28.9060 - mean_squared_logarithmic_error: 0.5595\n",
      "Epoch 82/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2705.8601 - mean_absolute_error: 28.9627 - mean_squared_logarithmic_error: 0.5664\n",
      "Epoch 83/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 505us/step - loss: 2867.3284 - mean_absolute_error: 29.1294 - mean_squared_logarithmic_error: 0.5717\n",
      "Epoch 84/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 526us/step - loss: 2662.6433 - mean_absolute_error: 29.0706 - mean_squared_logarithmic_error: 0.5798\n",
      "Epoch 85/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2938.5518 - mean_absolute_error: 29.5260 - mean_squared_logarithmic_error: 0.5745\n",
      "Epoch 86/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 3289.7332 - mean_absolute_error: 29.8374 - mean_squared_logarithmic_error: 0.5729\n",
      "Epoch 87/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 510us/step - loss: 2849.3774 - mean_absolute_error: 29.2271 - mean_squared_logarithmic_error: 0.5723\n",
      "Epoch 88/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2854.7737 - mean_absolute_error: 28.8056 - mean_squared_logarithmic_error: 0.5697\n",
      "Epoch 89/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 504us/step - loss: 2737.6577 - mean_absolute_error: 28.9640 - mean_squared_logarithmic_error: 0.5667\n",
      "Epoch 90/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step - loss: 2619.9414 - mean_absolute_error: 28.6774 - mean_squared_logarithmic_error: 0.5632\n",
      "Epoch 91/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2588.5674 - mean_absolute_error: 28.3076 - mean_squared_logarithmic_error: 0.5487\n",
      "Epoch 92/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2937.3821 - mean_absolute_error: 29.4350 - mean_squared_logarithmic_error: 0.5688\n",
      "Epoch 93/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 501us/step - loss: 2609.0554 - mean_absolute_error: 28.6073 - mean_squared_logarithmic_error: 0.5594\n",
      "Epoch 94/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 504us/step - loss: 2633.3809 - mean_absolute_error: 28.5611 - mean_squared_logarithmic_error: 0.5586\n",
      "Epoch 95/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 513us/step - loss: 2823.0247 - mean_absolute_error: 29.0811 - mean_squared_logarithmic_error: 0.5675\n",
      "Epoch 96/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2712.5535 - mean_absolute_error: 28.6181 - mean_squared_logarithmic_error: 0.5506\n",
      "Epoch 97/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2666.3105 - mean_absolute_error: 28.7380 - mean_squared_logarithmic_error: 0.5696\n",
      "Epoch 98/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2740.0667 - mean_absolute_error: 28.7465 - mean_squared_logarithmic_error: 0.5463\n",
      "Epoch 99/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2771.7217 - mean_absolute_error: 28.3982 - mean_squared_logarithmic_error: 0.5521\n",
      "Epoch 100/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2681.1577 - mean_absolute_error: 28.3253 - mean_squared_logarithmic_error: 0.5506\n",
      "Epoch 101/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2614.0374 - mean_absolute_error: 28.1693 - mean_squared_logarithmic_error: 0.5514\n",
      "Epoch 102/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2989.0701 - mean_absolute_error: 29.4315 - mean_squared_logarithmic_error: 0.5797\n",
      "Epoch 103/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2963.9485 - mean_absolute_error: 28.9983 - mean_squared_logarithmic_error: 0.5860\n",
      "Epoch 104/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 2846.7341 - mean_absolute_error: 28.7315 - mean_squared_logarithmic_error: 0.5596\n",
      "Epoch 105/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 484us/step - loss: 2799.1855 - mean_absolute_error: 29.1226 - mean_squared_logarithmic_error: 0.5674\n",
      "Epoch 106/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - loss: 2809.4663 - mean_absolute_error: 28.8820 - mean_squared_logarithmic_error: 0.5584\n",
      "Epoch 107/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2979.0808 - mean_absolute_error: 29.3861 - mean_squared_logarithmic_error: 0.5763\n",
      "Epoch 108/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 483us/step - loss: 2700.0964 - mean_absolute_error: 28.4190 - mean_squared_logarithmic_error: 0.5560\n",
      "Epoch 109/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2605.6372 - mean_absolute_error: 28.3074 - mean_squared_logarithmic_error: 0.5413\n",
      "Epoch 110/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2831.6304 - mean_absolute_error: 28.6518 - mean_squared_logarithmic_error: 0.5575\n",
      "Epoch 111/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - loss: 2803.5344 - mean_absolute_error: 28.8367 - mean_squared_logarithmic_error: 0.5752\n",
      "Epoch 112/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 2830.1775 - mean_absolute_error: 28.9022 - mean_squared_logarithmic_error: 0.5545\n",
      "Epoch 113/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2820.3699 - mean_absolute_error: 28.7870 - mean_squared_logarithmic_error: 0.5626\n",
      "Epoch 114/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2896.2400 - mean_absolute_error: 28.7596 - mean_squared_logarithmic_error: 0.5471\n",
      "Epoch 115/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 505us/step - loss: 2686.0608 - mean_absolute_error: 28.7952 - mean_squared_logarithmic_error: 0.5543\n",
      "Epoch 116/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 2894.4512 - mean_absolute_error: 29.1739 - mean_squared_logarithmic_error: 0.5622\n",
      "Epoch 117/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 2979.1882 - mean_absolute_error: 29.0788 - mean_squared_logarithmic_error: 0.5612\n",
      "Epoch 118/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 2719.2119 - mean_absolute_error: 28.5189 - mean_squared_logarithmic_error: 0.5633\n",
      "Epoch 119/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2898.4585 - mean_absolute_error: 29.0210 - mean_squared_logarithmic_error: 0.5601\n",
      "Epoch 120/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 2940.4912 - mean_absolute_error: 28.8507 - mean_squared_logarithmic_error: 0.5547\n",
      "Epoch 121/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2967.3889 - mean_absolute_error: 28.9455 - mean_squared_logarithmic_error: 0.5583\n",
      "Epoch 122/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2900.3828 - mean_absolute_error: 29.1933 - mean_squared_logarithmic_error: 0.5605\n",
      "Epoch 123/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2834.5752 - mean_absolute_error: 29.0831 - mean_squared_logarithmic_error: 0.5664\n",
      "Epoch 124/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2827.1426 - mean_absolute_error: 28.8830 - mean_squared_logarithmic_error: 0.5450\n",
      "Epoch 125/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 505us/step - loss: 2677.8291 - mean_absolute_error: 28.5908 - mean_squared_logarithmic_error: 0.5589\n",
      "Epoch 126/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2611.8428 - mean_absolute_error: 28.1539 - mean_squared_logarithmic_error: 0.5451\n",
      "Epoch 127/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2713.1013 - mean_absolute_error: 28.5238 - mean_squared_logarithmic_error: 0.5460\n",
      "Epoch 128/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2719.4763 - mean_absolute_error: 28.4794 - mean_squared_logarithmic_error: 0.5528\n",
      "Epoch 129/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2751.3523 - mean_absolute_error: 28.7778 - mean_squared_logarithmic_error: 0.5695\n",
      "Epoch 130/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2776.3015 - mean_absolute_error: 28.6773 - mean_squared_logarithmic_error: 0.5431\n",
      "Epoch 131/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 504us/step - loss: 2879.0422 - mean_absolute_error: 28.9125 - mean_squared_logarithmic_error: 0.5651\n",
      "Epoch 132/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - loss: 2910.5574 - mean_absolute_error: 28.6356 - mean_squared_logarithmic_error: 0.5440\n",
      "Epoch 133/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 483us/step - loss: 2846.0322 - mean_absolute_error: 28.7245 - mean_squared_logarithmic_error: 0.5464\n",
      "Epoch 134/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2688.0488 - mean_absolute_error: 28.4354 - mean_squared_logarithmic_error: 0.5428\n",
      "Epoch 135/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2756.0776 - mean_absolute_error: 28.4416 - mean_squared_logarithmic_error: 0.5452\n",
      "Epoch 136/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 523us/step - loss: 2659.9321 - mean_absolute_error: 28.3449 - mean_squared_logarithmic_error: 0.5364\n",
      "Epoch 137/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2713.2051 - mean_absolute_error: 28.7824 - mean_squared_logarithmic_error: 0.5454\n",
      "Epoch 138/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step - loss: 2700.1033 - mean_absolute_error: 28.4110 - mean_squared_logarithmic_error: 0.5446\n",
      "Epoch 139/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 495us/step - loss: 2892.4832 - mean_absolute_error: 28.2882 - mean_squared_logarithmic_error: 0.5468\n",
      "Epoch 140/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 523us/step - loss: 2668.3254 - mean_absolute_error: 28.1581 - mean_squared_logarithmic_error: 0.5422\n",
      "Epoch 141/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - loss: 2853.8433 - mean_absolute_error: 28.3346 - mean_squared_logarithmic_error: 0.5418\n",
      "Epoch 142/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 504us/step - loss: 2815.9702 - mean_absolute_error: 28.4767 - mean_squared_logarithmic_error: 0.5424\n",
      "Epoch 143/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 500us/step - loss: 2769.7742 - mean_absolute_error: 28.6495 - mean_squared_logarithmic_error: 0.5487\n",
      "Epoch 144/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step - loss: 2603.9343 - mean_absolute_error: 27.9631 - mean_squared_logarithmic_error: 0.5335\n",
      "Epoch 145/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 2968.9351 - mean_absolute_error: 28.9864 - mean_squared_logarithmic_error: 0.5585\n",
      "Epoch 146/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2816.9497 - mean_absolute_error: 28.7327 - mean_squared_logarithmic_error: 0.5333\n",
      "Epoch 147/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2729.9670 - mean_absolute_error: 28.6636 - mean_squared_logarithmic_error: 0.5426\n",
      "Epoch 148/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 2831.1562 - mean_absolute_error: 28.7414 - mean_squared_logarithmic_error: 0.5467\n",
      "Epoch 149/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - loss: 2732.2246 - mean_absolute_error: 28.5392 - mean_squared_logarithmic_error: 0.5483\n",
      "Epoch 150/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - loss: 2613.2622 - mean_absolute_error: 28.3416 - mean_squared_logarithmic_error: 0.5378\n",
      "Epoch 151/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2766.7495 - mean_absolute_error: 28.5306 - mean_squared_logarithmic_error: 0.5640\n",
      "Epoch 152/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2794.3748 - mean_absolute_error: 28.7343 - mean_squared_logarithmic_error: 0.5543\n",
      "Epoch 153/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2798.3687 - mean_absolute_error: 28.3233 - mean_squared_logarithmic_error: 0.5469\n",
      "Epoch 154/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2618.6106 - mean_absolute_error: 28.4501 - mean_squared_logarithmic_error: 0.5459\n",
      "Epoch 155/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 2815.0488 - mean_absolute_error: 28.6815 - mean_squared_logarithmic_error: 0.5457\n",
      "Epoch 156/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2490.0103 - mean_absolute_error: 27.8797 - mean_squared_logarithmic_error: 0.5251\n",
      "Epoch 157/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2735.2034 - mean_absolute_error: 28.3594 - mean_squared_logarithmic_error: 0.5375\n",
      "Epoch 158/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2865.4102 - mean_absolute_error: 28.8762 - mean_squared_logarithmic_error: 0.5534\n",
      "Epoch 159/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 2730.7744 - mean_absolute_error: 28.7246 - mean_squared_logarithmic_error: 0.5485\n",
      "Epoch 160/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2755.2478 - mean_absolute_error: 28.5449 - mean_squared_logarithmic_error: 0.5424\n",
      "Epoch 161/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 2762.2615 - mean_absolute_error: 28.3736 - mean_squared_logarithmic_error: 0.5453\n",
      "Epoch 162/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2761.1963 - mean_absolute_error: 28.5566 - mean_squared_logarithmic_error: 0.5425\n",
      "Epoch 163/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2519.0945 - mean_absolute_error: 27.8049 - mean_squared_logarithmic_error: 0.5301\n",
      "Epoch 164/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 2868.5503 - mean_absolute_error: 29.0880 - mean_squared_logarithmic_error: 0.5364\n",
      "Epoch 165/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2721.1145 - mean_absolute_error: 28.1254 - mean_squared_logarithmic_error: 0.5348\n",
      "Epoch 166/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2703.8591 - mean_absolute_error: 28.2451 - mean_squared_logarithmic_error: 0.5414\n",
      "Epoch 167/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - loss: 2686.7729 - mean_absolute_error: 28.1867 - mean_squared_logarithmic_error: 0.5405\n",
      "Epoch 168/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - loss: 3005.9963 - mean_absolute_error: 28.8472 - mean_squared_logarithmic_error: 0.5544\n",
      "Epoch 169/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 488us/step - loss: 2778.7095 - mean_absolute_error: 28.6982 - mean_squared_logarithmic_error: 0.5430\n",
      "Epoch 170/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 490us/step - loss: 2763.7798 - mean_absolute_error: 28.5850 - mean_squared_logarithmic_error: 0.5472\n",
      "Epoch 171/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - loss: 2930.1936 - mean_absolute_error: 28.7402 - mean_squared_logarithmic_error: 0.5433\n",
      "Epoch 172/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 2683.6035 - mean_absolute_error: 28.4605 - mean_squared_logarithmic_error: 0.5436\n",
      "Epoch 173/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - loss: 2777.3503 - mean_absolute_error: 28.5418 - mean_squared_logarithmic_error: 0.5373\n",
      "Epoch 174/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - loss: 2546.9204 - mean_absolute_error: 27.8940 - mean_squared_logarithmic_error: 0.5282\n",
      "Epoch 175/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 516us/step - loss: 2546.8037 - mean_absolute_error: 28.0269 - mean_squared_logarithmic_error: 0.5392\n",
      "Epoch 176/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - loss: 2695.1816 - mean_absolute_error: 28.3079 - mean_squared_logarithmic_error: 0.5364\n",
      "Epoch 177/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 494us/step - loss: 3081.1184 - mean_absolute_error: 29.1037 - mean_squared_logarithmic_error: 0.5509\n",
      "Epoch 178/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 486us/step - loss: 2594.9475 - mean_absolute_error: 28.1814 - mean_squared_logarithmic_error: 0.5366\n",
      "Epoch 179/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 489us/step - loss: 2628.7859 - mean_absolute_error: 28.5775 - mean_squared_logarithmic_error: 0.5556\n",
      "Epoch 180/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 603us/step - loss: 2818.0020 - mean_absolute_error: 28.5593 - mean_squared_logarithmic_error: 0.5539\n",
      "Epoch 181/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 2583.2324 - mean_absolute_error: 28.0293 - mean_squared_logarithmic_error: 0.5383\n",
      "Epoch 182/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2810.8484 - mean_absolute_error: 28.5229 - mean_squared_logarithmic_error: 0.5531\n",
      "Epoch 183/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 731us/step - loss: 2683.2058 - mean_absolute_error: 28.1700 - mean_squared_logarithmic_error: 0.5424\n",
      "Epoch 184/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 727us/step - loss: 2634.6318 - mean_absolute_error: 28.3213 - mean_squared_logarithmic_error: 0.5250\n",
      "Epoch 185/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2773.0535 - mean_absolute_error: 28.1516 - mean_squared_logarithmic_error: 0.5531\n",
      "Epoch 186/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 692us/step - loss: 2800.9375 - mean_absolute_error: 28.0883 - mean_squared_logarithmic_error: 0.5450\n",
      "Epoch 187/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 731us/step - loss: 2858.7466 - mean_absolute_error: 28.6295 - mean_squared_logarithmic_error: 0.5307\n",
      "Epoch 188/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 719us/step - loss: 2586.6035 - mean_absolute_error: 27.9660 - mean_squared_logarithmic_error: 0.5329\n",
      "Epoch 189/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 729us/step - loss: 2711.8142 - mean_absolute_error: 28.5110 - mean_squared_logarithmic_error: 0.5493\n",
      "Epoch 190/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 767us/step - loss: 2617.5623 - mean_absolute_error: 27.7593 - mean_squared_logarithmic_error: 0.5345\n",
      "Epoch 191/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 701us/step - loss: 2675.7732 - mean_absolute_error: 28.1834 - mean_squared_logarithmic_error: 0.5339\n",
      "Epoch 192/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 2676.4390 - mean_absolute_error: 28.2588 - mean_squared_logarithmic_error: 0.5456\n",
      "Epoch 193/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2855.8474 - mean_absolute_error: 29.0852 - mean_squared_logarithmic_error: 0.5569\n",
      "Epoch 194/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 757us/step - loss: 2874.1924 - mean_absolute_error: 28.3101 - mean_squared_logarithmic_error: 0.5340\n",
      "Epoch 195/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 741us/step - loss: 2746.4868 - mean_absolute_error: 28.1805 - mean_squared_logarithmic_error: 0.5297\n",
      "Epoch 196/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 753us/step - loss: 2487.1982 - mean_absolute_error: 27.7471 - mean_squared_logarithmic_error: 0.5336\n",
      "Epoch 197/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 718us/step - loss: 2608.3159 - mean_absolute_error: 28.4172 - mean_squared_logarithmic_error: 0.5323\n",
      "Epoch 198/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 763us/step - loss: 2758.5696 - mean_absolute_error: 28.3964 - mean_squared_logarithmic_error: 0.5405\n",
      "Epoch 199/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 711us/step - loss: 2813.7224 - mean_absolute_error: 28.5506 - mean_squared_logarithmic_error: 0.5471\n",
      "Epoch 200/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 760us/step - loss: 2948.8879 - mean_absolute_error: 28.3328 - mean_squared_logarithmic_error: 0.5423\n",
      "Epoch 201/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 726us/step - loss: 2629.5247 - mean_absolute_error: 28.3768 - mean_squared_logarithmic_error: 0.5363\n",
      "Epoch 202/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 775us/step - loss: 2916.2961 - mean_absolute_error: 28.7160 - mean_squared_logarithmic_error: 0.5540\n",
      "Epoch 203/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 731us/step - loss: 2768.9937 - mean_absolute_error: 28.8602 - mean_squared_logarithmic_error: 0.5429\n",
      "Epoch 204/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 842us/step - loss: 2673.7271 - mean_absolute_error: 28.3512 - mean_squared_logarithmic_error: 0.5402\n",
      "Epoch 205/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 749us/step - loss: 2787.1323 - mean_absolute_error: 28.7430 - mean_squared_logarithmic_error: 0.5357\n",
      "Epoch 206/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 856us/step - loss: 2710.5813 - mean_absolute_error: 28.1443 - mean_squared_logarithmic_error: 0.5348\n",
      "Epoch 207/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 842us/step - loss: 2840.0239 - mean_absolute_error: 28.5266 - mean_squared_logarithmic_error: 0.5447\n",
      "Epoch 208/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 887us/step - loss: 2652.1011 - mean_absolute_error: 28.0495 - mean_squared_logarithmic_error: 0.5391\n",
      "Epoch 209/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 847us/step - loss: 2795.1670 - mean_absolute_error: 28.4007 - mean_squared_logarithmic_error: 0.5478\n",
      "Epoch 210/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 724us/step - loss: 2699.7708 - mean_absolute_error: 28.5248 - mean_squared_logarithmic_error: 0.5482\n",
      "Epoch 211/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 723us/step - loss: 2631.7021 - mean_absolute_error: 27.9259 - mean_squared_logarithmic_error: 0.5405\n",
      "Epoch 212/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 2702.6128 - mean_absolute_error: 28.1503 - mean_squared_logarithmic_error: 0.5337\n",
      "Epoch 213/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 749us/step - loss: 2580.1094 - mean_absolute_error: 28.1315 - mean_squared_logarithmic_error: 0.5363\n",
      "Epoch 214/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 744us/step - loss: 2661.0547 - mean_absolute_error: 28.0872 - mean_squared_logarithmic_error: 0.5301\n",
      "Epoch 215/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 699us/step - loss: 2663.7715 - mean_absolute_error: 28.3647 - mean_squared_logarithmic_error: 0.5360\n",
      "Epoch 216/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 2846.6790 - mean_absolute_error: 29.0076 - mean_squared_logarithmic_error: 0.5550\n",
      "Epoch 217/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 2865.0593 - mean_absolute_error: 28.7280 - mean_squared_logarithmic_error: 0.5391\n",
      "Epoch 218/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 717us/step - loss: 3100.7300 - mean_absolute_error: 28.8344 - mean_squared_logarithmic_error: 0.5498\n",
      "Epoch 219/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 693us/step - loss: 2770.9480 - mean_absolute_error: 28.5642 - mean_squared_logarithmic_error: 0.5397\n",
      "Epoch 220/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 616us/step - loss: 2744.2227 - mean_absolute_error: 28.2690 - mean_squared_logarithmic_error: 0.5312\n",
      "Epoch 221/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 2754.9255 - mean_absolute_error: 28.0687 - mean_squared_logarithmic_error: 0.5301\n",
      "Epoch 222/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 861us/step - loss: 2807.4407 - mean_absolute_error: 28.6672 - mean_squared_logarithmic_error: 0.5425\n",
      "Epoch 223/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 817us/step - loss: 2718.1260 - mean_absolute_error: 28.2074 - mean_squared_logarithmic_error: 0.5360\n",
      "Epoch 224/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 819us/step - loss: 2714.1375 - mean_absolute_error: 28.4617 - mean_squared_logarithmic_error: 0.5330\n",
      "Epoch 225/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 747us/step - loss: 2752.3894 - mean_absolute_error: 28.3323 - mean_squared_logarithmic_error: 0.5406\n",
      "Epoch 226/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 2926.4268 - mean_absolute_error: 28.4045 - mean_squared_logarithmic_error: 0.5411\n",
      "Epoch 227/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 693us/step - loss: 2919.3013 - mean_absolute_error: 28.5888 - mean_squared_logarithmic_error: 0.5415\n",
      "Epoch 228/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 2659.0393 - mean_absolute_error: 28.2034 - mean_squared_logarithmic_error: 0.5287\n",
      "Epoch 229/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 712us/step - loss: 2658.6152 - mean_absolute_error: 28.2326 - mean_squared_logarithmic_error: 0.5275\n",
      "Epoch 230/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 2705.9956 - mean_absolute_error: 28.1428 - mean_squared_logarithmic_error: 0.5409\n",
      "Epoch 231/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step - loss: 2823.0747 - mean_absolute_error: 28.4794 - mean_squared_logarithmic_error: 0.5469\n",
      "Epoch 232/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2746.2571 - mean_absolute_error: 28.1557 - mean_squared_logarithmic_error: 0.5340\n",
      "Epoch 233/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 2631.1335 - mean_absolute_error: 28.5762 - mean_squared_logarithmic_error: 0.5374\n",
      "Epoch 234/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 706us/step - loss: 3219.2212 - mean_absolute_error: 28.7024 - mean_squared_logarithmic_error: 0.5328\n",
      "Epoch 235/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 701us/step - loss: 2975.2883 - mean_absolute_error: 28.4585 - mean_squared_logarithmic_error: 0.5320\n",
      "Epoch 236/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2562.1682 - mean_absolute_error: 27.9231 - mean_squared_logarithmic_error: 0.5268\n",
      "Epoch 237/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 695us/step - loss: 2724.7087 - mean_absolute_error: 28.5719 - mean_squared_logarithmic_error: 0.5532\n",
      "Epoch 238/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 712us/step - loss: 2738.4749 - mean_absolute_error: 28.1245 - mean_squared_logarithmic_error: 0.5410\n",
      "Epoch 239/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 2642.9885 - mean_absolute_error: 27.9423 - mean_squared_logarithmic_error: 0.5344\n",
      "Epoch 240/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 2466.6016 - mean_absolute_error: 27.8893 - mean_squared_logarithmic_error: 0.5379\n",
      "Epoch 241/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 765us/step - loss: 3047.8208 - mean_absolute_error: 28.7721 - mean_squared_logarithmic_error: 0.5490\n",
      "Epoch 242/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 2768.0598 - mean_absolute_error: 28.3698 - mean_squared_logarithmic_error: 0.5320\n",
      "Epoch 243/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 2631.0862 - mean_absolute_error: 27.9697 - mean_squared_logarithmic_error: 0.5293\n",
      "Epoch 244/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 2542.5898 - mean_absolute_error: 27.9378 - mean_squared_logarithmic_error: 0.5196\n",
      "Epoch 245/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 701us/step - loss: 2860.5527 - mean_absolute_error: 28.6980 - mean_squared_logarithmic_error: 0.5420\n",
      "Epoch 246/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 690us/step - loss: 2962.3374 - mean_absolute_error: 28.3058 - mean_squared_logarithmic_error: 0.5354\n",
      "Epoch 247/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 720us/step - loss: 2801.6589 - mean_absolute_error: 28.5582 - mean_squared_logarithmic_error: 0.5340\n",
      "Epoch 248/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 700us/step - loss: 2780.8333 - mean_absolute_error: 28.3781 - mean_squared_logarithmic_error: 0.5313\n",
      "Epoch 249/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 773us/step - loss: 2921.5110 - mean_absolute_error: 28.5930 - mean_squared_logarithmic_error: 0.5294\n",
      "Epoch 250/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 834us/step - loss: 2820.1106 - mean_absolute_error: 28.6852 - mean_squared_logarithmic_error: 0.5458\n",
      "Epoch 251/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 724us/step - loss: 2586.6252 - mean_absolute_error: 27.9345 - mean_squared_logarithmic_error: 0.5205\n",
      "Epoch 252/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 627us/step - loss: 2729.2969 - mean_absolute_error: 28.5439 - mean_squared_logarithmic_error: 0.5345\n",
      "Epoch 253/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 2686.7083 - mean_absolute_error: 28.2642 - mean_squared_logarithmic_error: 0.5428\n",
      "Epoch 254/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2740.3218 - mean_absolute_error: 28.5732 - mean_squared_logarithmic_error: 0.5415\n",
      "Epoch 255/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 2700.7083 - mean_absolute_error: 28.2299 - mean_squared_logarithmic_error: 0.5267\n",
      "Epoch 256/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 699us/step - loss: 2902.3066 - mean_absolute_error: 28.7268 - mean_squared_logarithmic_error: 0.5404\n",
      "Epoch 257/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 712us/step - loss: 2572.4006 - mean_absolute_error: 28.0828 - mean_squared_logarithmic_error: 0.5335\n",
      "Epoch 258/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 746us/step - loss: 2725.2122 - mean_absolute_error: 28.2428 - mean_squared_logarithmic_error: 0.5318\n",
      "Epoch 259/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 712us/step - loss: 2674.0461 - mean_absolute_error: 27.7935 - mean_squared_logarithmic_error: 0.5182\n",
      "Epoch 260/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 707us/step - loss: 2571.7715 - mean_absolute_error: 27.6167 - mean_squared_logarithmic_error: 0.5274\n",
      "Epoch 261/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 744us/step - loss: 2573.8933 - mean_absolute_error: 27.8099 - mean_squared_logarithmic_error: 0.5310\n",
      "Epoch 262/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 736us/step - loss: 2606.9771 - mean_absolute_error: 28.0925 - mean_squared_logarithmic_error: 0.5307\n",
      "Epoch 263/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 2968.2417 - mean_absolute_error: 28.9679 - mean_squared_logarithmic_error: 0.5365\n",
      "Epoch 264/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 689us/step - loss: 2764.5784 - mean_absolute_error: 28.2601 - mean_squared_logarithmic_error: 0.5278\n",
      "Epoch 265/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 697us/step - loss: 2703.8662 - mean_absolute_error: 28.1392 - mean_squared_logarithmic_error: 0.5330\n",
      "Epoch 266/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 723us/step - loss: 2803.3579 - mean_absolute_error: 28.6864 - mean_squared_logarithmic_error: 0.5326\n",
      "Epoch 267/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 717us/step - loss: 2694.0762 - mean_absolute_error: 28.1831 - mean_squared_logarithmic_error: 0.5214\n",
      "Epoch 268/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 703us/step - loss: 2662.9878 - mean_absolute_error: 27.9253 - mean_squared_logarithmic_error: 0.5315\n",
      "Epoch 269/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2786.9551 - mean_absolute_error: 28.0072 - mean_squared_logarithmic_error: 0.5176\n",
      "Epoch 270/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2820.7307 - mean_absolute_error: 28.5498 - mean_squared_logarithmic_error: 0.5466\n",
      "Epoch 271/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 714us/step - loss: 2640.8796 - mean_absolute_error: 28.4105 - mean_squared_logarithmic_error: 0.5343\n",
      "Epoch 272/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 717us/step - loss: 2713.8691 - mean_absolute_error: 28.3072 - mean_squared_logarithmic_error: 0.5310\n",
      "Epoch 273/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 755us/step - loss: 2758.3257 - mean_absolute_error: 28.1621 - mean_squared_logarithmic_error: 0.5319\n",
      "Epoch 274/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 839us/step - loss: 2845.6624 - mean_absolute_error: 28.7317 - mean_squared_logarithmic_error: 0.5382\n",
      "Epoch 275/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 725us/step - loss: 2693.7153 - mean_absolute_error: 28.2872 - mean_squared_logarithmic_error: 0.5353\n",
      "Epoch 276/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 725us/step - loss: 2805.9854 - mean_absolute_error: 28.5350 - mean_squared_logarithmic_error: 0.5375\n",
      "Epoch 277/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 746us/step - loss: 2473.5332 - mean_absolute_error: 27.9247 - mean_squared_logarithmic_error: 0.5188\n",
      "Epoch 278/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2777.5427 - mean_absolute_error: 28.9063 - mean_squared_logarithmic_error: 0.5511\n",
      "Epoch 279/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 698us/step - loss: 2814.5854 - mean_absolute_error: 28.5999 - mean_squared_logarithmic_error: 0.5381\n",
      "Epoch 280/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 730us/step - loss: 2668.8035 - mean_absolute_error: 28.3805 - mean_squared_logarithmic_error: 0.5319\n",
      "Epoch 281/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 690us/step - loss: 2666.0242 - mean_absolute_error: 28.1234 - mean_squared_logarithmic_error: 0.5327\n",
      "Epoch 282/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 2714.1421 - mean_absolute_error: 28.3391 - mean_squared_logarithmic_error: 0.5374\n",
      "Epoch 283/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 697us/step - loss: 2610.8118 - mean_absolute_error: 27.8002 - mean_squared_logarithmic_error: 0.5205\n",
      "Epoch 284/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2653.4646 - mean_absolute_error: 28.0319 - mean_squared_logarithmic_error: 0.5410\n",
      "Epoch 285/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - loss: 2593.1152 - mean_absolute_error: 28.1338 - mean_squared_logarithmic_error: 0.5372\n",
      "Epoch 286/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 2728.8647 - mean_absolute_error: 28.4192 - mean_squared_logarithmic_error: 0.5305\n",
      "Epoch 287/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2735.9336 - mean_absolute_error: 28.4238 - mean_squared_logarithmic_error: 0.5256\n",
      "Epoch 288/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 716us/step - loss: 2703.7036 - mean_absolute_error: 28.4572 - mean_squared_logarithmic_error: 0.5274\n",
      "Epoch 289/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 748us/step - loss: 2727.8694 - mean_absolute_error: 28.1563 - mean_squared_logarithmic_error: 0.5263\n",
      "Epoch 290/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2711.9219 - mean_absolute_error: 28.0105 - mean_squared_logarithmic_error: 0.5260\n",
      "Epoch 291/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 689us/step - loss: 2686.8701 - mean_absolute_error: 28.3532 - mean_squared_logarithmic_error: 0.5488\n",
      "Epoch 292/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 710us/step - loss: 2891.7598 - mean_absolute_error: 28.6370 - mean_squared_logarithmic_error: 0.5430\n",
      "Epoch 293/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 839us/step - loss: 2682.7456 - mean_absolute_error: 28.2438 - mean_squared_logarithmic_error: 0.5506\n",
      "Epoch 294/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 722us/step - loss: 2683.4810 - mean_absolute_error: 27.9040 - mean_squared_logarithmic_error: 0.5256\n",
      "Epoch 295/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 700us/step - loss: 2892.5269 - mean_absolute_error: 28.5057 - mean_squared_logarithmic_error: 0.5318\n",
      "Epoch 296/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 717us/step - loss: 3093.1973 - mean_absolute_error: 28.8724 - mean_squared_logarithmic_error: 0.5433\n",
      "Epoch 297/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 723us/step - loss: 2748.3516 - mean_absolute_error: 28.7737 - mean_squared_logarithmic_error: 0.5345\n",
      "Epoch 298/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 2674.1228 - mean_absolute_error: 28.2372 - mean_squared_logarithmic_error: 0.5228\n",
      "Epoch 299/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 747us/step - loss: 2499.8594 - mean_absolute_error: 27.9141 - mean_squared_logarithmic_error: 0.5236\n",
      "Epoch 300/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 720us/step - loss: 2690.2478 - mean_absolute_error: 28.0460 - mean_squared_logarithmic_error: 0.5241\n",
      "Epoch 301/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 707us/step - loss: 2808.0325 - mean_absolute_error: 28.2844 - mean_squared_logarithmic_error: 0.5359\n",
      "Epoch 302/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 744us/step - loss: 2743.9595 - mean_absolute_error: 28.1438 - mean_squared_logarithmic_error: 0.5419\n",
      "Epoch 303/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 715us/step - loss: 2681.5645 - mean_absolute_error: 28.0998 - mean_squared_logarithmic_error: 0.5288\n",
      "Epoch 304/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 690us/step - loss: 2761.1182 - mean_absolute_error: 28.6215 - mean_squared_logarithmic_error: 0.5318\n",
      "Epoch 305/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 708us/step - loss: 2726.9326 - mean_absolute_error: 28.1167 - mean_squared_logarithmic_error: 0.5341\n",
      "Epoch 306/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 2828.7803 - mean_absolute_error: 28.5579 - mean_squared_logarithmic_error: 0.5309\n",
      "Epoch 307/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 774us/step - loss: 2601.9810 - mean_absolute_error: 28.0086 - mean_squared_logarithmic_error: 0.5244\n",
      "Epoch 308/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 2585.2358 - mean_absolute_error: 27.6987 - mean_squared_logarithmic_error: 0.5062\n",
      "Epoch 309/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 708us/step - loss: 2729.8435 - mean_absolute_error: 28.2943 - mean_squared_logarithmic_error: 0.5260\n",
      "Epoch 310/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 710us/step - loss: 2742.8308 - mean_absolute_error: 28.2327 - mean_squared_logarithmic_error: 0.5275\n",
      "Epoch 311/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 714us/step - loss: 2802.5569 - mean_absolute_error: 28.5242 - mean_squared_logarithmic_error: 0.5290\n",
      "Epoch 312/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2767.7305 - mean_absolute_error: 28.0985 - mean_squared_logarithmic_error: 0.5292\n",
      "Epoch 313/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 763us/step - loss: 2681.4275 - mean_absolute_error: 28.3611 - mean_squared_logarithmic_error: 0.5307\n",
      "Epoch 314/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 722us/step - loss: 2709.2568 - mean_absolute_error: 28.1033 - mean_squared_logarithmic_error: 0.5352\n",
      "Epoch 315/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 728us/step - loss: 2697.4736 - mean_absolute_error: 28.1500 - mean_squared_logarithmic_error: 0.5205\n",
      "Epoch 316/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2828.0618 - mean_absolute_error: 28.5738 - mean_squared_logarithmic_error: 0.5330\n",
      "Epoch 317/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 762us/step - loss: 2757.2395 - mean_absolute_error: 27.8773 - mean_squared_logarithmic_error: 0.5228\n",
      "Epoch 318/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 2592.6736 - mean_absolute_error: 28.0130 - mean_squared_logarithmic_error: 0.5182\n",
      "Epoch 319/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 2711.9543 - mean_absolute_error: 28.3655 - mean_squared_logarithmic_error: 0.5335\n",
      "Epoch 320/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 701us/step - loss: 2632.0417 - mean_absolute_error: 28.1748 - mean_squared_logarithmic_error: 0.5319\n",
      "Epoch 321/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 707us/step - loss: 2643.3281 - mean_absolute_error: 27.8572 - mean_squared_logarithmic_error: 0.5297\n",
      "Epoch 322/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 719us/step - loss: 2519.1040 - mean_absolute_error: 27.7965 - mean_squared_logarithmic_error: 0.5209\n",
      "Epoch 323/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 2725.9900 - mean_absolute_error: 28.6204 - mean_squared_logarithmic_error: 0.5378\n",
      "Epoch 324/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 2771.4282 - mean_absolute_error: 28.0933 - mean_squared_logarithmic_error: 0.5305\n",
      "Epoch 325/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 700us/step - loss: 2590.5601 - mean_absolute_error: 28.3844 - mean_squared_logarithmic_error: 0.5348\n",
      "Epoch 326/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2608.6450 - mean_absolute_error: 27.8770 - mean_squared_logarithmic_error: 0.5200\n",
      "Epoch 327/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2863.0598 - mean_absolute_error: 28.5177 - mean_squared_logarithmic_error: 0.5322\n",
      "Epoch 328/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 2694.5635 - mean_absolute_error: 28.3619 - mean_squared_logarithmic_error: 0.5405\n",
      "Epoch 329/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 2744.1729 - mean_absolute_error: 28.2191 - mean_squared_logarithmic_error: 0.5263\n",
      "Epoch 330/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 3002.5085 - mean_absolute_error: 28.8635 - mean_squared_logarithmic_error: 0.5340\n",
      "Epoch 331/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 724us/step - loss: 2639.8782 - mean_absolute_error: 28.0521 - mean_squared_logarithmic_error: 0.5216\n",
      "Epoch 332/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2593.6648 - mean_absolute_error: 27.8531 - mean_squared_logarithmic_error: 0.5180\n",
      "Epoch 333/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 699us/step - loss: 3151.2112 - mean_absolute_error: 29.0481 - mean_squared_logarithmic_error: 0.5434\n",
      "Epoch 334/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 705us/step - loss: 2911.8608 - mean_absolute_error: 28.8684 - mean_squared_logarithmic_error: 0.5368\n",
      "Epoch 335/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 695us/step - loss: 2692.5962 - mean_absolute_error: 28.1691 - mean_squared_logarithmic_error: 0.5207\n",
      "Epoch 336/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 723us/step - loss: 2639.0879 - mean_absolute_error: 28.1716 - mean_squared_logarithmic_error: 0.5275\n",
      "Epoch 337/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2714.4504 - mean_absolute_error: 28.2376 - mean_squared_logarithmic_error: 0.5299\n",
      "Epoch 338/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 718us/step - loss: 2861.9500 - mean_absolute_error: 28.5609 - mean_squared_logarithmic_error: 0.5366\n",
      "Epoch 339/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2792.7983 - mean_absolute_error: 28.3151 - mean_squared_logarithmic_error: 0.5223\n",
      "Epoch 340/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 707us/step - loss: 2729.5437 - mean_absolute_error: 28.3584 - mean_squared_logarithmic_error: 0.5371\n",
      "Epoch 341/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - loss: 2463.7598 - mean_absolute_error: 27.7528 - mean_squared_logarithmic_error: 0.5306\n",
      "Epoch 342/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 743us/step - loss: 2814.2307 - mean_absolute_error: 28.5086 - mean_squared_logarithmic_error: 0.5298\n",
      "Epoch 343/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 2931.8503 - mean_absolute_error: 28.6137 - mean_squared_logarithmic_error: 0.5390\n",
      "Epoch 344/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 697us/step - loss: 2811.5710 - mean_absolute_error: 28.7665 - mean_squared_logarithmic_error: 0.5324\n",
      "Epoch 345/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 707us/step - loss: 2864.6582 - mean_absolute_error: 28.3852 - mean_squared_logarithmic_error: 0.5277\n",
      "Epoch 346/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 2750.6626 - mean_absolute_error: 28.3218 - mean_squared_logarithmic_error: 0.5263\n",
      "Epoch 347/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 713us/step - loss: 2712.4233 - mean_absolute_error: 28.4984 - mean_squared_logarithmic_error: 0.5273\n",
      "Epoch 348/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 695us/step - loss: 2754.5972 - mean_absolute_error: 28.5103 - mean_squared_logarithmic_error: 0.5229\n",
      "Epoch 349/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 2736.3223 - mean_absolute_error: 28.0720 - mean_squared_logarithmic_error: 0.5350\n",
      "Epoch 350/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2692.4502 - mean_absolute_error: 28.2457 - mean_squared_logarithmic_error: 0.5294\n",
      "Epoch 351/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 3012.3713 - mean_absolute_error: 28.8730 - mean_squared_logarithmic_error: 0.5334\n",
      "Epoch 352/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - loss: 2760.0688 - mean_absolute_error: 28.2885 - mean_squared_logarithmic_error: 0.5316\n",
      "Epoch 353/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 2663.4194 - mean_absolute_error: 27.9370 - mean_squared_logarithmic_error: 0.5244\n",
      "Epoch 354/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 698us/step - loss: 2601.5190 - mean_absolute_error: 27.8790 - mean_squared_logarithmic_error: 0.5248\n",
      "Epoch 355/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 785us/step - loss: 2699.6936 - mean_absolute_error: 28.4782 - mean_squared_logarithmic_error: 0.5312\n",
      "Epoch 356/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 2744.3545 - mean_absolute_error: 28.3127 - mean_squared_logarithmic_error: 0.5233\n",
      "Epoch 357/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 693us/step - loss: 2620.0911 - mean_absolute_error: 28.1828 - mean_squared_logarithmic_error: 0.5272\n",
      "Epoch 358/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 699us/step - loss: 2637.6392 - mean_absolute_error: 27.8974 - mean_squared_logarithmic_error: 0.5200\n",
      "Epoch 359/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 660us/step - loss: 2749.3311 - mean_absolute_error: 28.5475 - mean_squared_logarithmic_error: 0.5346\n",
      "Epoch 360/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 2772.1831 - mean_absolute_error: 28.4919 - mean_squared_logarithmic_error: 0.5318\n",
      "Epoch 361/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 671us/step - loss: 2692.2864 - mean_absolute_error: 28.0673 - mean_squared_logarithmic_error: 0.5239\n",
      "Epoch 362/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 657us/step - loss: 2770.3943 - mean_absolute_error: 28.2289 - mean_squared_logarithmic_error: 0.5231\n",
      "Epoch 363/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 685us/step - loss: 2758.1990 - mean_absolute_error: 28.3653 - mean_squared_logarithmic_error: 0.5326\n",
      "Epoch 364/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 3017.5708 - mean_absolute_error: 28.7856 - mean_squared_logarithmic_error: 0.5335\n",
      "Epoch 365/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 2652.8252 - mean_absolute_error: 28.1232 - mean_squared_logarithmic_error: 0.5283\n",
      "Epoch 366/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2679.7937 - mean_absolute_error: 28.2902 - mean_squared_logarithmic_error: 0.5227\n",
      "Epoch 367/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 766us/step - loss: 2846.1650 - mean_absolute_error: 28.8511 - mean_squared_logarithmic_error: 0.5419\n",
      "Epoch 368/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 2627.6018 - mean_absolute_error: 27.8232 - mean_squared_logarithmic_error: 0.5274\n",
      "Epoch 369/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - loss: 2559.8208 - mean_absolute_error: 27.6786 - mean_squared_logarithmic_error: 0.5251\n",
      "Epoch 370/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 724us/step - loss: 2762.8794 - mean_absolute_error: 28.6088 - mean_squared_logarithmic_error: 0.5276\n",
      "Epoch 371/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 702us/step - loss: 2668.5081 - mean_absolute_error: 28.1921 - mean_squared_logarithmic_error: 0.5350\n",
      "Epoch 372/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - loss: 2960.6501 - mean_absolute_error: 28.4371 - mean_squared_logarithmic_error: 0.5315\n",
      "Epoch 373/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 690us/step - loss: 2825.1887 - mean_absolute_error: 28.4909 - mean_squared_logarithmic_error: 0.5204\n",
      "Epoch 374/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2687.2334 - mean_absolute_error: 28.0445 - mean_squared_logarithmic_error: 0.5285\n",
      "Epoch 375/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 2752.1038 - mean_absolute_error: 28.2949 - mean_squared_logarithmic_error: 0.5140\n",
      "Epoch 376/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 720us/step - loss: 2756.6885 - mean_absolute_error: 28.1356 - mean_squared_logarithmic_error: 0.5227\n",
      "Epoch 377/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2887.1304 - mean_absolute_error: 28.9241 - mean_squared_logarithmic_error: 0.5420\n",
      "Epoch 378/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2815.9380 - mean_absolute_error: 28.3876 - mean_squared_logarithmic_error: 0.5174\n",
      "Epoch 379/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 705us/step - loss: 2656.9595 - mean_absolute_error: 28.2997 - mean_squared_logarithmic_error: 0.5371\n",
      "Epoch 380/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2652.1135 - mean_absolute_error: 28.1388 - mean_squared_logarithmic_error: 0.5264\n",
      "Epoch 381/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 2769.6536 - mean_absolute_error: 28.3573 - mean_squared_logarithmic_error: 0.5377\n",
      "Epoch 382/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 701us/step - loss: 2864.8345 - mean_absolute_error: 28.3670 - mean_squared_logarithmic_error: 0.5290\n",
      "Epoch 383/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 2549.5686 - mean_absolute_error: 27.7319 - mean_squared_logarithmic_error: 0.5265\n",
      "Epoch 384/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 2870.2673 - mean_absolute_error: 28.7939 - mean_squared_logarithmic_error: 0.5246\n",
      "Epoch 385/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2722.5894 - mean_absolute_error: 28.4373 - mean_squared_logarithmic_error: 0.5351\n",
      "Epoch 386/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 765us/step - loss: 2834.7358 - mean_absolute_error: 28.6251 - mean_squared_logarithmic_error: 0.5296\n",
      "Epoch 387/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 669us/step - loss: 2827.8042 - mean_absolute_error: 28.7388 - mean_squared_logarithmic_error: 0.5367\n",
      "Epoch 388/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 665us/step - loss: 2698.4468 - mean_absolute_error: 27.8737 - mean_squared_logarithmic_error: 0.5217\n",
      "Epoch 389/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 2756.5630 - mean_absolute_error: 28.0073 - mean_squared_logarithmic_error: 0.5341\n",
      "Epoch 390/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 2837.4624 - mean_absolute_error: 28.4479 - mean_squared_logarithmic_error: 0.5301\n",
      "Epoch 391/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 760us/step - loss: 2768.2866 - mean_absolute_error: 28.3096 - mean_squared_logarithmic_error: 0.5271\n",
      "Epoch 392/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 697us/step - loss: 2741.1262 - mean_absolute_error: 27.8421 - mean_squared_logarithmic_error: 0.5135\n",
      "Epoch 393/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 2603.6699 - mean_absolute_error: 28.0603 - mean_squared_logarithmic_error: 0.5312\n",
      "Epoch 394/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 2754.0149 - mean_absolute_error: 28.3000 - mean_squared_logarithmic_error: 0.5304\n",
      "Epoch 395/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 2508.3723 - mean_absolute_error: 28.0522 - mean_squared_logarithmic_error: 0.5280\n",
      "Epoch 396/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 712us/step - loss: 3106.5259 - mean_absolute_error: 28.9326 - mean_squared_logarithmic_error: 0.5314\n",
      "Epoch 397/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2635.3333 - mean_absolute_error: 27.8591 - mean_squared_logarithmic_error: 0.5155\n",
      "Epoch 398/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 2685.8928 - mean_absolute_error: 27.8963 - mean_squared_logarithmic_error: 0.5292\n",
      "Epoch 399/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 2630.9919 - mean_absolute_error: 28.0305 - mean_squared_logarithmic_error: 0.5269\n",
      "Epoch 400/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 2707.4055 - mean_absolute_error: 28.2242 - mean_squared_logarithmic_error: 0.5233\n",
      "Epoch 401/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 705us/step - loss: 2861.9331 - mean_absolute_error: 28.2618 - mean_squared_logarithmic_error: 0.5306\n",
      "Epoch 402/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 632us/step - loss: 2808.7439 - mean_absolute_error: 28.1866 - mean_squared_logarithmic_error: 0.5256\n",
      "Epoch 403/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 2751.1057 - mean_absolute_error: 28.3727 - mean_squared_logarithmic_error: 0.5386\n",
      "Epoch 404/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 2930.9666 - mean_absolute_error: 28.7261 - mean_squared_logarithmic_error: 0.5365\n",
      "Epoch 405/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2781.2703 - mean_absolute_error: 28.1167 - mean_squared_logarithmic_error: 0.5272\n",
      "Epoch 406/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - loss: 2876.5645 - mean_absolute_error: 28.2609 - mean_squared_logarithmic_error: 0.5282\n",
      "Epoch 407/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 2889.0369 - mean_absolute_error: 28.5994 - mean_squared_logarithmic_error: 0.5218\n",
      "Epoch 408/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 2603.1191 - mean_absolute_error: 27.9090 - mean_squared_logarithmic_error: 0.5246\n",
      "Epoch 409/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 2625.7935 - mean_absolute_error: 28.1920 - mean_squared_logarithmic_error: 0.5242\n",
      "Epoch 410/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 695us/step - loss: 2613.3435 - mean_absolute_error: 28.2482 - mean_squared_logarithmic_error: 0.5254\n",
      "Epoch 411/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - loss: 2912.7576 - mean_absolute_error: 28.3617 - mean_squared_logarithmic_error: 0.5362\n",
      "Epoch 412/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 3024.6819 - mean_absolute_error: 28.4436 - mean_squared_logarithmic_error: 0.5264\n",
      "Epoch 413/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - loss: 2595.4075 - mean_absolute_error: 28.0134 - mean_squared_logarithmic_error: 0.5173\n",
      "Epoch 414/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 710us/step - loss: 2508.8918 - mean_absolute_error: 27.6691 - mean_squared_logarithmic_error: 0.5279\n",
      "Epoch 415/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 821us/step - loss: 2764.7126 - mean_absolute_error: 28.3751 - mean_squared_logarithmic_error: 0.5302\n",
      "Epoch 416/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 693us/step - loss: 2707.4160 - mean_absolute_error: 28.2641 - mean_squared_logarithmic_error: 0.5396\n",
      "Epoch 417/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 720us/step - loss: 2752.1643 - mean_absolute_error: 28.1105 - mean_squared_logarithmic_error: 0.5385\n",
      "Epoch 418/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2868.8921 - mean_absolute_error: 28.2074 - mean_squared_logarithmic_error: 0.5277\n",
      "Epoch 419/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 659us/step - loss: 2860.4824 - mean_absolute_error: 28.4461 - mean_squared_logarithmic_error: 0.5318\n",
      "Epoch 420/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2829.8245 - mean_absolute_error: 28.6686 - mean_squared_logarithmic_error: 0.5443\n",
      "Epoch 421/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 716us/step - loss: 2583.2954 - mean_absolute_error: 28.0482 - mean_squared_logarithmic_error: 0.5170\n",
      "Epoch 422/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 713us/step - loss: 2645.9170 - mean_absolute_error: 28.1147 - mean_squared_logarithmic_error: 0.5266\n",
      "Epoch 423/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2659.2705 - mean_absolute_error: 28.0284 - mean_squared_logarithmic_error: 0.5180\n",
      "Epoch 424/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 2781.2795 - mean_absolute_error: 28.7570 - mean_squared_logarithmic_error: 0.5335\n",
      "Epoch 425/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - loss: 2551.5144 - mean_absolute_error: 27.8772 - mean_squared_logarithmic_error: 0.5285\n",
      "Epoch 426/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 712us/step - loss: 2662.3472 - mean_absolute_error: 27.6962 - mean_squared_logarithmic_error: 0.5115\n",
      "Epoch 427/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 2567.3354 - mean_absolute_error: 27.8431 - mean_squared_logarithmic_error: 0.5231\n",
      "Epoch 428/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 2485.0415 - mean_absolute_error: 27.3704 - mean_squared_logarithmic_error: 0.5198\n",
      "Epoch 429/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 2653.2065 - mean_absolute_error: 27.9658 - mean_squared_logarithmic_error: 0.5300\n",
      "Epoch 430/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 2550.0010 - mean_absolute_error: 27.7106 - mean_squared_logarithmic_error: 0.5198\n",
      "Epoch 431/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 717us/step - loss: 2776.9082 - mean_absolute_error: 28.7433 - mean_squared_logarithmic_error: 0.5310\n",
      "Epoch 432/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - loss: 2882.7986 - mean_absolute_error: 28.0581 - mean_squared_logarithmic_error: 0.5284\n",
      "Epoch 433/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 650us/step - loss: 2677.0427 - mean_absolute_error: 28.1279 - mean_squared_logarithmic_error: 0.5223\n",
      "Epoch 434/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 670us/step - loss: 2667.3948 - mean_absolute_error: 28.1255 - mean_squared_logarithmic_error: 0.5249\n",
      "Epoch 435/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 721us/step - loss: 2888.4810 - mean_absolute_error: 28.3085 - mean_squared_logarithmic_error: 0.5223\n",
      "Epoch 436/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 2726.8140 - mean_absolute_error: 28.3888 - mean_squared_logarithmic_error: 0.5257\n",
      "Epoch 437/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2693.0552 - mean_absolute_error: 28.1900 - mean_squared_logarithmic_error: 0.5311\n",
      "Epoch 438/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 739us/step - loss: 2999.0337 - mean_absolute_error: 28.5135 - mean_squared_logarithmic_error: 0.5352\n",
      "Epoch 439/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 655us/step - loss: 2772.6724 - mean_absolute_error: 28.3040 - mean_squared_logarithmic_error: 0.5161\n",
      "Epoch 440/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 2426.3386 - mean_absolute_error: 27.4312 - mean_squared_logarithmic_error: 0.5064\n",
      "Epoch 441/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 660us/step - loss: 2622.8914 - mean_absolute_error: 28.0359 - mean_squared_logarithmic_error: 0.5191\n",
      "Epoch 442/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 2788.7349 - mean_absolute_error: 28.4127 - mean_squared_logarithmic_error: 0.5179\n",
      "Epoch 443/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - loss: 2898.9426 - mean_absolute_error: 28.3213 - mean_squared_logarithmic_error: 0.5268\n",
      "Epoch 444/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 641us/step - loss: 2712.4827 - mean_absolute_error: 28.3522 - mean_squared_logarithmic_error: 0.5294\n",
      "Epoch 445/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 2749.5818 - mean_absolute_error: 28.7204 - mean_squared_logarithmic_error: 0.5429\n",
      "Epoch 446/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 2669.8303 - mean_absolute_error: 27.9225 - mean_squared_logarithmic_error: 0.5243\n",
      "Epoch 447/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 654us/step - loss: 2753.1042 - mean_absolute_error: 28.2403 - mean_squared_logarithmic_error: 0.5260\n",
      "Epoch 448/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - loss: 2765.5706 - mean_absolute_error: 28.3228 - mean_squared_logarithmic_error: 0.5191\n",
      "Epoch 449/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - loss: 2751.9526 - mean_absolute_error: 28.3491 - mean_squared_logarithmic_error: 0.5328\n",
      "Epoch 450/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 2853.3582 - mean_absolute_error: 28.8365 - mean_squared_logarithmic_error: 0.5306\n",
      "Epoch 451/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 661us/step - loss: 2737.4575 - mean_absolute_error: 28.0969 - mean_squared_logarithmic_error: 0.5224\n",
      "Epoch 452/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - loss: 2841.5620 - mean_absolute_error: 28.5940 - mean_squared_logarithmic_error: 0.5317\n",
      "Epoch 453/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2695.2947 - mean_absolute_error: 27.9959 - mean_squared_logarithmic_error: 0.5111\n",
      "Epoch 454/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 662us/step - loss: 2732.2388 - mean_absolute_error: 28.3866 - mean_squared_logarithmic_error: 0.5294\n",
      "Epoch 455/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - loss: 2694.7673 - mean_absolute_error: 28.2145 - mean_squared_logarithmic_error: 0.5297\n",
      "Epoch 456/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2868.7266 - mean_absolute_error: 28.3774 - mean_squared_logarithmic_error: 0.5148\n",
      "Epoch 457/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 2707.8062 - mean_absolute_error: 28.0376 - mean_squared_logarithmic_error: 0.5222\n",
      "Epoch 458/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696us/step - loss: 2921.0596 - mean_absolute_error: 28.6678 - mean_squared_logarithmic_error: 0.5314\n",
      "Epoch 459/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 2690.8877 - mean_absolute_error: 28.2880 - mean_squared_logarithmic_error: 0.5331\n",
      "Epoch 460/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - loss: 2806.4536 - mean_absolute_error: 28.5221 - mean_squared_logarithmic_error: 0.5220\n",
      "Epoch 461/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 737us/step - loss: 2772.9653 - mean_absolute_error: 28.4749 - mean_squared_logarithmic_error: 0.5224\n",
      "Epoch 462/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - loss: 2887.2981 - mean_absolute_error: 28.3667 - mean_squared_logarithmic_error: 0.5328\n",
      "Epoch 463/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - loss: 2684.9036 - mean_absolute_error: 28.2097 - mean_squared_logarithmic_error: 0.5200\n",
      "Epoch 464/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - loss: 2554.0642 - mean_absolute_error: 28.0117 - mean_squared_logarithmic_error: 0.5205\n",
      "Epoch 465/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - loss: 2871.0769 - mean_absolute_error: 28.1692 - mean_squared_logarithmic_error: 0.5274\n",
      "Epoch 466/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 714us/step - loss: 2731.7209 - mean_absolute_error: 28.0564 - mean_squared_logarithmic_error: 0.5093\n",
      "Epoch 467/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 2601.8203 - mean_absolute_error: 28.2548 - mean_squared_logarithmic_error: 0.5289\n",
      "Epoch 468/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - loss: 2771.0798 - mean_absolute_error: 28.4880 - mean_squared_logarithmic_error: 0.5395\n",
      "Epoch 469/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 663us/step - loss: 2604.1577 - mean_absolute_error: 27.8358 - mean_squared_logarithmic_error: 0.5185\n",
      "Epoch 470/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 2717.2324 - mean_absolute_error: 28.5016 - mean_squared_logarithmic_error: 0.5272\n",
      "Epoch 471/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 2813.0857 - mean_absolute_error: 28.6025 - mean_squared_logarithmic_error: 0.5317\n",
      "Epoch 472/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - loss: 2769.6379 - mean_absolute_error: 28.4316 - mean_squared_logarithmic_error: 0.5228\n",
      "Epoch 473/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - loss: 2804.1611 - mean_absolute_error: 28.2301 - mean_squared_logarithmic_error: 0.5291\n",
      "Epoch 474/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 2948.0137 - mean_absolute_error: 28.8172 - mean_squared_logarithmic_error: 0.5476\n",
      "Epoch 475/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 680us/step - loss: 2875.0471 - mean_absolute_error: 28.6742 - mean_squared_logarithmic_error: 0.5326\n",
      "Epoch 476/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 636us/step - loss: 2789.7864 - mean_absolute_error: 28.4021 - mean_squared_logarithmic_error: 0.5285\n",
      "Epoch 477/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 645us/step - loss: 2719.3533 - mean_absolute_error: 27.9191 - mean_squared_logarithmic_error: 0.5284\n",
      "Epoch 478/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 638us/step - loss: 2875.0557 - mean_absolute_error: 28.4647 - mean_squared_logarithmic_error: 0.5238\n",
      "Epoch 479/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 2671.6846 - mean_absolute_error: 28.2282 - mean_squared_logarithmic_error: 0.5228\n",
      "Epoch 480/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 648us/step - loss: 2814.6643 - mean_absolute_error: 28.3048 - mean_squared_logarithmic_error: 0.5160\n",
      "Epoch 481/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 646us/step - loss: 2689.2207 - mean_absolute_error: 27.9776 - mean_squared_logarithmic_error: 0.5190\n",
      "Epoch 482/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 704us/step - loss: 2745.6897 - mean_absolute_error: 28.2171 - mean_squared_logarithmic_error: 0.5266\n",
      "Epoch 483/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 688us/step - loss: 2656.9771 - mean_absolute_error: 27.9350 - mean_squared_logarithmic_error: 0.5243\n",
      "Epoch 484/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 699us/step - loss: 2633.4199 - mean_absolute_error: 27.8466 - mean_squared_logarithmic_error: 0.5198\n",
      "Epoch 485/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 656us/step - loss: 2583.6443 - mean_absolute_error: 28.1655 - mean_squared_logarithmic_error: 0.5234\n",
      "Epoch 486/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 645us/step - loss: 3078.7329 - mean_absolute_error: 29.0212 - mean_squared_logarithmic_error: 0.5290\n",
      "Epoch 487/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 651us/step - loss: 2667.2549 - mean_absolute_error: 28.1414 - mean_squared_logarithmic_error: 0.5198\n",
      "Epoch 488/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 634us/step - loss: 2676.8406 - mean_absolute_error: 28.2802 - mean_squared_logarithmic_error: 0.5330\n",
      "Epoch 489/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 667us/step - loss: 2592.3608 - mean_absolute_error: 27.9861 - mean_squared_logarithmic_error: 0.5269\n",
      "Epoch 490/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 694us/step - loss: 2835.9688 - mean_absolute_error: 28.7156 - mean_squared_logarithmic_error: 0.5305\n",
      "Epoch 491/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - loss: 2724.1892 - mean_absolute_error: 28.3993 - mean_squared_logarithmic_error: 0.5152\n",
      "Epoch 492/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2944.3550 - mean_absolute_error: 28.8481 - mean_squared_logarithmic_error: 0.5278\n",
      "Epoch 493/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - loss: 2752.5781 - mean_absolute_error: 28.1839 - mean_squared_logarithmic_error: 0.5315\n",
      "Epoch 494/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 2867.1873 - mean_absolute_error: 28.4542 - mean_squared_logarithmic_error: 0.5309\n",
      "Epoch 495/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step - loss: 2828.8064 - mean_absolute_error: 28.4169 - mean_squared_logarithmic_error: 0.5139\n",
      "Epoch 496/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - loss: 2907.3391 - mean_absolute_error: 27.9154 - mean_squared_logarithmic_error: 0.5178\n",
      "Epoch 497/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 655us/step - loss: 2830.2061 - mean_absolute_error: 28.6696 - mean_squared_logarithmic_error: 0.5187\n",
      "Epoch 498/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 664us/step - loss: 2729.4685 - mean_absolute_error: 28.3637 - mean_squared_logarithmic_error: 0.5193\n",
      "Epoch 499/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - loss: 2661.7378 - mean_absolute_error: 28.3721 - mean_squared_logarithmic_error: 0.5178\n",
      "Epoch 500/500\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 706us/step - loss: 2882.6753 - mean_absolute_error: 28.3395 - mean_squared_logarithmic_error: 0.5224\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x255c14c4410>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model evalueren"
   ],
   "id": "d538bb54a80b5e01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:39:45.459870Z",
     "start_time": "2024-04-16T08:39:45.067978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# predicting the model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted'], index=X_test.index)\n",
    "\n",
    "# Add the actual values to the DataFrame\n",
    "predictions_df['Actual'] = y_test\n",
    "\n",
    "predictions_df['Difference'] = predictions_df['Predicted'] - predictions_df['Actual']\n",
    "predictions_df['Absolute Difference'] = abs(predictions_df['Difference'])\n",
    "\n",
    "predictions_df"
   ],
   "id": "157c160913af3b20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m270/270\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Predicted  Actual  Difference  Absolute Difference\n9130   49.914692      56   -6.085308             6.085308\n27718  67.294991      36   31.294991            31.294991\n41898  37.297047      26   11.297047            11.297047\n15673  59.953228      24   35.953228            35.953228\n2314   70.045815      46   24.045815            24.045815\n...          ...     ...         ...                  ...\n38076  43.473000      46   -2.527000             2.527000\n18731  57.706905      94  -36.293095            36.293095\n2460   53.112999      56   -2.887001             2.887001\n15719  65.113281      90  -24.886719            24.886719\n39153   4.184751       6   -1.815249             1.815249\n\n[8613 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted</th>\n      <th>Actual</th>\n      <th>Difference</th>\n      <th>Absolute Difference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9130</th>\n      <td>49.914692</td>\n      <td>56</td>\n      <td>-6.085308</td>\n      <td>6.085308</td>\n    </tr>\n    <tr>\n      <th>27718</th>\n      <td>67.294991</td>\n      <td>36</td>\n      <td>31.294991</td>\n      <td>31.294991</td>\n    </tr>\n    <tr>\n      <th>41898</th>\n      <td>37.297047</td>\n      <td>26</td>\n      <td>11.297047</td>\n      <td>11.297047</td>\n    </tr>\n    <tr>\n      <th>15673</th>\n      <td>59.953228</td>\n      <td>24</td>\n      <td>35.953228</td>\n      <td>35.953228</td>\n    </tr>\n    <tr>\n      <th>2314</th>\n      <td>70.045815</td>\n      <td>46</td>\n      <td>24.045815</td>\n      <td>24.045815</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38076</th>\n      <td>43.473000</td>\n      <td>46</td>\n      <td>-2.527000</td>\n      <td>2.527000</td>\n    </tr>\n    <tr>\n      <th>18731</th>\n      <td>57.706905</td>\n      <td>94</td>\n      <td>-36.293095</td>\n      <td>36.293095</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>53.112999</td>\n      <td>56</td>\n      <td>-2.887001</td>\n      <td>2.887001</td>\n    </tr>\n    <tr>\n      <th>15719</th>\n      <td>65.113281</td>\n      <td>90</td>\n      <td>-24.886719</td>\n      <td>24.886719</td>\n    </tr>\n    <tr>\n      <th>39153</th>\n      <td>4.184751</td>\n      <td>6</td>\n      <td>-1.815249</td>\n      <td>1.815249</td>\n    </tr>\n  </tbody>\n</table>\n<p>8613 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:39:45.807918Z",
     "start_time": "2024-04-16T08:39:45.460877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluating the model\n",
    "loss, mae, mslr = model.evaluate(X_test, y_test)\n",
    "average_difference = predictions_df['Absolute Difference'].mean()\n",
    "print(f'Loss (Mean Squared Error): {loss}, Mean Absolute Error: {mae}, Mean Squared Logarithmic Error: {mslr}, Average Difference: {average_difference}')"
   ],
   "id": "a5c0f5dbc60aa3f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m270/270\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 595us/step - loss: 2152.5396 - mean_absolute_error: 28.1442 - mean_squared_logarithmic_error: 0.5398\n",
      "Loss (Mean Squared Error): 2531.427734375, Mean Absolute Error: 28.308095932006836, Mean Squared Logarithmic Error: 0.5284209847450256, Average Difference: 28.308103987471117\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pytorch\n",
    "neural network using pytorch"
   ],
   "id": "dae4114b45daf1f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model maken"
   ],
   "id": "2c2c87a21f46b8d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:39:45.984557Z",
     "start_time": "2024-04-16T08:39:45.808923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check if cuda is available\n",
    "# to use gpu, torch needs to be installed with the correct cuda version\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the architecture of the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 16), # input layer with 16 output nodes\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8), # 16 input nodes to 16 output nodes\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1) # 16 input nodes to 1 output node\n",
    ")\n",
    "\n",
    "# Send the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "print(f'The model is using {device}')"
   ],
   "id": "c863ac4bc5ea9bf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is using cuda\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model trainen"
   ],
   "id": "d9c80286b1f48d19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:39:45.989961Z",
     "start_time": "2024-04-16T08:39:45.985564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom optimizer class which doesn't use gradient descent or backpropagation\n",
    "class SimpleErrorOptimizerPyTorch(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(SimpleErrorOptimizerPyTorch, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                # Here we directly subtract the error from the parameters\n",
    "                p.data -= group['lr'] * p.grad.data"
   ],
   "id": "68b69ed9151a7d64",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:48:30.578043Z",
     "start_time": "2024-04-16T08:39:45.990968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Converting the dataframes to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the loss function and the custom optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = SimpleErrorOptimizerPyTorch(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):  # 100 epochs\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ],
   "id": "16f7e294580da2d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 857.3074951171875\n",
      "Epoch 2/500, Loss: 2255.376953125\n",
      "Epoch 3/500, Loss: 2648.048095703125\n",
      "Epoch 4/500, Loss: 4011.901123046875\n",
      "Epoch 5/500, Loss: 4907.1123046875\n",
      "Epoch 6/500, Loss: 1939.5321044921875\n",
      "Epoch 7/500, Loss: 3826.389404296875\n",
      "Epoch 8/500, Loss: 1707.519287109375\n",
      "Epoch 9/500, Loss: 3656.791748046875\n",
      "Epoch 10/500, Loss: 1977.0999755859375\n",
      "Epoch 11/500, Loss: 960.7280883789062\n",
      "Epoch 12/500, Loss: 5553.470703125\n",
      "Epoch 13/500, Loss: 1390.7059326171875\n",
      "Epoch 14/500, Loss: 4125.02783203125\n",
      "Epoch 15/500, Loss: 1343.591796875\n",
      "Epoch 16/500, Loss: 821.4384765625\n",
      "Epoch 17/500, Loss: 4062.966796875\n",
      "Epoch 18/500, Loss: 3165.706787109375\n",
      "Epoch 19/500, Loss: 18521.451171875\n",
      "Epoch 20/500, Loss: 1898.5599365234375\n",
      "Epoch 21/500, Loss: 3120.726806640625\n",
      "Epoch 22/500, Loss: 11396.89453125\n",
      "Epoch 23/500, Loss: 2055.083984375\n",
      "Epoch 24/500, Loss: 1951.7884521484375\n",
      "Epoch 25/500, Loss: 2329.10546875\n",
      "Epoch 26/500, Loss: 1113.5135498046875\n",
      "Epoch 27/500, Loss: 4089.701171875\n",
      "Epoch 28/500, Loss: 6011.04931640625\n",
      "Epoch 29/500, Loss: 1885.321044921875\n",
      "Epoch 30/500, Loss: 6214.3173828125\n",
      "Epoch 31/500, Loss: 5930.24755859375\n",
      "Epoch 32/500, Loss: 2874.693115234375\n",
      "Epoch 33/500, Loss: 3140.11279296875\n",
      "Epoch 34/500, Loss: 1028.0001220703125\n",
      "Epoch 35/500, Loss: 1307.5633544921875\n",
      "Epoch 36/500, Loss: 2031.785888671875\n",
      "Epoch 37/500, Loss: 5471.09619140625\n",
      "Epoch 38/500, Loss: 7922.427734375\n",
      "Epoch 39/500, Loss: 7975.1298828125\n",
      "Epoch 40/500, Loss: 1810.75146484375\n",
      "Epoch 41/500, Loss: 1670.674072265625\n",
      "Epoch 42/500, Loss: 11039.9169921875\n",
      "Epoch 43/500, Loss: 8703.1630859375\n",
      "Epoch 44/500, Loss: 2729.132080078125\n",
      "Epoch 45/500, Loss: 1946.90234375\n",
      "Epoch 46/500, Loss: 2652.97216796875\n",
      "Epoch 47/500, Loss: 1485.3963623046875\n",
      "Epoch 48/500, Loss: 1650.8587646484375\n",
      "Epoch 49/500, Loss: 6144.48095703125\n",
      "Epoch 50/500, Loss: 3409.965576171875\n",
      "Epoch 51/500, Loss: 4568.6904296875\n",
      "Epoch 52/500, Loss: 1764.398681640625\n",
      "Epoch 53/500, Loss: 1176.07275390625\n",
      "Epoch 54/500, Loss: 1268.9581298828125\n",
      "Epoch 55/500, Loss: 2724.2177734375\n",
      "Epoch 56/500, Loss: 1973.9833984375\n",
      "Epoch 57/500, Loss: 3063.60107421875\n",
      "Epoch 58/500, Loss: 4457.09326171875\n",
      "Epoch 59/500, Loss: 3358.764892578125\n",
      "Epoch 60/500, Loss: 2901.88671875\n",
      "Epoch 61/500, Loss: 2750.17138671875\n",
      "Epoch 62/500, Loss: 2220.997802734375\n",
      "Epoch 63/500, Loss: 5103.89794921875\n",
      "Epoch 64/500, Loss: 5293.541015625\n",
      "Epoch 65/500, Loss: 4334.03662109375\n",
      "Epoch 66/500, Loss: 4713.8701171875\n",
      "Epoch 67/500, Loss: 4470.93896484375\n",
      "Epoch 68/500, Loss: 4407.10791015625\n",
      "Epoch 69/500, Loss: 2623.48583984375\n",
      "Epoch 70/500, Loss: 6495.9052734375\n",
      "Epoch 71/500, Loss: 2475.041259765625\n",
      "Epoch 72/500, Loss: 1659.61767578125\n",
      "Epoch 73/500, Loss: 9182.177734375\n",
      "Epoch 74/500, Loss: 4785.20263671875\n",
      "Epoch 75/500, Loss: 9732.033203125\n",
      "Epoch 76/500, Loss: 1648.8353271484375\n",
      "Epoch 77/500, Loss: 2831.8046875\n",
      "Epoch 78/500, Loss: 1196.4820556640625\n",
      "Epoch 79/500, Loss: 1786.6514892578125\n",
      "Epoch 80/500, Loss: 1819.8271484375\n",
      "Epoch 81/500, Loss: 3266.83935546875\n",
      "Epoch 82/500, Loss: 1439.7952880859375\n",
      "Epoch 83/500, Loss: 3002.52294921875\n",
      "Epoch 84/500, Loss: 2674.802490234375\n",
      "Epoch 85/500, Loss: 1208.1824951171875\n",
      "Epoch 86/500, Loss: 4301.02880859375\n",
      "Epoch 87/500, Loss: 1842.2564697265625\n",
      "Epoch 88/500, Loss: 3605.5224609375\n",
      "Epoch 89/500, Loss: 10440.66015625\n",
      "Epoch 90/500, Loss: 2794.767333984375\n",
      "Epoch 91/500, Loss: 1344.24658203125\n",
      "Epoch 92/500, Loss: 2411.53857421875\n",
      "Epoch 93/500, Loss: 3731.017333984375\n",
      "Epoch 94/500, Loss: 7048.32470703125\n",
      "Epoch 95/500, Loss: 973.4640502929688\n",
      "Epoch 96/500, Loss: 2778.73681640625\n",
      "Epoch 97/500, Loss: 1604.6558837890625\n",
      "Epoch 98/500, Loss: 2033.831787109375\n",
      "Epoch 99/500, Loss: 5536.8359375\n",
      "Epoch 100/500, Loss: 2102.734619140625\n",
      "Epoch 101/500, Loss: 3091.25341796875\n",
      "Epoch 102/500, Loss: 7529.9287109375\n",
      "Epoch 103/500, Loss: 2653.31689453125\n",
      "Epoch 104/500, Loss: 3507.661376953125\n",
      "Epoch 105/500, Loss: 3789.1474609375\n",
      "Epoch 106/500, Loss: 1561.6318359375\n",
      "Epoch 107/500, Loss: 1028.498046875\n",
      "Epoch 108/500, Loss: 7746.1962890625\n",
      "Epoch 109/500, Loss: 2656.70556640625\n",
      "Epoch 110/500, Loss: 1251.3634033203125\n",
      "Epoch 111/500, Loss: 2959.29638671875\n",
      "Epoch 112/500, Loss: 6117.501953125\n",
      "Epoch 113/500, Loss: 676.4150390625\n",
      "Epoch 114/500, Loss: 1800.6925048828125\n",
      "Epoch 115/500, Loss: 3732.7958984375\n",
      "Epoch 116/500, Loss: 1701.3934326171875\n",
      "Epoch 117/500, Loss: 2783.8037109375\n",
      "Epoch 118/500, Loss: 3357.94775390625\n",
      "Epoch 119/500, Loss: 3439.48681640625\n",
      "Epoch 120/500, Loss: 1783.254638671875\n",
      "Epoch 121/500, Loss: 4468.93212890625\n",
      "Epoch 122/500, Loss: 14147.2763671875\n",
      "Epoch 123/500, Loss: 2380.452392578125\n",
      "Epoch 124/500, Loss: 1759.1485595703125\n",
      "Epoch 125/500, Loss: 4077.317138671875\n",
      "Epoch 126/500, Loss: 1989.6827392578125\n",
      "Epoch 127/500, Loss: 2475.73486328125\n",
      "Epoch 128/500, Loss: 3044.067626953125\n",
      "Epoch 129/500, Loss: 2846.526123046875\n",
      "Epoch 130/500, Loss: 1271.655029296875\n",
      "Epoch 131/500, Loss: 1087.6873779296875\n",
      "Epoch 132/500, Loss: 3044.432373046875\n",
      "Epoch 133/500, Loss: 2034.3822021484375\n",
      "Epoch 134/500, Loss: 7711.36376953125\n",
      "Epoch 135/500, Loss: 4328.8486328125\n",
      "Epoch 136/500, Loss: 844.73046875\n",
      "Epoch 137/500, Loss: 21011.583984375\n",
      "Epoch 138/500, Loss: 3349.03076171875\n",
      "Epoch 139/500, Loss: 1646.22021484375\n",
      "Epoch 140/500, Loss: 1398.4169921875\n",
      "Epoch 141/500, Loss: 6126.0771484375\n",
      "Epoch 142/500, Loss: 1237.7049560546875\n",
      "Epoch 143/500, Loss: 945.1493530273438\n",
      "Epoch 144/500, Loss: 5394.71630859375\n",
      "Epoch 145/500, Loss: 16001.63671875\n",
      "Epoch 146/500, Loss: 2002.4058837890625\n",
      "Epoch 147/500, Loss: 1334.18212890625\n",
      "Epoch 148/500, Loss: 1427.8310546875\n",
      "Epoch 149/500, Loss: 852.671630859375\n",
      "Epoch 150/500, Loss: 7024.85498046875\n",
      "Epoch 151/500, Loss: 5937.68994140625\n",
      "Epoch 152/500, Loss: 1725.939208984375\n",
      "Epoch 153/500, Loss: 3498.06494140625\n",
      "Epoch 154/500, Loss: 3240.856689453125\n",
      "Epoch 155/500, Loss: 3102.510498046875\n",
      "Epoch 156/500, Loss: 1121.4603271484375\n",
      "Epoch 157/500, Loss: 1538.113525390625\n",
      "Epoch 158/500, Loss: 1194.2218017578125\n",
      "Epoch 159/500, Loss: 10361.1103515625\n",
      "Epoch 160/500, Loss: 1366.6368408203125\n",
      "Epoch 161/500, Loss: 3859.059814453125\n",
      "Epoch 162/500, Loss: 1338.855712890625\n",
      "Epoch 163/500, Loss: 1638.5330810546875\n",
      "Epoch 164/500, Loss: 3450.060302734375\n",
      "Epoch 165/500, Loss: 3039.46337890625\n",
      "Epoch 166/500, Loss: 859.6995849609375\n",
      "Epoch 167/500, Loss: 3815.516845703125\n",
      "Epoch 168/500, Loss: 12933.8447265625\n",
      "Epoch 169/500, Loss: 1626.6925048828125\n",
      "Epoch 170/500, Loss: 6816.23486328125\n",
      "Epoch 171/500, Loss: 2155.963134765625\n",
      "Epoch 172/500, Loss: 3206.9423828125\n",
      "Epoch 173/500, Loss: 770.689697265625\n",
      "Epoch 174/500, Loss: 2947.013427734375\n",
      "Epoch 175/500, Loss: 4512.1123046875\n",
      "Epoch 176/500, Loss: 4686.87744140625\n",
      "Epoch 177/500, Loss: 1069.9952392578125\n",
      "Epoch 178/500, Loss: 12759.3525390625\n",
      "Epoch 179/500, Loss: 1425.0430908203125\n",
      "Epoch 180/500, Loss: 1313.68701171875\n",
      "Epoch 181/500, Loss: 2052.183837890625\n",
      "Epoch 182/500, Loss: 2737.753173828125\n",
      "Epoch 183/500, Loss: 1857.6546630859375\n",
      "Epoch 184/500, Loss: 6005.0693359375\n",
      "Epoch 185/500, Loss: 2076.85595703125\n",
      "Epoch 186/500, Loss: 17861.81640625\n",
      "Epoch 187/500, Loss: 3844.688720703125\n",
      "Epoch 188/500, Loss: 1827.9207763671875\n",
      "Epoch 189/500, Loss: 2642.59130859375\n",
      "Epoch 190/500, Loss: 1464.598876953125\n",
      "Epoch 191/500, Loss: 2720.029541015625\n",
      "Epoch 192/500, Loss: 2377.186767578125\n",
      "Epoch 193/500, Loss: 1432.5655517578125\n",
      "Epoch 194/500, Loss: 1320.7008056640625\n",
      "Epoch 195/500, Loss: 4551.70166015625\n",
      "Epoch 196/500, Loss: 1364.493408203125\n",
      "Epoch 197/500, Loss: 2395.3876953125\n",
      "Epoch 198/500, Loss: 1613.8448486328125\n",
      "Epoch 199/500, Loss: 2869.94970703125\n",
      "Epoch 200/500, Loss: 1926.027587890625\n",
      "Epoch 201/500, Loss: 955.4747924804688\n",
      "Epoch 202/500, Loss: 1199.0108642578125\n",
      "Epoch 203/500, Loss: 6292.93310546875\n",
      "Epoch 204/500, Loss: 2781.708740234375\n",
      "Epoch 205/500, Loss: 1819.2529296875\n",
      "Epoch 206/500, Loss: 1434.739990234375\n",
      "Epoch 207/500, Loss: 2280.6787109375\n",
      "Epoch 208/500, Loss: 1546.4549560546875\n",
      "Epoch 209/500, Loss: 3153.213623046875\n",
      "Epoch 210/500, Loss: 3194.374267578125\n",
      "Epoch 211/500, Loss: 3288.449951171875\n",
      "Epoch 212/500, Loss: 2760.29736328125\n",
      "Epoch 213/500, Loss: 1562.6793212890625\n",
      "Epoch 214/500, Loss: 3141.267822265625\n",
      "Epoch 215/500, Loss: 1061.1063232421875\n",
      "Epoch 216/500, Loss: 1614.6422119140625\n",
      "Epoch 217/500, Loss: 2034.091796875\n",
      "Epoch 218/500, Loss: 1628.466064453125\n",
      "Epoch 219/500, Loss: 2135.919189453125\n",
      "Epoch 220/500, Loss: 2705.423583984375\n",
      "Epoch 221/500, Loss: 2241.427490234375\n",
      "Epoch 222/500, Loss: 3660.15283203125\n",
      "Epoch 223/500, Loss: 3524.161865234375\n",
      "Epoch 224/500, Loss: 1704.83935546875\n",
      "Epoch 225/500, Loss: 1450.3828125\n",
      "Epoch 226/500, Loss: 2361.693603515625\n",
      "Epoch 227/500, Loss: 5349.2119140625\n",
      "Epoch 228/500, Loss: 2128.791748046875\n",
      "Epoch 229/500, Loss: 5813.0458984375\n",
      "Epoch 230/500, Loss: 4062.17236328125\n",
      "Epoch 231/500, Loss: 4694.828125\n",
      "Epoch 232/500, Loss: 5182.78759765625\n",
      "Epoch 233/500, Loss: 4204.80517578125\n",
      "Epoch 234/500, Loss: 1600.62841796875\n",
      "Epoch 235/500, Loss: 2215.41357421875\n",
      "Epoch 236/500, Loss: 1827.591552734375\n",
      "Epoch 237/500, Loss: 1100.3660888671875\n",
      "Epoch 238/500, Loss: 10144.6875\n",
      "Epoch 239/500, Loss: 2515.64404296875\n",
      "Epoch 240/500, Loss: 1379.0535888671875\n",
      "Epoch 241/500, Loss: 2084.20556640625\n",
      "Epoch 242/500, Loss: 2870.990966796875\n",
      "Epoch 243/500, Loss: 1666.782470703125\n",
      "Epoch 244/500, Loss: 790.0028686523438\n",
      "Epoch 245/500, Loss: 1631.51806640625\n",
      "Epoch 246/500, Loss: 3614.924560546875\n",
      "Epoch 247/500, Loss: 1864.896484375\n",
      "Epoch 248/500, Loss: 1031.7347412109375\n",
      "Epoch 249/500, Loss: 2673.270263671875\n",
      "Epoch 250/500, Loss: 1000.214111328125\n",
      "Epoch 251/500, Loss: 3140.418701171875\n",
      "Epoch 252/500, Loss: 1287.7734375\n",
      "Epoch 253/500, Loss: 10251.6787109375\n",
      "Epoch 254/500, Loss: 3070.04833984375\n",
      "Epoch 255/500, Loss: 1206.0235595703125\n",
      "Epoch 256/500, Loss: 3501.112060546875\n",
      "Epoch 257/500, Loss: 2081.43115234375\n",
      "Epoch 258/500, Loss: 1729.5654296875\n",
      "Epoch 259/500, Loss: 959.5870971679688\n",
      "Epoch 260/500, Loss: 3555.591796875\n",
      "Epoch 261/500, Loss: 3896.108154296875\n",
      "Epoch 262/500, Loss: 2957.5947265625\n",
      "Epoch 263/500, Loss: 3963.282958984375\n",
      "Epoch 264/500, Loss: 3169.786376953125\n",
      "Epoch 265/500, Loss: 3556.6513671875\n",
      "Epoch 266/500, Loss: 2966.4287109375\n",
      "Epoch 267/500, Loss: 1359.5146484375\n",
      "Epoch 268/500, Loss: 1597.98828125\n",
      "Epoch 269/500, Loss: 1768.7265625\n",
      "Epoch 270/500, Loss: 8930.6845703125\n",
      "Epoch 271/500, Loss: 1581.4219970703125\n",
      "Epoch 272/500, Loss: 2390.3955078125\n",
      "Epoch 273/500, Loss: 9337.4306640625\n",
      "Epoch 274/500, Loss: 1859.787109375\n",
      "Epoch 275/500, Loss: 3080.30810546875\n",
      "Epoch 276/500, Loss: 5170.5322265625\n",
      "Epoch 277/500, Loss: 1242.642333984375\n",
      "Epoch 278/500, Loss: 2512.365234375\n",
      "Epoch 279/500, Loss: 1629.166259765625\n",
      "Epoch 280/500, Loss: 1579.7679443359375\n",
      "Epoch 281/500, Loss: 1021.2633666992188\n",
      "Epoch 282/500, Loss: 3628.338623046875\n",
      "Epoch 283/500, Loss: 3450.403076171875\n",
      "Epoch 284/500, Loss: 16080.7275390625\n",
      "Epoch 285/500, Loss: 1006.3607788085938\n",
      "Epoch 286/500, Loss: 6127.55908203125\n",
      "Epoch 287/500, Loss: 1468.743896484375\n",
      "Epoch 288/500, Loss: 1971.4783935546875\n",
      "Epoch 289/500, Loss: 1475.641845703125\n",
      "Epoch 290/500, Loss: 3352.537841796875\n",
      "Epoch 291/500, Loss: 4305.13916015625\n",
      "Epoch 292/500, Loss: 4041.847412109375\n",
      "Epoch 293/500, Loss: 3305.02001953125\n",
      "Epoch 294/500, Loss: 6163.7216796875\n",
      "Epoch 295/500, Loss: 1600.091064453125\n",
      "Epoch 296/500, Loss: 3024.11181640625\n",
      "Epoch 297/500, Loss: 1987.474365234375\n",
      "Epoch 298/500, Loss: 3854.1748046875\n",
      "Epoch 299/500, Loss: 1929.226806640625\n",
      "Epoch 300/500, Loss: 5266.8603515625\n",
      "Epoch 301/500, Loss: 1405.5537109375\n",
      "Epoch 302/500, Loss: 2701.97900390625\n",
      "Epoch 303/500, Loss: 1243.28564453125\n",
      "Epoch 304/500, Loss: 2276.79443359375\n",
      "Epoch 305/500, Loss: 3838.76708984375\n",
      "Epoch 306/500, Loss: 19069.84375\n",
      "Epoch 307/500, Loss: 1306.72265625\n",
      "Epoch 308/500, Loss: 1818.613525390625\n",
      "Epoch 309/500, Loss: 938.6859130859375\n",
      "Epoch 310/500, Loss: 4241.46923828125\n",
      "Epoch 311/500, Loss: 1589.9659423828125\n",
      "Epoch 312/500, Loss: 2177.182373046875\n",
      "Epoch 313/500, Loss: 4047.592041015625\n",
      "Epoch 314/500, Loss: 8919.2578125\n",
      "Epoch 315/500, Loss: 12904.7685546875\n",
      "Epoch 316/500, Loss: 2484.439697265625\n",
      "Epoch 317/500, Loss: 1426.63525390625\n",
      "Epoch 318/500, Loss: 9491.9033203125\n",
      "Epoch 319/500, Loss: 4034.81298828125\n",
      "Epoch 320/500, Loss: 1494.950927734375\n",
      "Epoch 321/500, Loss: 6587.05029296875\n",
      "Epoch 322/500, Loss: 1972.96435546875\n",
      "Epoch 323/500, Loss: 4733.625\n",
      "Epoch 324/500, Loss: 11411.623046875\n",
      "Epoch 325/500, Loss: 2589.270263671875\n",
      "Epoch 326/500, Loss: 2486.1689453125\n",
      "Epoch 327/500, Loss: 1739.1534423828125\n",
      "Epoch 328/500, Loss: 852.6359252929688\n",
      "Epoch 329/500, Loss: 2575.75146484375\n",
      "Epoch 330/500, Loss: 6749.91357421875\n",
      "Epoch 331/500, Loss: 2007.730224609375\n",
      "Epoch 332/500, Loss: 2454.04833984375\n",
      "Epoch 333/500, Loss: 2437.38427734375\n",
      "Epoch 334/500, Loss: 4253.72802734375\n",
      "Epoch 335/500, Loss: 52687.41015625\n",
      "Epoch 336/500, Loss: 1347.959716796875\n",
      "Epoch 337/500, Loss: 3213.497802734375\n",
      "Epoch 338/500, Loss: 2127.272705078125\n",
      "Epoch 339/500, Loss: 2890.640625\n",
      "Epoch 340/500, Loss: 630.2762451171875\n",
      "Epoch 341/500, Loss: 3035.3974609375\n",
      "Epoch 342/500, Loss: 3867.581787109375\n",
      "Epoch 343/500, Loss: 2722.486572265625\n",
      "Epoch 344/500, Loss: 1084.801513671875\n",
      "Epoch 345/500, Loss: 1430.5050048828125\n",
      "Epoch 346/500, Loss: 4877.4521484375\n",
      "Epoch 347/500, Loss: 2443.66357421875\n",
      "Epoch 348/500, Loss: 2439.8828125\n",
      "Epoch 349/500, Loss: 1800.3216552734375\n",
      "Epoch 350/500, Loss: 2653.515625\n",
      "Epoch 351/500, Loss: 3023.3583984375\n",
      "Epoch 352/500, Loss: 2096.9208984375\n",
      "Epoch 353/500, Loss: 3743.153076171875\n",
      "Epoch 354/500, Loss: 2514.817138671875\n",
      "Epoch 355/500, Loss: 1351.7686767578125\n",
      "Epoch 356/500, Loss: 2868.846923828125\n",
      "Epoch 357/500, Loss: 1474.0345458984375\n",
      "Epoch 358/500, Loss: 7408.1328125\n",
      "Epoch 359/500, Loss: 6332.6640625\n",
      "Epoch 360/500, Loss: 4303.73095703125\n",
      "Epoch 361/500, Loss: 3777.1162109375\n",
      "Epoch 362/500, Loss: 10664.646484375\n",
      "Epoch 363/500, Loss: 3376.64306640625\n",
      "Epoch 364/500, Loss: 1267.49365234375\n",
      "Epoch 365/500, Loss: 1476.185302734375\n",
      "Epoch 366/500, Loss: 1685.85205078125\n",
      "Epoch 367/500, Loss: 2376.604248046875\n",
      "Epoch 368/500, Loss: 1787.896728515625\n",
      "Epoch 369/500, Loss: 4610.365234375\n",
      "Epoch 370/500, Loss: 5483.2666015625\n",
      "Epoch 371/500, Loss: 1781.9349365234375\n",
      "Epoch 372/500, Loss: 2295.376220703125\n",
      "Epoch 373/500, Loss: 6935.3212890625\n",
      "Epoch 374/500, Loss: 8877.9912109375\n",
      "Epoch 375/500, Loss: 2758.0634765625\n",
      "Epoch 376/500, Loss: 4196.375\n",
      "Epoch 377/500, Loss: 1855.1229248046875\n",
      "Epoch 378/500, Loss: 2037.017822265625\n",
      "Epoch 379/500, Loss: 2329.901123046875\n",
      "Epoch 380/500, Loss: 2544.846923828125\n",
      "Epoch 381/500, Loss: 1572.5909423828125\n",
      "Epoch 382/500, Loss: 1427.6451416015625\n",
      "Epoch 383/500, Loss: 1041.42431640625\n",
      "Epoch 384/500, Loss: 4943.6083984375\n",
      "Epoch 385/500, Loss: 1939.31201171875\n",
      "Epoch 386/500, Loss: 5844.92724609375\n",
      "Epoch 387/500, Loss: 4803.0546875\n",
      "Epoch 388/500, Loss: 2548.976318359375\n",
      "Epoch 389/500, Loss: 3577.02685546875\n",
      "Epoch 390/500, Loss: 7200.744140625\n",
      "Epoch 391/500, Loss: 1851.6007080078125\n",
      "Epoch 392/500, Loss: 958.6683349609375\n",
      "Epoch 393/500, Loss: 4473.59912109375\n",
      "Epoch 394/500, Loss: 1939.2691650390625\n",
      "Epoch 395/500, Loss: 986.211669921875\n",
      "Epoch 396/500, Loss: 1590.849365234375\n",
      "Epoch 397/500, Loss: 3998.071533203125\n",
      "Epoch 398/500, Loss: 1309.9429931640625\n",
      "Epoch 399/500, Loss: 1145.8919677734375\n",
      "Epoch 400/500, Loss: 28293.8984375\n",
      "Epoch 401/500, Loss: 1353.69091796875\n",
      "Epoch 402/500, Loss: 4790.35693359375\n",
      "Epoch 403/500, Loss: 2384.404296875\n",
      "Epoch 404/500, Loss: 1933.4505615234375\n",
      "Epoch 405/500, Loss: 4314.50732421875\n",
      "Epoch 406/500, Loss: 2602.2548828125\n",
      "Epoch 407/500, Loss: 5315.6484375\n",
      "Epoch 408/500, Loss: 2205.983642578125\n",
      "Epoch 409/500, Loss: 3172.493896484375\n",
      "Epoch 410/500, Loss: 2121.48828125\n",
      "Epoch 411/500, Loss: 3733.083251953125\n",
      "Epoch 412/500, Loss: 2990.544189453125\n",
      "Epoch 413/500, Loss: 1928.74560546875\n",
      "Epoch 414/500, Loss: 1453.6380615234375\n",
      "Epoch 415/500, Loss: 5630.24365234375\n",
      "Epoch 416/500, Loss: 15732.5029296875\n",
      "Epoch 417/500, Loss: 3413.7822265625\n",
      "Epoch 418/500, Loss: 1483.2315673828125\n",
      "Epoch 419/500, Loss: 1887.2506103515625\n",
      "Epoch 420/500, Loss: 3169.2861328125\n",
      "Epoch 421/500, Loss: 5782.79248046875\n",
      "Epoch 422/500, Loss: 1952.11181640625\n",
      "Epoch 423/500, Loss: 5125.69384765625\n",
      "Epoch 424/500, Loss: 2038.5677490234375\n",
      "Epoch 425/500, Loss: 2534.877197265625\n",
      "Epoch 426/500, Loss: 4677.92822265625\n",
      "Epoch 427/500, Loss: 2360.536865234375\n",
      "Epoch 428/500, Loss: 3639.974853515625\n",
      "Epoch 429/500, Loss: 3172.079833984375\n",
      "Epoch 430/500, Loss: 1868.872314453125\n",
      "Epoch 431/500, Loss: 874.161376953125\n",
      "Epoch 432/500, Loss: 14180.9033203125\n",
      "Epoch 433/500, Loss: 3455.030517578125\n",
      "Epoch 434/500, Loss: 4386.7080078125\n",
      "Epoch 435/500, Loss: 9343.359375\n",
      "Epoch 436/500, Loss: 3207.7392578125\n",
      "Epoch 437/500, Loss: 1647.04052734375\n",
      "Epoch 438/500, Loss: 1549.2696533203125\n",
      "Epoch 439/500, Loss: 10037.634765625\n",
      "Epoch 440/500, Loss: 2177.693359375\n",
      "Epoch 441/500, Loss: 2915.412353515625\n",
      "Epoch 442/500, Loss: 6341.99169921875\n",
      "Epoch 443/500, Loss: 2026.2196044921875\n",
      "Epoch 444/500, Loss: 2421.19287109375\n",
      "Epoch 445/500, Loss: 2001.6051025390625\n",
      "Epoch 446/500, Loss: 2254.106689453125\n",
      "Epoch 447/500, Loss: 20326.375\n",
      "Epoch 448/500, Loss: 2309.000244140625\n",
      "Epoch 449/500, Loss: 49089.71484375\n",
      "Epoch 450/500, Loss: 2819.673095703125\n",
      "Epoch 451/500, Loss: 4218.17431640625\n",
      "Epoch 452/500, Loss: 4299.57666015625\n",
      "Epoch 453/500, Loss: 2437.28466796875\n",
      "Epoch 454/500, Loss: 3284.322998046875\n",
      "Epoch 455/500, Loss: 2101.953369140625\n",
      "Epoch 456/500, Loss: 1592.9561767578125\n",
      "Epoch 457/500, Loss: 1149.263671875\n",
      "Epoch 458/500, Loss: 1685.5162353515625\n",
      "Epoch 459/500, Loss: 3553.7255859375\n",
      "Epoch 460/500, Loss: 4669.74658203125\n",
      "Epoch 461/500, Loss: 1249.1866455078125\n",
      "Epoch 462/500, Loss: 4535.9697265625\n",
      "Epoch 463/500, Loss: 1941.829345703125\n",
      "Epoch 464/500, Loss: 7937.0146484375\n",
      "Epoch 465/500, Loss: 2971.231689453125\n",
      "Epoch 466/500, Loss: 2700.086181640625\n",
      "Epoch 467/500, Loss: 2390.554931640625\n",
      "Epoch 468/500, Loss: 5494.51171875\n",
      "Epoch 469/500, Loss: 3583.84375\n",
      "Epoch 470/500, Loss: 2800.025634765625\n",
      "Epoch 471/500, Loss: 3961.021240234375\n",
      "Epoch 472/500, Loss: 1455.01171875\n",
      "Epoch 473/500, Loss: 1228.8961181640625\n",
      "Epoch 474/500, Loss: 2261.80224609375\n",
      "Epoch 475/500, Loss: 1768.5968017578125\n",
      "Epoch 476/500, Loss: 1579.7708740234375\n",
      "Epoch 477/500, Loss: 943.8201904296875\n",
      "Epoch 478/500, Loss: 1612.659912109375\n",
      "Epoch 479/500, Loss: 7342.96337890625\n",
      "Epoch 480/500, Loss: 2503.42236328125\n",
      "Epoch 481/500, Loss: 2909.66650390625\n",
      "Epoch 482/500, Loss: 6438.60107421875\n",
      "Epoch 483/500, Loss: 1513.1221923828125\n",
      "Epoch 484/500, Loss: 3662.033447265625\n",
      "Epoch 485/500, Loss: 1492.36767578125\n",
      "Epoch 486/500, Loss: 1300.2677001953125\n",
      "Epoch 487/500, Loss: 1437.61669921875\n",
      "Epoch 488/500, Loss: 1479.387451171875\n",
      "Epoch 489/500, Loss: 3894.419921875\n",
      "Epoch 490/500, Loss: 4841.3193359375\n",
      "Epoch 491/500, Loss: 3417.78564453125\n",
      "Epoch 492/500, Loss: 3114.177001953125\n",
      "Epoch 493/500, Loss: 6702.5703125\n",
      "Epoch 494/500, Loss: 2499.4521484375\n",
      "Epoch 495/500, Loss: 1726.7728271484375\n",
      "Epoch 496/500, Loss: 3013.759521484375\n",
      "Epoch 497/500, Loss: 1849.5380859375\n",
      "Epoch 498/500, Loss: 2811.8984375\n",
      "Epoch 499/500, Loss: 3028.319091796875\n",
      "Epoch 500/500, Loss: 2708.1875\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model evalueren"
   ],
   "id": "4264b461dc76c362"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:48:30.583274Z",
     "start_time": "2024-04-16T08:48:30.579047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).squeeze()\n",
    "    loss = criterion(predictions, y_test_tensor)\n",
    "print(f'Test Loss: {loss.item()}')"
   ],
   "id": "e5f80e9088cf4e94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3318.3095703125\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       Predicted  Actual  Difference  Absolute Difference\n9130   51.624249    56.0   -4.375751             4.375751\n27718  51.624249    36.0   15.624249            15.624249\n41898  51.624249    26.0   25.624249            25.624249\n15673  51.624249    24.0   27.624249            27.624249\n2314   51.624249    46.0    5.624249             5.624249\n...          ...     ...         ...                  ...\n38076  51.624249    46.0    5.624249             5.624249\n18731  51.624249    94.0  -42.375751            42.375751\n2460   51.624249    56.0   -4.375751             4.375751\n15719  51.624249    90.0  -38.375751            38.375751\n39153  51.624249     6.0   45.624249            45.624249\n\n[8613 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted</th>\n      <th>Actual</th>\n      <th>Difference</th>\n      <th>Absolute Difference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9130</th>\n      <td>51.624249</td>\n      <td>56.0</td>\n      <td>-4.375751</td>\n      <td>4.375751</td>\n    </tr>\n    <tr>\n      <th>27718</th>\n      <td>51.624249</td>\n      <td>36.0</td>\n      <td>15.624249</td>\n      <td>15.624249</td>\n    </tr>\n    <tr>\n      <th>41898</th>\n      <td>51.624249</td>\n      <td>26.0</td>\n      <td>25.624249</td>\n      <td>25.624249</td>\n    </tr>\n    <tr>\n      <th>15673</th>\n      <td>51.624249</td>\n      <td>24.0</td>\n      <td>27.624249</td>\n      <td>27.624249</td>\n    </tr>\n    <tr>\n      <th>2314</th>\n      <td>51.624249</td>\n      <td>46.0</td>\n      <td>5.624249</td>\n      <td>5.624249</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38076</th>\n      <td>51.624249</td>\n      <td>46.0</td>\n      <td>5.624249</td>\n      <td>5.624249</td>\n    </tr>\n    <tr>\n      <th>18731</th>\n      <td>51.624249</td>\n      <td>94.0</td>\n      <td>-42.375751</td>\n      <td>42.375751</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>51.624249</td>\n      <td>56.0</td>\n      <td>-4.375751</td>\n      <td>4.375751</td>\n    </tr>\n    <tr>\n      <th>15719</th>\n      <td>51.624249</td>\n      <td>90.0</td>\n      <td>-38.375751</td>\n      <td>38.375751</td>\n    </tr>\n    <tr>\n      <th>39153</th>\n      <td>51.624249</td>\n      <td>6.0</td>\n      <td>45.624249</td>\n      <td>45.624249</td>\n    </tr>\n  </tbody>\n</table>\n<p>8613 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the predictions to the cpu\n",
    "predictions_cpu_tensor = predictions.detach().cpu()\n",
    "y_test_cpu_tensor = y_test_tensor.cpu()\n",
    "\n",
    "# Convert the predictions to a numpy array\n",
    "predictions_np = predictions_cpu_tensor.numpy()\n",
    "y_test_np = y_test_cpu_tensor.numpy()\n",
    "\n",
    "# Convert the numpy array to a pandas DataFrame\n",
    "predictions_df = pd.DataFrame(predictions_np, columns=['Predicted'], index=X_test.index)\n",
    "\n",
    "# Convert the actual values to a pandas DataFrame\n",
    "actual_df = pd.DataFrame(y_test_np, columns=['Actual'], index=X_test.index)\n",
    "\n",
    "# Concatenate the two dataframes along the column axis\n",
    "result_df = pd.concat([predictions_df, actual_df], axis=1)\n",
    "\n",
    "# adding difference and absolute difference\n",
    "result_df['Difference'] = result_df['Predicted'] - result_df['Actual']\n",
    "result_df['Absolute Difference'] = abs(result_df['Difference'])\n",
    "\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T08:48:30.595395Z",
     "start_time": "2024-04-16T08:48:30.584279Z"
    }
   },
   "id": "dd1d4f1680fdf576",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the average difference\n",
    "average_difference = result_df['Absolute Difference'].mean()\n",
    "print(f'Average Difference: {average_difference}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd5798588577f44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scratch\n",
    "Een neural network maken zonder gebruik te maken van een library"
   ],
   "id": "a92666033051abe6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model maken"
   ],
   "id": "fad4368ab5282f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:48:30.604637Z",
     "start_time": "2024-04-16T08:48:30.596402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomNeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5,\n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5,\n",
    "                                       (self.hidden_nodes, 1))\n",
    "        self.bias_hidden = np.zeros(self.hidden_nodes)\n",
    "        self.bias_output = np.zeros(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def linear(x):\n",
    "        return x\n",
    "\n",
    "    def forward_pass(self, X):\n",
    "        hidden_layer_input = np.dot(X, self.weights_input_to_hidden) + self.bias_hidden\n",
    "        hidden_layer_output = self.linear(hidden_layer_input)\n",
    "\n",
    "        output_layer_input = np.dot(hidden_layer_output, self.weights_hidden_to_output) + self.bias_output\n",
    "        output_layer_output = self.linear(output_layer_input)\n",
    "\n",
    "        return hidden_layer_output, output_layer_output\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_error(y, final_outputs):\n",
    "        return y - final_outputs\n",
    "\n",
    "    def update_weights(self, X, hidden_outputs, error, lr):\n",
    "        epsilon = 1e-8\n",
    "        # Simple rule for updating weights\n",
    "        for i in range(self.weights_input_to_hidden.shape[0]):\n",
    "            for j in range(self.weights_input_to_hidden.shape[1]):\n",
    "                for k in range(X.shape[0]):\n",
    "                    self.weights_input_to_hidden[i, j] += lr * error[k][0] * X[k, i] / (np.abs(hidden_outputs[k, j]) + epsilon)\n",
    "                    \n",
    "    def calculate_loss(self, y, final_outputs):\n",
    "        # Calculate the Mean Squared Error loss\n",
    "        return np.mean((y - final_outputs) ** 2)\n",
    "\n",
    "        \n",
    "    def train(self, X, y, lr, batch_size=50):\n",
    "        # normalize the input data\n",
    "        X = X / np.max(X, axis=0)\n",
    "        \n",
    "        # Initialize the loss\n",
    "        loss = 0.0\n",
    "        \n",
    "        # Batch training\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            X_batch = X[i:i+batch_size]\n",
    "            y_batch = y[i:i+batch_size]\n",
    "            \n",
    "            hidden_outputs, final_outputs = self.forward_pass(X_batch)\n",
    "            error = self.calculate_error(y_batch, final_outputs)\n",
    "            self.update_weights(X_batch, hidden_outputs, error, lr)\n",
    "            loss = self.calculate_loss(y_batch, final_outputs)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        _, final_outputs = self.forward_pass(X)\n",
    "        return final_outputs"
   ],
   "id": "4b1362a323153efd",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T08:48:30.609154Z",
     "start_time": "2024-04-16T08:48:30.605643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the neural network\n",
    "nn = CustomNeuralNetwork(input_nodes=4, hidden_nodes=8)"
   ],
   "id": "95839ed30be18c2b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model trainen"
   ],
   "id": "3cfdc9c2363e3485"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T09:00:40.102897Z",
     "start_time": "2024-04-16T08:48:30.610160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert pandas DataFrame to numpy array\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):  # number of epochs\n",
    "    loss = nn.train(X_train_np, y_train_np, lr=0.001, batch_size=batch_size)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss(MSE): {loss}')"
   ],
   "id": "eef1bdfb6780a4a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss(MSE): 41.39129093631583\n",
      "Epoch 2/500, Loss(MSE): 41.7811476793938\n",
      "Epoch 3/500, Loss(MSE): 41.82521275104665\n",
      "Epoch 4/500, Loss(MSE): 41.82275250923871\n",
      "Epoch 5/500, Loss(MSE): 41.81702020019149\n",
      "Epoch 6/500, Loss(MSE): 41.81250978254357\n",
      "Epoch 7/500, Loss(MSE): 41.80912320812436\n",
      "Epoch 8/500, Loss(MSE): 41.80652497484913\n",
      "Epoch 9/500, Loss(MSE): 41.80444805017139\n",
      "Epoch 10/500, Loss(MSE): 41.80281798882764\n",
      "Epoch 11/500, Loss(MSE): 41.801581614892264\n",
      "Epoch 12/500, Loss(MSE): 41.80054771944224\n",
      "Epoch 13/500, Loss(MSE): 41.7996823722765\n",
      "Epoch 14/500, Loss(MSE): 41.79896591069845\n",
      "Epoch 15/500, Loss(MSE): 41.79838766021559\n",
      "Epoch 16/500, Loss(MSE): 41.79791272785633\n",
      "Epoch 17/500, Loss(MSE): 41.79752717213745\n",
      "Epoch 18/500, Loss(MSE): 41.79721890302286\n",
      "Epoch 19/500, Loss(MSE): 41.79697736425153\n",
      "Epoch 20/500, Loss(MSE): 41.79679337149186\n",
      "Epoch 21/500, Loss(MSE): 41.79666053311607\n",
      "Epoch 22/500, Loss(MSE): 41.79656943126193\n",
      "Epoch 23/500, Loss(MSE): 41.796522123429234\n",
      "Epoch 24/500, Loss(MSE): 41.79650975946178\n",
      "Epoch 25/500, Loss(MSE): 41.79652636067026\n",
      "Epoch 26/500, Loss(MSE): 41.7965653001277\n",
      "Epoch 27/500, Loss(MSE): 41.796623232430875\n",
      "Epoch 28/500, Loss(MSE): 41.79669735892686\n",
      "Epoch 29/500, Loss(MSE): 41.7967865633443\n",
      "Epoch 30/500, Loss(MSE): 41.79688748952675\n",
      "Epoch 31/500, Loss(MSE): 41.79699830412681\n",
      "Epoch 32/500, Loss(MSE): 41.79712375480658\n",
      "Epoch 33/500, Loss(MSE): 41.79727148827561\n",
      "Epoch 34/500, Loss(MSE): 41.797424819177806\n",
      "Epoch 35/500, Loss(MSE): 41.7975827971217\n",
      "Epoch 36/500, Loss(MSE): 41.79774461050342\n",
      "Epoch 37/500, Loss(MSE): 41.79790956626838\n",
      "Epoch 38/500, Loss(MSE): 41.798077072565306\n",
      "Epoch 39/500, Loss(MSE): 41.79824662390638\n",
      "Epoch 40/500, Loss(MSE): 41.798417788487676\n",
      "Epoch 41/500, Loss(MSE): 41.79859019736658\n",
      "Epoch 42/500, Loss(MSE): 41.79876353523471\n",
      "Epoch 43/500, Loss(MSE): 41.79893753255523\n",
      "Epoch 44/500, Loss(MSE): 41.799111958867414\n",
      "Epoch 45/500, Loss(MSE): 41.79928661708784\n",
      "Epoch 46/500, Loss(MSE): 41.79946133866132\n",
      "Epoch 47/500, Loss(MSE): 41.79963959066752\n",
      "Epoch 48/500, Loss(MSE): 41.79982108012733\n",
      "Epoch 49/500, Loss(MSE): 41.8000022277061\n",
      "Epoch 50/500, Loss(MSE): 41.800182945191374\n",
      "Epoch 51/500, Loss(MSE): 41.800363157336356\n",
      "Epoch 52/500, Loss(MSE): 41.800542800062665\n",
      "Epoch 53/500, Loss(MSE): 41.80072590001389\n",
      "Epoch 54/500, Loss(MSE): 41.80090922412568\n",
      "Epoch 55/500, Loss(MSE): 41.80109182092067\n",
      "Epoch 56/500, Loss(MSE): 41.801273657220506\n",
      "Epoch 57/500, Loss(MSE): 41.80145470544338\n",
      "Epoch 58/500, Loss(MSE): 41.801634942904485\n",
      "Epoch 59/500, Loss(MSE): 41.80181435121923\n",
      "Epoch 60/500, Loss(MSE): 41.80199291579273\n",
      "Epoch 61/500, Loss(MSE): 41.80217062538389\n",
      "Epoch 62/500, Loss(MSE): 41.80234747173101\n",
      "Epoch 63/500, Loss(MSE): 41.80252344923211\n",
      "Epoch 64/500, Loss(MSE): 41.80269855466738\n",
      "Epoch 65/500, Loss(MSE): 41.80287278696267\n",
      "Epoch 66/500, Loss(MSE): 41.80304614698283\n",
      "Epoch 67/500, Loss(MSE): 41.803218637352394\n",
      "Epoch 68/500, Loss(MSE): 41.80339620179645\n",
      "Epoch 69/500, Loss(MSE): 41.803580579984136\n",
      "Epoch 70/500, Loss(MSE): 41.803764061177105\n",
      "Epoch 71/500, Loss(MSE): 41.803946653914885\n",
      "Epoch 72/500, Loss(MSE): 41.80412836787159\n",
      "Epoch 73/500, Loss(MSE): 41.80430921377315\n",
      "Epoch 74/500, Loss(MSE): 41.804489203322454\n",
      "Epoch 75/500, Loss(MSE): 41.80466834913038\n",
      "Epoch 76/500, Loss(MSE): 41.80484666465368\n",
      "Epoch 77/500, Loss(MSE): 41.805024164136526\n",
      "Epoch 78/500, Loss(MSE): 41.805200862556426\n",
      "Epoch 79/500, Loss(MSE): 41.805383106631986\n",
      "Epoch 80/500, Loss(MSE): 41.805564961940654\n",
      "Epoch 81/500, Loss(MSE): 41.805746039440486\n",
      "Epoch 82/500, Loss(MSE): 41.80592635678232\n",
      "Epoch 83/500, Loss(MSE): 41.806105932123124\n",
      "Epoch 84/500, Loss(MSE): 41.80628478408683\n",
      "Epoch 85/500, Loss(MSE): 41.80646293172433\n",
      "Epoch 86/500, Loss(MSE): 41.80664039447623\n",
      "Epoch 87/500, Loss(MSE): 41.8068171921357\n",
      "Epoch 88/500, Loss(MSE): 41.80699334481338\n",
      "Epoch 89/500, Loss(MSE): 41.80716887290164\n",
      "Epoch 90/500, Loss(MSE): 41.80734379704126\n",
      "Epoch 91/500, Loss(MSE): 41.80751813808832\n",
      "Epoch 92/500, Loss(MSE): 41.80769191708142\n",
      "Epoch 93/500, Loss(MSE): 41.807865155210315\n",
      "Epoch 94/500, Loss(MSE): 41.80803787378509\n",
      "Epoch 95/500, Loss(MSE): 41.8082100942066\n",
      "Epoch 96/500, Loss(MSE): 41.80838183793618\n",
      "Epoch 97/500, Loss(MSE): 41.80855312646814\n",
      "Epoch 98/500, Loss(MSE): 41.80872398130184\n",
      "Epoch 99/500, Loss(MSE): 41.80889442391447\n",
      "Epoch 100/500, Loss(MSE): 41.80906447573587\n",
      "Epoch 101/500, Loss(MSE): 41.809234158122166\n",
      "Epoch 102/500, Loss(MSE): 41.80940349233264\n",
      "Epoch 103/500, Loss(MSE): 41.8095724995052\n",
      "Epoch 104/500, Loss(MSE): 41.809741200635095\n",
      "Epoch 105/500, Loss(MSE): 41.809909616551714\n",
      "Epoch 106/500, Loss(MSE): 41.81008089982772\n",
      "Epoch 107/500, Loss(MSE): 41.81025341670385\n",
      "Epoch 108/500, Loss(MSE): 41.81042570409745\n",
      "Epoch 109/500, Loss(MSE): 41.81059778207959\n",
      "Epoch 110/500, Loss(MSE): 41.81076967045517\n",
      "Epoch 111/500, Loss(MSE): 41.810941388747494\n",
      "Epoch 112/500, Loss(MSE): 41.8111129561819\n",
      "Epoch 113/500, Loss(MSE): 41.811284391672814\n",
      "Epoch 114/500, Loss(MSE): 41.81145571380868\n",
      "Epoch 115/500, Loss(MSE): 41.81162694084105\n",
      "Epoch 116/500, Loss(MSE): 41.81179809067153\n",
      "Epoch 117/500, Loss(MSE): 41.81196918084205\n",
      "Epoch 118/500, Loss(MSE): 41.81214022852398\n",
      "Epoch 119/500, Loss(MSE): 41.81231125051004\n",
      "Epoch 120/500, Loss(MSE): 41.812482263205574\n",
      "Epoch 121/500, Loss(MSE): 41.81265328262121\n",
      "Epoch 122/500, Loss(MSE): 41.81282432436639\n",
      "Epoch 123/500, Loss(MSE): 41.81299540364337\n",
      "Epoch 124/500, Loss(MSE): 41.81316653524231\n",
      "Epoch 125/500, Loss(MSE): 41.813337733536834\n",
      "Epoch 126/500, Loss(MSE): 41.81350901248076\n",
      "Epoch 127/500, Loss(MSE): 41.8136803856046\n",
      "Epoch 128/500, Loss(MSE): 41.81385186601371\n",
      "Epoch 129/500, Loss(MSE): 41.81402346638666\n",
      "Epoch 130/500, Loss(MSE): 41.81419519897423\n",
      "Epoch 131/500, Loss(MSE): 41.8143670755989\n",
      "Epoch 132/500, Loss(MSE): 41.8145423366279\n",
      "Epoch 133/500, Loss(MSE): 41.8147241252386\n",
      "Epoch 134/500, Loss(MSE): 41.814906048831915\n",
      "Epoch 135/500, Loss(MSE): 41.81508811768592\n",
      "Epoch 136/500, Loss(MSE): 41.815270341659264\n",
      "Epoch 137/500, Loss(MSE): 41.815452730192625\n",
      "Epoch 138/500, Loss(MSE): 41.8156352923127\n",
      "Epoch 139/500, Loss(MSE): 41.81581803663515\n",
      "Epoch 140/500, Loss(MSE): 41.81600097136792\n",
      "Epoch 141/500, Loss(MSE): 41.81618410431617\n",
      "Epoch 142/500, Loss(MSE): 41.81636744288571\n",
      "Epoch 143/500, Loss(MSE): 41.81655099408832\n",
      "Epoch 144/500, Loss(MSE): 41.81673476454647\n",
      "Epoch 145/500, Loss(MSE): 41.81691876049845\n",
      "Epoch 146/500, Loss(MSE): 41.81710298780389\n",
      "Epoch 147/500, Loss(MSE): 41.817287451949504\n",
      "Epoch 148/500, Loss(MSE): 41.81747215805487\n",
      "Epoch 149/500, Loss(MSE): 41.8176571108784\n",
      "Epoch 150/500, Loss(MSE): 41.817842314823785\n",
      "Epoch 151/500, Loss(MSE): 41.818027773946056\n",
      "Epoch 152/500, Loss(MSE): 41.81821349195839\n",
      "Epoch 153/500, Loss(MSE): 41.81839947223835\n",
      "Epoch 154/500, Loss(MSE): 41.81858571783473\n",
      "Epoch 155/500, Loss(MSE): 41.81877223147476\n",
      "Epoch 156/500, Loss(MSE): 41.8189590155703\n",
      "Epoch 157/500, Loss(MSE): 41.81914607222493\n",
      "Epoch 158/500, Loss(MSE): 41.819333403241416\n",
      "Epoch 159/500, Loss(MSE): 41.81952101012818\n",
      "Epoch 160/500, Loss(MSE): 41.81970889410629\n",
      "Epoch 161/500, Loss(MSE): 41.819897056117085\n",
      "Epoch 162/500, Loss(MSE): 41.82008549682848\n",
      "Epoch 163/500, Loss(MSE): 41.82027421664246\n",
      "Epoch 164/500, Loss(MSE): 41.820463215702105\n",
      "Epoch 165/500, Loss(MSE): 41.82065249389846\n",
      "Epoch 166/500, Loss(MSE): 41.82084205087734\n",
      "Epoch 167/500, Loss(MSE): 41.821031886046626\n",
      "Epoch 168/500, Loss(MSE): 41.82122199858291\n",
      "Epoch 169/500, Loss(MSE): 41.82141238743842\n",
      "Epoch 170/500, Loss(MSE): 41.821603051347545\n",
      "Epoch 171/500, Loss(MSE): 41.82179398883405\n",
      "Epoch 172/500, Loss(MSE): 41.82198519821722\n",
      "Epoch 173/500, Loss(MSE): 41.82217667761877\n",
      "Epoch 174/500, Loss(MSE): 41.82236842496894\n",
      "Epoch 175/500, Loss(MSE): 41.82256043801348\n",
      "Epoch 176/500, Loss(MSE): 41.82275271431935\n",
      "Epoch 177/500, Loss(MSE): 41.82294525128143\n",
      "Epoch 178/500, Loss(MSE): 41.82313804612859\n",
      "Epoch 179/500, Loss(MSE): 41.82333109592929\n",
      "Epoch 180/500, Loss(MSE): 41.82352439759791\n",
      "Epoch 181/500, Loss(MSE): 41.82371794790099\n",
      "Epoch 182/500, Loss(MSE): 41.82391174346221\n",
      "Epoch 183/500, Loss(MSE): 41.824105780768434\n",
      "Epoch 184/500, Loss(MSE): 41.824300056175225\n",
      "Epoch 185/500, Loss(MSE): 41.824494565912175\n",
      "Epoch 186/500, Loss(MSE): 41.82469129713699\n",
      "Epoch 187/500, Loss(MSE): 41.824890761050014\n",
      "Epoch 188/500, Loss(MSE): 41.82509043438609\n",
      "Epoch 189/500, Loss(MSE): 41.825290312944404\n",
      "Epoch 190/500, Loss(MSE): 41.825490392424264\n",
      "Epoch 191/500, Loss(MSE): 41.82569066842958\n",
      "Epoch 192/500, Loss(MSE): 41.82589113647373\n",
      "Epoch 193/500, Loss(MSE): 41.82609179198384\n",
      "Epoch 194/500, Loss(MSE): 41.82629263030585\n",
      "Epoch 195/500, Loss(MSE): 41.82649364670832\n",
      "Epoch 196/500, Loss(MSE): 41.826694836387134\n",
      "Epoch 197/500, Loss(MSE): 41.82689619446929\n",
      "Epoch 198/500, Loss(MSE): 41.827097716017064\n",
      "Epoch 199/500, Loss(MSE): 41.82729939603236\n",
      "Epoch 200/500, Loss(MSE): 41.82750122945983\n",
      "Epoch 201/500, Loss(MSE): 41.827703211191306\n",
      "Epoch 202/500, Loss(MSE): 41.82790533606914\n",
      "Epoch 203/500, Loss(MSE): 41.828107598889524\n",
      "Epoch 204/500, Loss(MSE): 41.82830999440663\n",
      "Epoch 205/500, Loss(MSE): 41.82851251733536\n",
      "Epoch 206/500, Loss(MSE): 41.828715162354705\n",
      "Epoch 207/500, Loss(MSE): 41.82891792411115\n",
      "Epoch 208/500, Loss(MSE): 41.829120797221584\n",
      "Epoch 209/500, Loss(MSE): 41.82932377627644\n",
      "Epoch 210/500, Loss(MSE): 41.82952685584223\n",
      "Epoch 211/500, Loss(MSE): 41.8297300304649\n",
      "Epoch 212/500, Loss(MSE): 41.82993329467215\n",
      "Epoch 213/500, Loss(MSE): 41.83013664297604\n",
      "Epoch 214/500, Loss(MSE): 41.83034082974634\n",
      "Epoch 215/500, Loss(MSE): 41.830553964422826\n",
      "Epoch 216/500, Loss(MSE): 41.83076728163236\n",
      "Epoch 217/500, Loss(MSE): 41.830985563712744\n",
      "Epoch 218/500, Loss(MSE): 41.8312038536806\n",
      "Epoch 219/500, Loss(MSE): 41.831422146178156\n",
      "Epoch 220/500, Loss(MSE): 41.83164043584755\n",
      "Epoch 221/500, Loss(MSE): 41.8318587173332\n",
      "Epoch 222/500, Loss(MSE): 41.83207698528394\n",
      "Epoch 223/500, Loss(MSE): 41.83229523435435\n",
      "Epoch 224/500, Loss(MSE): 41.832513459207085\n",
      "Epoch 225/500, Loss(MSE): 41.832731654514305\n",
      "Epoch 226/500, Loss(MSE): 41.83294981495969\n",
      "Epoch 227/500, Loss(MSE): 41.833167935239885\n",
      "Epoch 228/500, Loss(MSE): 41.83338601006593\n",
      "Epoch 229/500, Loss(MSE): 41.833604034165134\n",
      "Epoch 230/500, Loss(MSE): 41.83382200228202\n",
      "Epoch 231/500, Loss(MSE): 41.83403990918026\n",
      "Epoch 232/500, Loss(MSE): 41.834257749643704\n",
      "Epoch 233/500, Loss(MSE): 41.83447551847788\n",
      "Epoch 234/500, Loss(MSE): 41.83469321051065\n",
      "Epoch 235/500, Loss(MSE): 41.834910820594445\n",
      "Epoch 236/500, Loss(MSE): 41.83512834360618\n",
      "Epoch 237/500, Loss(MSE): 41.835345774449394\n",
      "Epoch 238/500, Loss(MSE): 41.835563108054735\n",
      "Epoch 239/500, Loss(MSE): 41.83578033938085\n",
      "Epoch 240/500, Loss(MSE): 41.8359974634159\n",
      "Epoch 241/500, Loss(MSE): 41.836214475177734\n",
      "Epoch 242/500, Loss(MSE): 41.836431369715186\n",
      "Epoch 243/500, Loss(MSE): 41.8366481421091\n",
      "Epoch 244/500, Loss(MSE): 41.836864787472706\n",
      "Epoch 245/500, Loss(MSE): 41.837081300952356\n",
      "Epoch 246/500, Loss(MSE): 41.83729767772872\n",
      "Epoch 247/500, Loss(MSE): 41.83751391301676\n",
      "Epoch 248/500, Loss(MSE): 41.83773000206699\n",
      "Epoch 249/500, Loss(MSE): 41.83794594016564\n",
      "Epoch 250/500, Loss(MSE): 41.83816172263553\n",
      "Epoch 251/500, Loss(MSE): 41.83837734483637\n",
      "Epoch 252/500, Loss(MSE): 41.83859280216555\n",
      "Epoch 253/500, Loss(MSE): 41.838808090058095\n",
      "Epoch 254/500, Loss(MSE): 41.83902320398795\n",
      "Epoch 255/500, Loss(MSE): 41.83923813946743\n",
      "Epoch 256/500, Loss(MSE): 41.83945289204834\n",
      "Epoch 257/500, Loss(MSE): 41.839667457322044\n",
      "Epoch 258/500, Loss(MSE): 41.8398818309199\n",
      "Epoch 259/500, Loss(MSE): 41.84009600851335\n",
      "Epoch 260/500, Loss(MSE): 41.840309985814464\n",
      "Epoch 261/500, Loss(MSE): 41.84052375857624\n",
      "Epoch 262/500, Loss(MSE): 41.84073732259261\n",
      "Epoch 263/500, Loss(MSE): 41.84095067369877\n",
      "Epoch 264/500, Loss(MSE): 41.841163807771245\n",
      "Epoch 265/500, Loss(MSE): 41.84137672072882\n",
      "Epoch 266/500, Loss(MSE): 41.841589408531306\n",
      "Epoch 267/500, Loss(MSE): 41.841801867181026\n",
      "Epoch 268/500, Loss(MSE): 41.842014092722174\n",
      "Epoch 269/500, Loss(MSE): 41.842226081241314\n",
      "Epoch 270/500, Loss(MSE): 41.842437828867055\n",
      "Epoch 271/500, Loss(MSE): 41.842649331770524\n",
      "Epoch 272/500, Loss(MSE): 41.842860586165216\n",
      "Epoch 273/500, Loss(MSE): 41.84307158830723\n",
      "Epoch 274/500, Loss(MSE): 41.843282334494965\n",
      "Epoch 275/500, Loss(MSE): 41.84349282106947\n",
      "Epoch 276/500, Loss(MSE): 41.843703044414006\n",
      "Epoch 277/500, Loss(MSE): 41.84391300095483\n",
      "Epoch 278/500, Loss(MSE): 41.84412268716036\n",
      "Epoch 279/500, Loss(MSE): 41.844332099541425\n",
      "Epoch 280/500, Loss(MSE): 41.84454123465147\n",
      "Epoch 281/500, Loss(MSE): 41.84475008908593\n",
      "Epoch 282/500, Loss(MSE): 41.84495865948286\n",
      "Epoch 283/500, Loss(MSE): 41.845166942522\n",
      "Epoch 284/500, Loss(MSE): 41.8453749349257\n",
      "Epoch 285/500, Loss(MSE): 41.84558263345824\n",
      "Epoch 286/500, Loss(MSE): 41.84579003492526\n",
      "Epoch 287/500, Loss(MSE): 41.84599713617468\n",
      "Epoch 288/500, Loss(MSE): 41.84620393409585\n",
      "Epoch 289/500, Loss(MSE): 41.84641042561959\n",
      "Epoch 290/500, Loss(MSE): 41.84661676240185\n",
      "Epoch 291/500, Loss(MSE): 41.84682567980132\n",
      "Epoch 292/500, Loss(MSE): 41.847034272482375\n",
      "Epoch 293/500, Loss(MSE): 41.847242537571596\n",
      "Epoch 294/500, Loss(MSE): 41.84745047223587\n",
      "Epoch 295/500, Loss(MSE): 41.847658073683\n",
      "Epoch 296/500, Loss(MSE): 41.84786533916082\n",
      "Epoch 297/500, Loss(MSE): 41.84807226595719\n",
      "Epoch 298/500, Loss(MSE): 41.848278851400075\n",
      "Epoch 299/500, Loss(MSE): 41.848485092857004\n",
      "Epoch 300/500, Loss(MSE): 41.8486909877349\n",
      "Epoch 301/500, Loss(MSE): 41.84889653348008\n",
      "Epoch 302/500, Loss(MSE): 41.849101727577704\n",
      "Epoch 303/500, Loss(MSE): 41.84930656755217\n",
      "Epoch 304/500, Loss(MSE): 41.84951105096618\n",
      "Epoch 305/500, Loss(MSE): 41.84971517542103\n",
      "Epoch 306/500, Loss(MSE): 41.84991893855609\n",
      "Epoch 307/500, Loss(MSE): 41.850122338048216\n",
      "Epoch 308/500, Loss(MSE): 41.85032537161291\n",
      "Epoch 309/500, Loss(MSE): 41.850528037002405\n",
      "Epoch 310/500, Loss(MSE): 41.85073033200666\n",
      "Epoch 311/500, Loss(MSE): 41.850932254451756\n",
      "Epoch 312/500, Loss(MSE): 41.85113380220168\n",
      "Epoch 313/500, Loss(MSE): 41.85133497315602\n",
      "Epoch 314/500, Loss(MSE): 41.85153576525072\n",
      "Epoch 315/500, Loss(MSE): 41.85173617645794\n",
      "Epoch 316/500, Loss(MSE): 41.85193620478566\n",
      "Epoch 317/500, Loss(MSE): 41.85213584827684\n",
      "Epoch 318/500, Loss(MSE): 41.852335105010305\n",
      "Epoch 319/500, Loss(MSE): 41.852533973099156\n",
      "Epoch 320/500, Loss(MSE): 41.852732450691434\n",
      "Epoch 321/500, Loss(MSE): 41.85293053596986\n",
      "Epoch 322/500, Loss(MSE): 41.853128227150975\n",
      "Epoch 323/500, Loss(MSE): 41.853325522485534\n",
      "Epoch 324/500, Loss(MSE): 41.85352242025765\n",
      "Epoch 325/500, Loss(MSE): 41.853718918784615\n",
      "Epoch 326/500, Loss(MSE): 41.85391501641752\n",
      "Epoch 327/500, Loss(MSE): 41.85411071153954\n",
      "Epoch 328/500, Loss(MSE): 41.854306002566744\n",
      "Epoch 329/500, Loss(MSE): 41.85450088794757\n",
      "Epoch 330/500, Loss(MSE): 41.85469536616232\n",
      "Epoch 331/500, Loss(MSE): 41.85488943572297\n",
      "Epoch 332/500, Loss(MSE): 41.85508309517334\n",
      "Epoch 333/500, Loss(MSE): 41.85527634308796\n",
      "Epoch 334/500, Loss(MSE): 41.85546917807271\n",
      "Epoch 335/500, Loss(MSE): 41.85566159876397\n",
      "Epoch 336/500, Loss(MSE): 41.85585360382848\n",
      "Epoch 337/500, Loss(MSE): 41.856045861789866\n",
      "Epoch 338/500, Loss(MSE): 41.8562413330675\n",
      "Epoch 339/500, Loss(MSE): 41.85643637265194\n",
      "Epoch 340/500, Loss(MSE): 41.85663097936408\n",
      "Epoch 341/500, Loss(MSE): 41.85682515205395\n",
      "Epoch 342/500, Loss(MSE): 41.85701888960039\n",
      "Epoch 343/500, Loss(MSE): 41.85721219091025\n",
      "Epoch 344/500, Loss(MSE): 41.85740505491885\n",
      "Epoch 345/500, Loss(MSE): 41.85759748058958\n",
      "Epoch 346/500, Loss(MSE): 41.85778946691304\n",
      "Epoch 347/500, Loss(MSE): 41.85798101290736\n",
      "Epoch 348/500, Loss(MSE): 41.85817211761807\n",
      "Epoch 349/500, Loss(MSE): 41.85836278011712\n",
      "Epoch 350/500, Loss(MSE): 41.85855299950321\n",
      "Epoch 351/500, Loss(MSE): 41.85874277490146\n",
      "Epoch 352/500, Loss(MSE): 41.85893210546276\n",
      "Epoch 353/500, Loss(MSE): 41.85912099036414\n",
      "Epoch 354/500, Loss(MSE): 41.85930942880793\n",
      "Epoch 355/500, Loss(MSE): 41.85949742002196\n",
      "Epoch 356/500, Loss(MSE): 41.85968496325877\n",
      "Epoch 357/500, Loss(MSE): 41.85987205779575\n",
      "Epoch 358/500, Loss(MSE): 41.86005870293524\n",
      "Epoch 359/500, Loss(MSE): 41.860244898003025\n",
      "Epoch 360/500, Loss(MSE): 41.86043064234965\n",
      "Epoch 361/500, Loss(MSE): 41.860615935348996\n",
      "Epoch 362/500, Loss(MSE): 41.860800776398406\n",
      "Epoch 363/500, Loss(MSE): 41.86098516491895\n",
      "Epoch 364/500, Loss(MSE): 41.86116910035392\n",
      "Epoch 365/500, Loss(MSE): 41.86135258216995\n",
      "Epoch 366/500, Loss(MSE): 41.86153560985613\n",
      "Epoch 367/500, Loss(MSE): 41.86171818292368\n",
      "Epoch 368/500, Loss(MSE): 41.86190030090576\n",
      "Epoch 369/500, Loss(MSE): 41.86208196335739\n",
      "Epoch 370/500, Loss(MSE): 41.86226316985526\n",
      "Epoch 371/500, Loss(MSE): 41.86244391999696\n",
      "Epoch 372/500, Loss(MSE): 41.86262421340171\n",
      "Epoch 373/500, Loss(MSE): 41.862806207897755\n",
      "Epoch 374/500, Loss(MSE): 41.86299105559024\n",
      "Epoch 375/500, Loss(MSE): 41.863175429656174\n",
      "Epoch 376/500, Loss(MSE): 41.86335932984981\n",
      "Epoch 377/500, Loss(MSE): 41.863542755944586\n",
      "Epoch 378/500, Loss(MSE): 41.86372570773372\n",
      "Epoch 379/500, Loss(MSE): 41.86390818502977\n",
      "Epoch 380/500, Loss(MSE): 41.864090187664054\n",
      "Epoch 381/500, Loss(MSE): 41.864271715486765\n",
      "Epoch 382/500, Loss(MSE): 41.86445276836671\n",
      "Epoch 383/500, Loss(MSE): 41.86463334619086\n",
      "Epoch 384/500, Loss(MSE): 41.86481344886468\n",
      "Epoch 385/500, Loss(MSE): 41.86499307631136\n",
      "Epoch 386/500, Loss(MSE): 41.8651722284716\n",
      "Epoch 387/500, Loss(MSE): 41.86535090530377\n",
      "Epoch 388/500, Loss(MSE): 41.86552910678346\n",
      "Epoch 389/500, Loss(MSE): 41.865706832903264\n",
      "Epoch 390/500, Loss(MSE): 41.865884083672555\n",
      "Epoch 391/500, Loss(MSE): 41.866060859117404\n",
      "Epoch 392/500, Loss(MSE): 41.86623715928041\n",
      "Epoch 393/500, Loss(MSE): 41.866412984220055\n",
      "Epoch 394/500, Loss(MSE): 41.866588334011\n",
      "Epoch 395/500, Loss(MSE): 41.86676320874381\n",
      "Epoch 396/500, Loss(MSE): 41.8669376085244\n",
      "Epoch 397/500, Loss(MSE): 41.86711153347415\n",
      "Epoch 398/500, Loss(MSE): 41.86728498372992\n",
      "Epoch 399/500, Loss(MSE): 41.867460016862246\n",
      "Epoch 400/500, Loss(MSE): 41.86763608983138\n",
      "Epoch 401/500, Loss(MSE): 41.867811678482916\n",
      "Epoch 402/500, Loss(MSE): 41.86798678304221\n",
      "Epoch 403/500, Loss(MSE): 41.86816140374904\n",
      "Epoch 404/500, Loss(MSE): 41.868335540857075\n",
      "Epoch 405/500, Loss(MSE): 41.86850919463394\n",
      "Epoch 406/500, Loss(MSE): 41.86868236536031\n",
      "Epoch 407/500, Loss(MSE): 41.86885505333075\n",
      "Epoch 408/500, Loss(MSE): 41.8690272588529\n",
      "Epoch 409/500, Loss(MSE): 41.86919898224718\n",
      "Epoch 410/500, Loss(MSE): 41.86937022384702\n",
      "Epoch 411/500, Loss(MSE): 41.86954098399831\n",
      "Epoch 412/500, Loss(MSE): 41.86971126305971\n",
      "Epoch 413/500, Loss(MSE): 41.86988106140192\n",
      "Epoch 414/500, Loss(MSE): 41.87005037940771\n",
      "Epoch 415/500, Loss(MSE): 41.87021921747184\n",
      "Epoch 416/500, Loss(MSE): 41.87038757600094\n",
      "Epoch 417/500, Loss(MSE): 41.8705554554131\n",
      "Epoch 418/500, Loss(MSE): 41.87072285613775\n",
      "Epoch 419/500, Loss(MSE): 41.870889778615975\n",
      "Epoch 420/500, Loss(MSE): 41.87105622329918\n",
      "Epoch 421/500, Loss(MSE): 41.87122219065031\n",
      "Epoch 422/500, Loss(MSE): 41.8713876811429\n",
      "Epoch 423/500, Loss(MSE): 41.87155269526092\n",
      "Epoch 424/500, Loss(MSE): 41.871717233498956\n",
      "Epoch 425/500, Loss(MSE): 41.87188129636171\n",
      "Epoch 426/500, Loss(MSE): 41.87204488436396\n",
      "Epoch 427/500, Loss(MSE): 41.872207998030426\n",
      "Epoch 428/500, Loss(MSE): 41.87237063789586\n",
      "Epoch 429/500, Loss(MSE): 41.87253280450433\n",
      "Epoch 430/500, Loss(MSE): 41.87269449840935\n",
      "Epoch 431/500, Loss(MSE): 41.87285572017423\n",
      "Epoch 432/500, Loss(MSE): 41.87301647037099\n",
      "Epoch 433/500, Loss(MSE): 41.87317674958065\n",
      "Epoch 434/500, Loss(MSE): 41.87333655839343\n",
      "Epoch 435/500, Loss(MSE): 41.87349589740803\n",
      "Epoch 436/500, Loss(MSE): 41.87365476723177\n",
      "Epoch 437/500, Loss(MSE): 41.87381316848057\n",
      "Epoch 438/500, Loss(MSE): 41.87397110177855\n",
      "Epoch 439/500, Loss(MSE): 41.87412856775782\n",
      "Epoch 440/500, Loss(MSE): 41.87428556705871\n",
      "Epoch 441/500, Loss(MSE): 41.874442100329496\n",
      "Epoch 442/500, Loss(MSE): 41.87459816822609\n",
      "Epoch 443/500, Loss(MSE): 41.87475377141187\n",
      "Epoch 444/500, Loss(MSE): 41.87490891055775\n",
      "Epoch 445/500, Loss(MSE): 41.8750635863422\n",
      "Epoch 446/500, Loss(MSE): 41.87521779945078\n",
      "Epoch 447/500, Loss(MSE): 41.87537155057611\n",
      "Epoch 448/500, Loss(MSE): 41.87552484041758\n",
      "Epoch 449/500, Loss(MSE): 41.8756776696818\n",
      "Epoch 450/500, Loss(MSE): 41.87583003908164\n",
      "Epoch 451/500, Loss(MSE): 41.87598194933707\n",
      "Epoch 452/500, Loss(MSE): 41.87613340117403\n",
      "Epoch 453/500, Loss(MSE): 41.876284395324866\n",
      "Epoch 454/500, Loss(MSE): 41.87643493252838\n",
      "Epoch 455/500, Loss(MSE): 41.876585013529294\n",
      "Epoch 456/500, Loss(MSE): 41.876734639078336\n",
      "Epoch 457/500, Loss(MSE): 41.87688380993207\n",
      "Epoch 458/500, Loss(MSE): 41.87703252685279\n",
      "Epoch 459/500, Loss(MSE): 41.87718079060835\n",
      "Epoch 460/500, Loss(MSE): 41.87732860197227\n",
      "Epoch 461/500, Loss(MSE): 41.8774759617234\n",
      "Epoch 462/500, Loss(MSE): 41.877622870645936\n",
      "Epoch 463/500, Loss(MSE): 41.8777693295291\n",
      "Epoch 464/500, Loss(MSE): 41.87791533916729\n",
      "Epoch 465/500, Loss(MSE): 41.878060900359756\n",
      "Epoch 466/500, Loss(MSE): 41.87820601391072\n",
      "Epoch 467/500, Loss(MSE): 41.87835068062933\n",
      "Epoch 468/500, Loss(MSE): 41.878494901329034\n",
      "Epoch 469/500, Loss(MSE): 41.878638676827926\n",
      "Epoch 470/500, Loss(MSE): 41.87878200794873\n",
      "Epoch 471/500, Loss(MSE): 41.87892489551838\n",
      "Epoch 472/500, Loss(MSE): 41.879067340368\n",
      "Epoch 473/500, Loss(MSE): 41.87920982120664\n",
      "Epoch 474/500, Loss(MSE): 41.87935288333604\n",
      "Epoch 475/500, Loss(MSE): 41.87949549866792\n",
      "Epoch 476/500, Loss(MSE): 41.879637668074054\n",
      "Epoch 477/500, Loss(MSE): 41.87977939243017\n",
      "Epoch 478/500, Loss(MSE): 41.87992067261544\n",
      "Epoch 479/500, Loss(MSE): 41.880061509512906\n",
      "Epoch 480/500, Loss(MSE): 41.88020190400866\n",
      "Epoch 481/500, Loss(MSE): 41.88034185699245\n",
      "Epoch 482/500, Loss(MSE): 41.88048136935737\n",
      "Epoch 483/500, Loss(MSE): 41.8806204419997\n",
      "Epoch 484/500, Loss(MSE): 41.88075907581874\n",
      "Epoch 485/500, Loss(MSE): 41.88089727171672\n",
      "Epoch 486/500, Loss(MSE): 41.88103503059892\n",
      "Epoch 487/500, Loss(MSE): 41.8811723533737\n",
      "Epoch 488/500, Loss(MSE): 41.881309240951985\n",
      "Epoch 489/500, Loss(MSE): 41.88144569424747\n",
      "Epoch 490/500, Loss(MSE): 41.881581714176576\n",
      "Epoch 491/500, Loss(MSE): 41.881717301658114\n",
      "Epoch 492/500, Loss(MSE): 41.88185245761343\n",
      "Epoch 493/500, Loss(MSE): 41.881987182966355\n",
      "Epoch 494/500, Loss(MSE): 41.88212147864305\n",
      "Epoch 495/500, Loss(MSE): 41.8822553455718\n",
      "Epoch 496/500, Loss(MSE): 41.88238878468295\n",
      "Epoch 497/500, Loss(MSE): 41.8825217969096\n",
      "Epoch 498/500, Loss(MSE): 41.88265438318608\n",
      "Epoch 499/500, Loss(MSE): 41.88278654444909\n",
      "Epoch 500/500, Loss(MSE): 41.882918281637274\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model evalueren"
   ],
   "id": "75869ad696a70683"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T09:00:40.323776Z",
     "start_time": "2024-04-16T09:00:40.103901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate predictions for the test data\n",
    "predictions = nn.predict(X_test.values)\n",
    "\n",
    "# Calculate the error\n",
    "error = y_test.values - predictions\n",
    "\n",
    "# Square the error\n",
    "squared_error = np.square(error)\n",
    "\n",
    "# Calculate the mean of the squared errors\n",
    "mse = np.mean(squared_error)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Convert the predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Predicted'], index=X_test.index)\n",
    "# adding the actual values to the dataframe\n",
    "predictions_df['Actual'] = y_test\n",
    "predictions_df['Difference'] = predictions_df['Predicted'] - predictions_df['Actual']\n",
    "predictions_df['Absolute Difference'] = abs(predictions_df['Difference'])\n",
    "\n",
    "predictions_df"
   ],
   "id": "e577e213bc894e78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8182748.722262755\n"
     ]
    },
    {
     "data": {
      "text/plain": "         Predicted  Actual   Difference  Absolute Difference\n9130   3572.949940      56  3516.949940          3516.949940\n27718  1644.388599      36  1608.388599          1608.388599\n41898  2772.833450      26  2746.833450          2746.833450\n15673  1956.277276      24  1932.277276          1932.277276\n2314   2133.148955      46  2087.148955          2087.148955\n...            ...     ...          ...                  ...\n38076  3740.011614      46  3694.011614          3694.011614\n18731  4136.185523      94  4042.185523          4042.185523\n2460   3502.598164      56  3446.598164          3446.598164\n15719  2158.480623      90  2068.480623          2068.480623\n39153  3762.358042       6  3756.358042          3756.358042\n\n[8613 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted</th>\n      <th>Actual</th>\n      <th>Difference</th>\n      <th>Absolute Difference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9130</th>\n      <td>3572.949940</td>\n      <td>56</td>\n      <td>3516.949940</td>\n      <td>3516.949940</td>\n    </tr>\n    <tr>\n      <th>27718</th>\n      <td>1644.388599</td>\n      <td>36</td>\n      <td>1608.388599</td>\n      <td>1608.388599</td>\n    </tr>\n    <tr>\n      <th>41898</th>\n      <td>2772.833450</td>\n      <td>26</td>\n      <td>2746.833450</td>\n      <td>2746.833450</td>\n    </tr>\n    <tr>\n      <th>15673</th>\n      <td>1956.277276</td>\n      <td>24</td>\n      <td>1932.277276</td>\n      <td>1932.277276</td>\n    </tr>\n    <tr>\n      <th>2314</th>\n      <td>2133.148955</td>\n      <td>46</td>\n      <td>2087.148955</td>\n      <td>2087.148955</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38076</th>\n      <td>3740.011614</td>\n      <td>46</td>\n      <td>3694.011614</td>\n      <td>3694.011614</td>\n    </tr>\n    <tr>\n      <th>18731</th>\n      <td>4136.185523</td>\n      <td>94</td>\n      <td>4042.185523</td>\n      <td>4042.185523</td>\n    </tr>\n    <tr>\n      <th>2460</th>\n      <td>3502.598164</td>\n      <td>56</td>\n      <td>3446.598164</td>\n      <td>3446.598164</td>\n    </tr>\n    <tr>\n      <th>15719</th>\n      <td>2158.480623</td>\n      <td>90</td>\n      <td>2068.480623</td>\n      <td>2068.480623</td>\n    </tr>\n    <tr>\n      <th>39153</th>\n      <td>3762.358042</td>\n      <td>6</td>\n      <td>3756.358042</td>\n      <td>3756.358042</td>\n    </tr>\n  </tbody>\n</table>\n<p>8613 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Difference: 2621.7266332248496\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average difference\n",
    "average_difference = predictions_df['Absolute Difference'].mean()\n",
    "print(f'Average Difference: {average_difference}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T09:00:40.327735Z",
     "start_time": "2024-04-16T09:00:40.324782Z"
    }
   },
   "id": "a2175abd978cea4d",
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
